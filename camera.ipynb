{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Intrinsic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL.ExifTags\n",
    "from bisect import bisect_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_NUM_MATCHES = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Data/dinoSparseRing/\"\n",
    "images = [cv.imread(file) for file in glob(datasetPath+'*.png')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read EXIF Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = PIL.Image.open('tryexif.jpg')\n",
    "exif = {\n",
    "    PIL.ExifTags.TAGS[k]: v\n",
    "    for k, v in img._getexif().items()\n",
    "    if k in PIL.ExifTags.TAGS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesModels = []\n",
    "for img in images:\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp,des = sift.detectAndCompute(img, None)\n",
    "    imageModel = {\n",
    "        \"keyPts\": kp,\n",
    "        \"descriptors\": des\n",
    "    }\n",
    "    imagesModels.append(imageModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fundmental matrix between 2 pictures\n",
    "matchesIdx = [[list() for x in range(len(images))] for y in range(len(images))] \n",
    "def compute_matches(idx1,idx2):\n",
    "    #Matching descriptors\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0 #TODO try:1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(imagesModels[idx1][\"descriptors\"], imagesModels[idx2][\"descriptors\"], k=2)\n",
    "    \n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    #Need to draw only good matches, so create a mask\n",
    "    matchesMask = [[0,0] for i in range(len(matches))]\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.6*n.distance:\n",
    "            #pt = list(kp2[m.trainIdx].pt)\n",
    "            #pt.append(1) #t\n",
    "            pts2.append(imagesModels[idx2][\"keyPts\"][m.trainIdx].pt)\n",
    "            #pt = list(kp1[m.queryIdx].pt)\n",
    "            #pt.append(1) #t\n",
    "            pts1.append(imagesModels[idx1][\"keyPts\"][m.queryIdx].pt) \n",
    "            \n",
    "            matchesIdx[idx1][idx2].append({'idx1': m.queryIdx, 'idx2':  m.trainIdx})\n",
    "            matchesIdx[idx2][idx1].append({'idx1': m.trainIdx, 'idx2': m.queryIdx})\n",
    "            matchesMask[i] = [1,0]\n",
    "    \n",
    "    #Draw Matches\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "    img3 = cv.drawMatchesKnn(images[idx1], imagesModels[idx1][\"keyPts\"], images[idx2], imagesModels[idx2][\"keyPts\"], matches,None,**draw_params)\n",
    "    show_images([images[idx1], images[idx2], img3], [\"img1: idx \" + str(idx1), \"img2: idx \"+str(idx2), \"matches\"])\n",
    "    \n",
    "    return pts1, pts2\n",
    "    '''\n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    #print(pts1)\n",
    "    #print(pts2)\n",
    "    ;;;;;;;;;;;;;;;;;;;;;;;\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    fundmentalMat, mask = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n",
    "    # We select only inlier points\n",
    "    #pts1 = pts1[mask.ravel()==1]\n",
    "    #pts2 = pts2[mask.ravel()==1]\n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Intrinsic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.zeros((3,3))\n",
    "focalLen = 0.5\n",
    "k = [[focalLen, 0, 0],\n",
    "     [0, focalLen, 0],\n",
    "     [0, 0, 1]]\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compute Fundamental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm.\n",
    "    each row is constructed as\n",
    "    [x’*x, x’*y, x’, y’*x, y’*y, y’, x, y, 1] \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # build matrix for equations\n",
    "    A = np.zeros((n,9))\n",
    "    for i in range(n):\n",
    "        A[i] = [x1[0,i]*x2[0,i], x1[0,i]*x2[1,i], x1[0,i]*x2[2,i],\n",
    "        x1[1,i]*x2[0,i], x1[1,i]*x2[1,i], x1[1,i]*x2[2,i],\n",
    "        x1[2,i]*x2[0,i], x1[2,i]*x2[1,i], x1[2,i]*x2[2,i] ]\n",
    "    # compute linear least square solution\n",
    "    U,S,V = np.linalg.svd(A)\n",
    "    F = V[-1].reshape(3,3)\n",
    "    # constrain F\n",
    "    # make rank 2 by zeroing out last singular value\n",
    "    U,S,V = np. linalg.svd(F)\n",
    "    S[2] = 0\n",
    "    F = np.dot(U,np.dot(np.diag(S),V))\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental_normalized(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm. \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # normalize image coordinates\n",
    "    x1 = x1 / x1[2]\n",
    "    mean_1 = np.mean(x1[:2],axis=1)\n",
    "    S1 = np.sqrt(2) / np.std(x1[:2])\n",
    "    T1 = np.array([[S1,0,-S1*mean_1[0]],[0,S1,-S1*mean_1[1]],[0,0,1]])\n",
    "    x1 = np.dot(T1,x1)\n",
    "    x2 = x2 / x2[2]\n",
    "    mean_2 = np.mean(x2[:2],axis=1)\n",
    "    S2 = np.sqrt(2) / np.std(x2[:2])\n",
    "    T2 = np.array([[S2,0,-S2*mean_2[0]],[0,S2,-S2*mean_2[1]],[0,0,1]])\n",
    "    x2 = np.dot(T2,x2) \n",
    "    # compute F with the normalized coordinates\n",
    "    F = compute_fundamental(x1,x2)\n",
    "    # reverse normalization\n",
    "    F = np.dot(np.transpose(T1),np.dot(F,T2))\n",
    "    return F/F[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RansacModel(object):\n",
    "    \"\"\" Class for fundmental matrix fit with ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC\"\"\"\n",
    "    def __init__(self,debug=False):\n",
    "        self.debug = debug\n",
    "        \n",
    "    def fit(self,data):\n",
    "        \"\"\" Estimate fundamental matrix using eight\n",
    "        selected correspondences. \"\"\"\n",
    "        # transpose and split data into the two point sets\n",
    "        data = np.transpose(data)\n",
    "        x1 = data[:3,:8]\n",
    "        x2 = data[3:,:8]\n",
    "        # estimate fundamental matrix and return\n",
    "        F = compute_fundamental_normalized(x1,x2)\n",
    "        return F\n",
    "    \n",
    "    def get_error(self,data,F):\n",
    "        \"\"\" Compute x^T F x for all correspondences,\n",
    "        return error for each transformed point. \"\"\"\n",
    "        # transpose and split data into the two point\n",
    "        data = np.transpose(data)\n",
    "        x1 = data[:3]\n",
    "        x2 = data[3:]\n",
    "        # Sampson distance as error measure\n",
    "        Fx1 = np.dot(F,x1)\n",
    "        Fx2 = np.dot(F,x2)\n",
    "        denom = Fx1[0]**2 + Fx1[1]**2 + Fx2[0]**2 + Fx2[1]**2\n",
    "        err = ( np.diag(np.dot(np.transpose(x1),np.dot(F,x2))) )**2 / denom\n",
    "        # return error per point\n",
    "        return err\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_from_ransac(x1,x2,model,maxiter=5000,match_theshold=1e-6):\n",
    "    \"\"\" Robust estimation of a fundamental matrix F from point\n",
    "    correspondences using RANSAC (ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC).\n",
    "    input: x1,x2 (3*n arrays) points in hom. coordinates. \"\"\"\n",
    "    import ransactmp as ransac\n",
    "    data = np.vstack((x1,x2))\n",
    "    # compute F and return with inlier index\n",
    "    F,ransac_data = ransac.ransac(np.transpose(data),model,8,maxiter,match_theshold,20,debug = False,return_all=True)\n",
    "    return F, ransac_data['inliers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matchScores = np.zeros((len(images), len(images)))\n",
    "homographyScores = np.zeros((len(images), len(images)))\n",
    "#matches = np.zeros((len(images), len(images), 2, 2)) #TODO \"2 or 3 if t is added\"\n",
    "# estimate E with RANSAC\n",
    "model = RansacModel()\n",
    "for i in range(len(images)):\n",
    "    for j in range(i+1, len(images)):\n",
    "        pts1, pts2 = compute_matches(i,j)\n",
    "        #matchScores[i][j] = len(pts1)\n",
    "        #matchScores[j][i] = len(pts1)\n",
    "        print(\"No. of features between \", str(i) , \"&\", str(j),len(pts1))\n",
    "\n",
    "        '''\n",
    "        #TODO Add \"t\" to every point\n",
    "        pts1 = np.transpose(pts1)\n",
    "        pts2 = np.transpose(pts2)\n",
    "        if(len(pts1) < 8):\n",
    "            print(\"Couldn't find good 8 matches to compute Fundamental matrix\")\n",
    "        else:\n",
    "            F,inliers = F_from_ransac(pts1,pts2,model,maxiter=2048,match_theshold=1)\n",
    "            print(\"Fundamental Matrix between \", str(i) , \"&\", str(j), F)\n",
    "        '''\n",
    "       #matches[i][j] = [pts1, pts2]\n",
    "       #matches[j][i] = [pts2, pts1]\n",
    "        \n",
    "        pts1 = np.float32(pts1).reshape(-1,1,2)\n",
    "        pts2 = np.float32(pts2).reshape(-1,1,2)\n",
    "        h, w, _ = images[i].shape\n",
    "        #H, _ = cv.findHomography(pts1, pts2, cv.RANSAC, 0.004*max(h,w))\n",
    "        #if len(H) ==  0:\n",
    "        #    print(\"H matrix cannot be estimated\")\n",
    "        #else:\n",
    "        #   if matchScores[i][j] >= MIN_NUM_MATCHES:\n",
    "        #        homographyScores[i][j] = \n",
    "#sort homographyScores\n",
    "#choose min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyList(object):\n",
    "    # bisect doesn't accept a key function, so we build the key into our sequence.\n",
    "    def __init__(self, l, key):\n",
    "        self.l = l\n",
    "        self.key = key\n",
    "    def __len__(self):\n",
    "        return len(self.l)\n",
    "    def __getitem__(self, index):\n",
    "        return self.key(self.l[index])\n",
    "    \n",
    "\n",
    "def get_matched_idx(matchesList, searchItem):\n",
    "    i = bisect_left(KeyList(matchesList, key=lambda k: k['idx1']), searchItem) \n",
    "    if i != len(matchesList) and matchesList[i]['idx1'] == searchItem: return matchesList[i]['idx2']\n",
    "    else: return -1\n",
    "    \n",
    "#Test \n",
    "'''\n",
    "matchesList = [{'idx1': 100, 'idx2': 5}, {'idx1': 2, 'idx2': 88}, {'idx1': 7, 'idx2': 5}, {'idx1': 9, 'idx2': 10}]\n",
    "print(matchesList[0]['idx1'])\n",
    "matchesList = sorted(matchesList, key=lambda k: k[\"idx1\"]) \n",
    "print(matchesList[0]['idx1'])\n",
    "print(get_matched_idx(matchesList, 2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = []\n",
    "#Sort matchesIdx #TODO #find faster way \n",
    "for i in range(len(images)):\n",
    "    for j in range(len(images)):\n",
    "        matchesIdx[i][j] =  sorted(matchesIdx[i][j], key=lambda k: k[\"idx1\"])\n",
    "\n",
    "for imgIdx in range(len(images)):\n",
    "    if len(matchesIdx[imgIdx]) == 0: continue #??TODO neighbors\n",
    "    flags = np.zeros(len(imagesModels[imgIdx]['keyPts']))\n",
    "    imagesModels[imgIdx]['keyFlags'] = flags\n",
    "    \n",
    "for imgIdx in range(len(images)):\n",
    "    if len(matchesIdx[imgIdx]) == 0: continue #??TODO neighbors\n",
    "    '''\n",
    "    BFS from each feature\n",
    "    images --> Nodes\n",
    "    Features --> Egdes\n",
    "    '''\n",
    "    for featureIdx in range(len(imagesModels[imgIdx]['keyPts'])):\n",
    "        #if the feature was visited\n",
    "        if imagesModels[imgIdx]['keyFlags'][featureIdx] == 1: continue\n",
    "        featuresTrack = []\n",
    "        featuresQueue = []\n",
    "        imageVisited = np.zeros(len(images))\n",
    "        #Mark the feature as visited\n",
    "        imagesModels[imgIdx]['keyFlags'][featureIdx] = 1\n",
    "        featuresTrack.append((imgIdx, featureIdx))\n",
    "        featuresQueue.append((imgIdx, featureIdx))\n",
    "        imageVisited[imgIdx] = 1\n",
    "        while not len(featuresQueue) == 0:\n",
    "            feature = featuresQueue.pop(0)\n",
    "            parImgIdx = feature[0]\n",
    "            parFeatureIdx = feature[1]\n",
    "            for childIdx in range(len(matchesIdx[parImgIdx])): #??TODO neighbors\n",
    "                if imageVisited[childIdx] == 1: continue\n",
    "                childFeatureIdx = get_matched_idx(matchesIdx[parImgIdx][childIdx], parFeatureIdx)# search for parFeatureIdx get the corresponding idx\n",
    "                if childFeatureIdx == -1: continue\n",
    "                if imagesModels[childIdx]['keyFlags'][childFeatureIdx] == 1: continue\n",
    "                imagesModels[childIdx]['keyFlags'][childFeatureIdx] = 1\n",
    "                featuresTrack.append((childIdx, childFeatureIdx))\n",
    "                featuresQueue.append((childIdx, childFeatureIdx))\n",
    "                imageVisited[childIdx] = 1\n",
    "        if len(featuresTrack) >= 2:\n",
    "            tracks.append(featuresTrack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}