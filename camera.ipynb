{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from bisect import bisect_left\n",
    "from copy import copy, deepcopy\n",
    "import os\n",
    "from PIL import Image,ExifTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_MIN_NUM_MATCHES = 50\n",
    "RAY_ANGLE_TH = 2 #degrees\n",
    "TERMINATE_TH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Data/dinoSparseRing/\"\n",
    "filesNames = glob(datasetPath+'*.png') #TODO add jpg also\n",
    "filesNames = sorted(filesNames)\n",
    "images = [cv.imread(file) for file in filesNames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read EXIF Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_focal_length(imgIdx):\n",
    "    ccdWidths = {\n",
    "        \"samsung SM-A307FN\": 1.7#todo for test only #1/2.8\"\n",
    "    }\n",
    "    #img = Image.open('tryexif2.jpg')\n",
    "    img = Image.open(filesNames[imgIdx])\n",
    "    exif = {\n",
    "        ExifTags.TAGS[k]: v\n",
    "        for k, v in img._getexif().items()\n",
    "        if k in ExifTags.TAGS\n",
    "    }\n",
    "    print(exif)\n",
    "    #Get Focal Length\n",
    "    focalN, focalD = exif['FocalLength']\n",
    "    focalLen = float(focalN)/float(focalD)\n",
    "\n",
    "    imgWidth = exif['ExifImageWidth']\n",
    "    imgHeight = exif['ExifImageHeight']\n",
    "    #????????#TODO\n",
    "    if imgWidth < imgHeight:\n",
    "        imgWidth,imgHeight = imgHeight,imgWidth\n",
    "    #Get CCD Width\n",
    "    ccdWidth = 1.0\n",
    "    make = exif['Make']\n",
    "    model = exif['Model']\n",
    "    #Search in the DB\n",
    "    if (make + ' ' + model) in ccdWidths:\n",
    "        ccdWidth = ccdWidths[make + ' ' + model]\n",
    "        print(\"ccdWidth: \", ccdWidth)\n",
    "    #????????#TODO\n",
    "    else:\n",
    "        fplaneN, fplaneD = exif['FocalPlaneXResolution']\n",
    "        if fplaneN != 0:\n",
    "            ccdWidth = 25.4*float(imgWidth)*float(fplaneD)/float(fplaneN)\n",
    "            print(\"ccdWidth: \", ccdWidth)\n",
    "        else:\n",
    "            ccdWidth = 0\n",
    "\n",
    "    if (imgWidth == 0 or imgHeight == 0 or focalN == 0 or ccdWidth == 0):\n",
    "        print (\"focal length can't be determined\")\n",
    "    #Get Focal Length in Pixels\n",
    "    focalLen = imgWidth * (focalLen / ccdWidth)\n",
    "    print(\"focalLen: \", focalLen)\n",
    "    return focalLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Intrinsic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "imgHeight, imgWidth, _ = images[0].shape   \n",
    "#focalLen =  1.2 * max(imgHeight, imgWidth)\n",
    "focalLen = compute_focal_length(0)\n",
    "pp = (imgWidth/2, imgHeight/2)\n",
    "K = [[focalLen, 0, pp[0]],\n",
    "     [0, focalLen, pp[1]],\n",
    "     [0,     0,       1]]\n",
    "'''\n",
    "focalLen = 3310.400000\n",
    "imgHeight, imgWidth, _ = images[0].shape \n",
    "pp = (316.730000, 200.550000)\n",
    "'''\n",
    "K = [[3310.400000, 0.0, 316.730000],\n",
    "     [0.0, 3325.500000, 200.550000],\n",
    "     [0.0,     0.0,       1.0]]\n",
    "'''\n",
    "K = [[3310.400000, 0.0, 316.730000],\n",
    "     [0.0, 3310.400000, 200.550000],\n",
    "     [0.0,     0.0,       1.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sift():\n",
    "    for imgIdx, img in enumerate(images):\n",
    "        #show_images([img],[\"img\"])\n",
    "        #gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        sift = cv.xfeatures2d.SIFT_create()\n",
    "        # find keypoints and descriptors with SIFT\n",
    "        kp,des = sift.detectAndCompute(img, None)\n",
    "        imageModel = {\n",
    "            \"keyPts\": kp,\n",
    "            \"descriptors\": des,\n",
    "            \"tracksFeaturesIdx\": [],\n",
    "            \"projMat\": np.zeros((3,4))\n",
    "        }\n",
    "        imagesModels.append(imageModel)\n",
    "        print(\"Number of keypoints \",len(kp))\n",
    "        #draw\n",
    "        #imgKp = cv.drawKeypoints(gray,kp,copy(img),flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        #show_images([imgKp],[\"img\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Sift BOOk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def process_image(imagename,resultname,params=\"--edge-thresh 10 --peak-thresh 5\"):\n",
    "    \"\"\" Process an image and save the results in a file. \"\"\"\n",
    "    if imagename[-3:] != 'pgm':\n",
    "        # create a pgm file\n",
    "        im = Image.open(imagename).convert('L')\n",
    "        im.save('tmp/tmp.pgm')\n",
    "        imagename = 'tmp/tmp.pgm'\n",
    "    cmmd = str(\"sift \"+imagename+\" --output=\"+resultname+\" \"+params)\n",
    "    os.system(cmmd)\n",
    "    print(\"processed\", imagename, \"to\", resultname)\n",
    "    \n",
    "def read_features_from_file(filename):\n",
    "    \"\"\" Read feature properties and return in matrix form. \"\"\"\n",
    "    f = np.loadtxt(filename)\n",
    "    return f[:,:4],f[:,4:] # feature locations, descriptors\n",
    "def plot_features(im,locs,circle=False):\n",
    "    \"\"\" Show image with features. input: im (image as array),\n",
    "    locs (row, col, scale, orientation of each feature). \"\"\"\n",
    "    def draw_circle(c,r):\n",
    "        t = arange(0,1.01,.01)*2*pi\n",
    "        x = r*cos(t) + c[0]\n",
    "        y = r*sin(t) + c[1]\n",
    "        plot(x,y,'b',linewidth=2)\n",
    "    imshow(im)\n",
    "    if circle:\n",
    "        for p in locs:\n",
    "            draw_circle(p[:2],p[2])\n",
    "    else:\n",
    "        plot(locs[:,0],locs[:,1],'ob')\n",
    "    axis('off')\n",
    "    \n",
    "#for i,img in enumerate(images):\n",
    "for file in glob(datasetPath+'*.png'):\n",
    "    img = np.array(Image.open(file).convert('L'))\n",
    "    print(file)\n",
    "    process_image(file,  str(i)+'.sift')\n",
    "    l1,d1 = read_features_from_file(str(i)+'.sift')\n",
    "    #figure()\n",
    "    #gray()\n",
    "    plot_features(img,l1,circle=True)\n",
    "    #show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matches(idx1,idx2): #image indices\n",
    "    #Matching descriptors\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0 #TODO try:1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(imagesModels[idx1][\"descriptors\"], imagesModels[idx2][\"descriptors\"], k=2)\n",
    "    \n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    #Need to draw only good matches, so create a mask\n",
    "    matchesMask = [[0,0] for i in range(len(matches))]\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.6*n.distance:\n",
    "            pts2.append(imagesModels[idx2][\"keyPts\"][m.trainIdx].pt)\n",
    "            pts1.append(imagesModels[idx1][\"keyPts\"][m.queryIdx].pt) \n",
    "            \n",
    "            matchesIdx[idx1][idx2].append({'idx1': m.queryIdx, 'idx2':  m.trainIdx})\n",
    "            matchesIdx[idx2][idx1].append({'idx1': m.trainIdx, 'idx2': m.queryIdx})\n",
    "            matchesMask[i] = [1,0]\n",
    "    \n",
    "    #Draw Matches\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "    img3 = cv.drawMatchesKnn(images[idx1], imagesModels[idx1][\"keyPts\"], images[idx2], imagesModels[idx2][\"keyPts\"], matches,None,**draw_params)\n",
    "    #show_images([images[idx1], images[idx2], img3], [\"img1: idx \" + str(idx1), \"img2: idx \"+str(idx2), \"matches\"])\n",
    "    \n",
    "    return pts1, pts2\n",
    "    '''\n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    #print(pts1)\n",
    "    #print(pts2)\n",
    "    ;;;;;;;;;;;;;;;;;;;;;;;\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    fundmentalMat, mask = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n",
    "    # We select only inlier points\n",
    "    #pts1 = pts1[mask.ravel()==1]\n",
    "    #pts2 = pts2[mask.ravel()==1]\n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat\n",
    "    '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Compute Fundamental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm.\n",
    "    each row is constructed as\n",
    "    [x’*x, x’*y, x’, y’*x, y’*y, y’, x, y, 1] \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # build matrix for equations\n",
    "    A = np.zeros((n,9))\n",
    "    for i in range(n):\n",
    "        A[i] = [x1[0,i]*x2[0,i], x1[0,i]*x2[1,i], x1[0,i]*x2[2,i],\n",
    "        x1[1,i]*x2[0,i], x1[1,i]*x2[1,i], x1[1,i]*x2[2,i],\n",
    "        x1[2,i]*x2[0,i], x1[2,i]*x2[1,i], x1[2,i]*x2[2,i] ]\n",
    "    # compute linear least square solution\n",
    "    U,S,V = np.linalg.svd(A)\n",
    "    F = V[-1].reshape(3,3)\n",
    "    # constrain F\n",
    "    # make rank 2 by zeroing out last singular value\n",
    "    U,S,V = np. linalg.svd(F)\n",
    "    S[2] = 0\n",
    "    F = np.dot(U,np.dot(np.diag(S),V))\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental_normalized(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm. \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # normalize image coordinates\n",
    "    x1 = x1 / x1[2]\n",
    "    mean_1 = np.mean(x1[:2],axis=1)\n",
    "    S1 = np.sqrt(2) / np.std(x1[:2])\n",
    "    T1 = np.array([[S1,0,-S1*mean_1[0]],[0,S1,-S1*mean_1[1]],[0,0,1]])\n",
    "    x1 = np.dot(T1,x1)\n",
    "    x2 = x2 / x2[2]\n",
    "    mean_2 = np.mean(x2[:2],axis=1)\n",
    "    S2 = np.sqrt(2) / np.std(x2[:2])\n",
    "    T2 = np.array([[S2,0,-S2*mean_2[0]],[0,S2,-S2*mean_2[1]],[0,0,1]])\n",
    "    x2 = np.dot(T2,x2) \n",
    "    # compute F with the normalized coordinates\n",
    "    F = compute_fundamental(x1,x2)\n",
    "    # reverse normalization\n",
    "    F = np.dot(np.transpose(T1),np.dot(F,T2))\n",
    "    return F/F[2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RansacModel(object):\n",
    "    \"\"\" Class for fundmental matrix fit with ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC\"\"\"\n",
    "    def __init__(self,debug=False):\n",
    "        self.debug = debug\n",
    "        \n",
    "    def fit(self,data):\n",
    "        \"\"\" Estimate fundamental matrix using eight\n",
    "        selected correspondences. \"\"\"\n",
    "        # transpose and split data into the two point sets\n",
    "        data = np.transpose(data)\n",
    "        x1 = data[:3,:8]\n",
    "        x2 = data[3:,:8]\n",
    "        # estimate fundamental matrix and return\n",
    "        F = compute_fundamental_normalized(x1,x2)\n",
    "        return F\n",
    "    \n",
    "    def get_error(self,data,F):\n",
    "        \"\"\" Compute x^T F x for all correspondences,\n",
    "        return error for each transformed point. \"\"\"\n",
    "        # transpose and split data into the two point\n",
    "        data = np.transpose(data)\n",
    "        x1 = data[:3]\n",
    "        x2 = data[3:]\n",
    "        # Sampson distance as error measure\n",
    "        Fx1 = np.dot(F,x1)\n",
    "        Fx2 = np.dot(F,x2)\n",
    "        denom = Fx1[0]**2 + Fx1[1]**2 + Fx2[0]**2 + Fx2[1]**2\n",
    "        err = ( np.diag(np.dot(np.transpose(x1),np.dot(F,x2))) )**2 / denom\n",
    "        # return error per point\n",
    "        return err\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F_from_ransac(x1,x2,model,maxiter=5000,match_theshold=1e-6):\n",
    "    \"\"\" Robust estimation of a fundamental matrix F from point\n",
    "    correspondences using RANSAC (ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC).\n",
    "    input: x1,x2 (3*n arrays) points in hom. coordinates. \"\"\"\n",
    "    import ransactmp as ransac\n",
    "    data = np.vstack((x1,x2))\n",
    "    # compute F and return with inlier index\n",
    "    F,ransac_data = ransac.ransac(np.transpose(data),model,8,maxiter,match_theshold,20,debug = False,return_all=True)\n",
    "    return F, ransac_data['inliers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyList(object):\n",
    "    # bisect doesn't accept a key function, so we build the key into our sequence.\n",
    "    def __init__(self, l, key):\n",
    "        self.l = l\n",
    "        self.key = key\n",
    "    def __len__(self):\n",
    "        return len(self.l)\n",
    "    def __getitem__(self, index):\n",
    "        return self.key(self.l[index])\n",
    "    \n",
    "\n",
    "def get_matched_idx(matchesList, searchItem):\n",
    "    i = bisect_left(KeyList(matchesList, key=lambda k: k['idx1']), searchItem) \n",
    "    if i != len(matchesList) and matchesList[i]['idx1'] == searchItem: return matchesList[i]['idx2']\n",
    "    else: return -1\n",
    "    \n",
    "#Test \n",
    "'''\n",
    "matchesList = [{'idx1': 100, 'idx2': 5}, {'idx1': 2, 'idx2': 88}, {'idx1': 7, 'idx2': 5}, {'idx1': 9, 'idx2': 10}]\n",
    "print(matchesList[0]['idx1'])\n",
    "matchesList = sorted(matchesList, key=lambda k: k[\"idx1\"]) \n",
    "print(matchesList[0]['idx1'])\n",
    "print(get_matched_idx(matchesList, 2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tracks():\n",
    "    #Sort matchesIdx #TODO #find faster way \n",
    "    for i in range(len(images)):\n",
    "        for j in range(len(images)):\n",
    "            matchesIdx[i][j] =  sorted(matchesIdx[i][j], key=lambda k: k[\"idx1\"])\n",
    "\n",
    "    for imgIdx in range(len(images)):\n",
    "        if len(matchesIdx[imgIdx]) == 0: continue #??TODO neighbors\n",
    "        flags = np.zeros(len(imagesModels[imgIdx]['keyPts']))\n",
    "        imagesModels[imgIdx]['keyFlags'] = flags\n",
    "\n",
    "    for imgIdx in range(len(images)):\n",
    "        if len(matchesIdx[imgIdx]) == 0: continue #??TODO neighbors\n",
    "        '''\n",
    "        BFS from each feature\n",
    "        images --> Nodes\n",
    "        Features --> Egdes\n",
    "        '''\n",
    "        for featureIdx in range(len(imagesModels[imgIdx]['keyPts'])):\n",
    "            #if the feature was visited\n",
    "            if imagesModels[imgIdx]['keyFlags'][featureIdx] == 1: continue\n",
    "            featuresTrack = []\n",
    "            featuresQueue = []\n",
    "            imageVisited = np.zeros(len(images))\n",
    "            #Mark the feature as visited\n",
    "            imagesModels[imgIdx]['keyFlags'][featureIdx] = 1\n",
    "            featuresTrack.append((imgIdx, featureIdx))\n",
    "            featuresQueue.append((imgIdx, featureIdx))\n",
    "            imageVisited[imgIdx] = 1\n",
    "            while not len(featuresQueue) == 0:\n",
    "                feature = featuresQueue.pop(0)\n",
    "                parImgIdx = feature[0]\n",
    "                parFeatureIdx = feature[1]\n",
    "                for childIdx in range(len(matchesIdx[parImgIdx])): #??TODO neighbors\n",
    "                    if imageVisited[childIdx] == 1: continue\n",
    "                    childFeatureIdx = get_matched_idx(matchesIdx[parImgIdx][childIdx], parFeatureIdx)# search for parFeatureIdx get the corresponding idx\n",
    "                    if childFeatureIdx == -1: continue\n",
    "                    if imagesModels[childIdx]['keyFlags'][childFeatureIdx] == 1: continue\n",
    "                    imagesModels[childIdx]['keyFlags'][childFeatureIdx] = 1\n",
    "                    featuresTrack.append((childIdx, childFeatureIdx))\n",
    "                    featuresQueue.append((childIdx, childFeatureIdx))\n",
    "                    imageVisited[childIdx] = 1\n",
    "            if len(featuresTrack) >= 2:\n",
    "                tracks.append(featuresTrack)\n",
    "    for trackIdx in range(len(tracks)):\n",
    "        for imgIdx,featureIdx in tracks[trackIdx]:\n",
    "            imagesModels[imgIdx]['tracksFeaturesIdx'].append((trackIdx, featureIdx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Projection Matrix For initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cam2 is the ref #TODO make sure?\n",
    "#tODO test on each pair of images\n",
    "def proj_matrix_for_initial_camera(imgIdx1, imgIdx2):\n",
    "    #TODO instead of the two for loops --> Store the value of pts\n",
    "    matchIndices1 = []\n",
    "    matchIndices2 = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for item in matchesIdx[imgIdx1][imgIdx2]:\n",
    "        matchIndices1.append(item['idx1'])\n",
    "        matchIndices2.append(item['idx2'])\n",
    "    \n",
    "    for i in range(len(matchIndices1)):\n",
    "        pts1.append(imagesModels[imgIdx1]['keyPts'][matchIndices1[i]].pt)\n",
    "        pts2.append(imagesModels[imgIdx2]['keyPts'][matchIndices2[i]].pt)\n",
    "\n",
    "    E, mask = cv.findEssentialMat(np.array(pts1), np.array(pts2), \n",
    "                             focal = focalLen,\n",
    "                             pp = (imgWidth/2, imgHeight/2), #TODO may be 0,0 or imgWidth/2, imgHeight/2\n",
    "                             method = cv.RANSAC, \n",
    "                             prob = 0.999, \n",
    "                             threshold = 1.0) \n",
    "\n",
    "    '''\n",
    "   ** threshold – Parameter used for RANSAC. \n",
    "    It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier\n",
    "    and is not used for computing the final fundamental matrix.\n",
    "    It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise.\n",
    "   ** prob – Parameter used for the RANSAC or LMedS methods only. \n",
    "    It specifies a desirable level of confidence (probability) that the estimated matrix is correct\n",
    "    '''\n",
    "    #retval:NumOfInliers\n",
    "    retval, R, t, mask, triangulatedPoints = cv.recoverPose(E, np.array(pts1), np.array(pts2), np.array(K), distanceThresh = 50) #TODO  # 2pass l mask l tal3 mn l essential?\n",
    "    return R, t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Projection Matrix From point correspondence Book\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_P(x,X):\n",
    "    \"\"\" Compute camera matrix from pairs of\n",
    "    2D-3D correspondences (in homog. coordinates). \"\"\"\n",
    "    n = x.shape[1]\n",
    "    if X.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "        \n",
    "    # create matrix for DLT solution\n",
    "    M = np.zeros((3*n,12+n))\n",
    "    for i in range(n):\n",
    "        M[3*i,0:4] = X[:,i]\n",
    "        M[3*i+1,4:8] = X[:,i]\n",
    "        M[3*i+2,8:12] = X[:,i]\n",
    "        M[3*i:3*i+3,i+12] = -x[:,i]\n",
    "    U,S,V = np.linalg.svd(M)\n",
    "    return V[-1,:12].reshape((3,4))\n",
    "\n",
    "\"\"\"\n",
    "#Test\n",
    "# load 2D points for each view to a list\n",
    "points2D = [np.loadtxt('Data/dataset_camera_3_MertonCollegeI/2D/00'+str(i+1)+'.corners').T for i in range(3)]\n",
    "# load 3D points\n",
    "points3D = np.loadtxt('Data/dataset_camera_3_MertonCollegeI/3D/p3d').T\n",
    "# load correspondences\n",
    "corr = np.genfromtxt('Data/dataset_camera_3_MertonCollegeI/2D/nview-corners',dtype='int',missing_values='*')\n",
    "# load cameras to a list of Camera objects\n",
    "P = [np.loadtxt('Data/dataset_camera_3_MertonCollegeI/2D/00'+str(i+1)+'.P') for i in range(3)]\n",
    "\n",
    "corr = corr[:,0] # view 1\n",
    "ndx3D = np.where(corr>=0)[0] # missing values are -1\n",
    "ndx2D = corr[ndx3D]\n",
    "# select visible points and make homogeneous\n",
    "x = points2D[0][:,ndx2D] # view 1\n",
    "x = np.vstack( (x,np.ones(x.shape[1])) )\n",
    "X = points3D[:,ndx3D]\n",
    "X = np.vstack( (X,np.ones(X.shape[1])) )\n",
    "print(\"x: \", x.shape, \"X: \", X.shape)\n",
    "print(\"x: \", x, \"X: \", X)\n",
    "#### estimate P ####\n",
    "Pest = compute_P(x,X)\n",
    "print(Pest/ Pest[2,3])\n",
    "print(P[0] / P[0][2,3])\n",
    "###project the  estimated 3D point  #Try\n",
    "#the true points in blue and the estimated camera projection in red.\n",
    "xest = Pest.project(X)\n",
    "'''\n",
    "# plotting\n",
    "figure()\n",
    "imshow(im1)\n",
    "plot(x[0],x[1],’b.’)\n",
    "plot(xest[0],xest[1],’r.’)\n",
    "axis(’off’)\n",
    "show()\n",
    "'''\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Bundle Adjustment_implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def reprojectionError(camMatrices, X_est, imgCoords):\n",
    "    '''\n",
    "    Inputs: camMatrices is a numCameras by 3 by 4 numpy array.\n",
    "    X_est is a 3 by numPoints numpy array.\n",
    "    imgCoords is a 2 by numPoints numpy array.\n",
    "    '''\n",
    "    \n",
    "    numCameras = camMatrices.shape[0]\n",
    "    numPoints = X_est.shape[1]\n",
    "    \n",
    "    proj = camMatrices @ np.vstack((X_est,np.ones((1,numPoints))))\n",
    "    cost = np.sum((proj[:,0,:]/proj[:,2,:] - imgCoords[:,0,:])**2 + (proj[:,1,:]/proj[:,2,:] - imgCoords[:,1,:])**2)\n",
    "            \n",
    "    return cost\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def bundleAdjust_LM(camMatrices, X_est, imgCoords):\n",
    "    '''\n",
    "    We perform bundle adjustment using the Levenberg-Marquardt algorithm.\n",
    "    See bundleAdjust_sparseLM for the sparse version of this algortihm.\n",
    "    \n",
    "    Inputs: camMatrices is a numCameras by 3 by 4 numpy array.\n",
    "    X_est is a 3 by numPoints numpy array.\n",
    "    imgCoords is a numCameras by 2 by numPoints numpy array.\n",
    "    '''\n",
    "    \n",
    "    lmbda = .0001\n",
    "    maxIter = 10\n",
    "    reduceFactor = .1\n",
    "    increaseFactor = 10\n",
    "    \n",
    "    numCameras = camMatrices.shape[0]\n",
    "    numPoints = X_est.shape[1]\n",
    "    \n",
    "    d = 12*numCameras + 3*numPoints\n",
    "    \n",
    "    P = camMatrices.copy()\n",
    "    X = X_est.copy()\n",
    "    \n",
    "    reprojErr = reprojectionError(P,X,imgCoords)\n",
    "    reprojErrors = np.zeros(maxIter)\n",
    "    \n",
    "    for iter in range(maxIter):\n",
    "        \n",
    "        print('iter is: ', iter)\n",
    "        \n",
    "        # Set up the normal equations.\n",
    "        mtrx = np.zeros((d,d))\n",
    "        rhs = np.zeros(d)\n",
    "        \n",
    "        for i in range(numCameras):\n",
    "            \n",
    "            Pi = P[i]\n",
    "            rows = np.zeros((12, d))\n",
    "            \n",
    "            for j in range(numPoints):\n",
    "                \n",
    "                Xj = X[:,j]\n",
    "                x_ij = imgCoords[i,:,j]\n",
    "                \n",
    "                dxHatdP_ij = dxHatdP(Pi,Xj)\n",
    "                dxHatdX_ij = dxHatdX(Pi,Xj)\n",
    "                \n",
    "                rows[:,12*i:12*i+12] += dxHatdP_ij.T @ dxHatdP_ij\n",
    "                rows[:,12*numCameras + 3*j:12*numCameras + 3*j + 3] = dxHatdP_ij.T @ dxHatdX_ij\n",
    "                \n",
    "                rhs[12*i:12*i+12] += dxHatdP_ij.T @ (x_ij - xHat(Pi,Xj))\n",
    "                \n",
    "            \n",
    "            rows[:,12*i:12*i+12] += lmbda * np.eye(12)\n",
    "            \n",
    "            mtrx[12*i:12*i+12,:] = rows\n",
    "            \n",
    "        for j in range(numPoints):\n",
    "            \n",
    "            Xj = X[:,j]\n",
    "            rows = np.zeros((3,d))\n",
    "            \n",
    "            for i in range(numCameras):\n",
    "                \n",
    "                Pi = P[i]\n",
    "                x_ij = imgCoords[i,:,j]\n",
    "                dxHatdP_ij = dxHatdP(Pi,Xj)\n",
    "                dxHatdX_ij = dxHatdX(Pi,Xj)\n",
    "                \n",
    "                rows[:,12*i:12*i+12] = dxHatdX_ij.T @ dxHatdP_ij\n",
    "                rows[:,12*numCameras + 3*j:12*numCameras + 3*j+3] += dxHatdX_ij.T @ dxHatdX_ij\n",
    "                \n",
    "                rhs[12*numCameras + 3*j:12*numCameras + 3*j + 3] += dxHatdX_ij.T @ (x_ij - xHat(Pi,Xj))\n",
    "                \n",
    "            rows[:,12*numCameras + 3*j:12*numCameras + 3*j+3] += lmbda * np.eye(3)\n",
    "            \n",
    "            mtrx[12*numCameras + 3*j:12*numCameras + 3*j + 3] = rows\n",
    "            \n",
    "        # Now solve normal equations\n",
    "        vec = np.linalg.solve(mtrx, rhs)\n",
    "        \n",
    "        dP = vec[0:12*numCameras]\n",
    "        dX = vec[12*numCameras:]\n",
    "        \n",
    "        dP = np.reshape(dP,(numCameras,3,4))\n",
    "        dX = np.reshape(dX,(numPoints,3)).T\n",
    "\n",
    "        P_next = P + dP\n",
    "        X_next = X + dX\n",
    "        \n",
    "        reprojErr_next = reprojectionError(P_next, X_next, imgCoords)\n",
    "        \n",
    "        if reprojErr_next < reprojErr:\n",
    "            \n",
    "            P = P_next\n",
    "            X = X_next\n",
    "            reprojErr = reprojErr_next\n",
    "            lmbda *= reduceFactor\n",
    "\n",
    "        else:\n",
    "            lmbda *= increaseFactor\n",
    "            reprojErrors[iter] = reprojErr\n",
    "            \n",
    "        reprojErrors[iter] = reprojErr\n",
    "        print('iter: ', iter, 'reprojError: ', reprojErr_next, 'lmbda: ', lmbda)\n",
    "        \n",
    "    return P, X, reprojErrors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def bundleAdjust_sparseLM(camMatrices, X_est, imgCoords):\n",
    "    '''\n",
    "    We perform bundle adjustment using the sparse Levenberg-Marquardt algorithm.\n",
    "    \n",
    "    Inputs: camMatrices is a numCameras by 3 by 4 numpy array.\n",
    "    X_est is a 3 by numPoints numpy array.\n",
    "    imgCoords is a numCameras by 2 by numPoints numpy array.\n",
    "    '''\n",
    "    \n",
    "    lmbda = .0001\n",
    "    maxIter = 10\n",
    "    reduceFactor = .1\n",
    "    increaseFactor = 10\n",
    "    \n",
    "    numCameras = camMatrices.shape[0]\n",
    "    numPoints = X_est.shape[1]\n",
    "    \n",
    "    d = 12*numCameras + 3*numPoints\n",
    "    \n",
    "    P = camMatrices.copy()\n",
    "    X = X_est.copy()\n",
    "    \n",
    "    reprojErr = reprojectionError(P,X,imgCoords)\n",
    "    reprojErrors = np.zeros(maxIter)\n",
    "    \n",
    "    for iter in range(maxIter):\n",
    "        \n",
    "        print('iter is: ', iter)\n",
    "        \n",
    "        # Set up the normal equations.\n",
    "        \n",
    "        # upperLeftBlocks = np.zeros((numCameras,12,12))\n",
    "        # coefficient matrix for normal equations is partitioned into\n",
    "        # upper left (UL), upper right (UR), lower left (LL), and lower right (LR) blocks.\n",
    "        # Lower left block is transpose of upper right block.\n",
    "        # The lower right matrix is itself block diagonal.\n",
    "        UL = np.zeros((12*numCameras,12*numCameras))\n",
    "        UR = np.zeros((12*numCameras,3*numPoints))\n",
    "        LR_blocks= np.zeros((numPoints,3,3))\n",
    "        rhs = np.zeros(d) # right hand side of normal equations.\n",
    "        \n",
    "        for i in range(numCameras):\n",
    "            \n",
    "            Pi = P[i]\n",
    "            rows = np.zeros((12, d))\n",
    "            \n",
    "            for j in range(numPoints):\n",
    "                \n",
    "                Xj = X[:,j]\n",
    "                x_ij = imgCoords[i,:,j]\n",
    "                \n",
    "                dxHatdP_ij = dxHatdP(Pi,Xj)\n",
    "                dxHatdX_ij = dxHatdX(Pi,Xj)\n",
    "                \n",
    "                rows[:,12*i:12*i+12] += dxHatdP_ij.T @ dxHatdP_ij\n",
    "                rows[:,12*numCameras + 3*j:12*numCameras + 3*j + 3] = dxHatdP_ij.T @ dxHatdX_ij\n",
    "                \n",
    "                UL[12*i:12*i+12,12*i:12*i+12] += dxHatdP_ij.T @ dxHatdP_ij\n",
    "                UR[12*i:12*i+12,3*j:3*j + 3] = dxHatdP_ij.T @ dxHatdX_ij\n",
    "                \n",
    "                rhs[12*i:12*i+12] += dxHatdP_ij.T @ (x_ij - xHat(Pi,Xj))\n",
    "                \n",
    "            UL[12*i:12*i+12,12*i:12*i+12] += lmbda * np.eye(12)\n",
    "            \n",
    "        for j in range(numPoints):\n",
    "            \n",
    "            Xj = X[:,j]\n",
    "            \n",
    "            for i in range(numCameras):\n",
    "                \n",
    "                Pi = P[i]\n",
    "                x_ij = imgCoords[i,:,j]\n",
    "                dxHatdP_ij = dxHatdP(Pi,Xj)\n",
    "                dxHatdX_ij = dxHatdX(Pi,Xj)\n",
    "                \n",
    "                LR_blocks[j] += dxHatdX_ij.T @ dxHatdX_ij\n",
    "                \n",
    "                rhs[12*numCameras + 3*j:12*numCameras + 3*j + 3] += dxHatdX_ij.T @ (x_ij - xHat(Pi,Xj))\n",
    "                \n",
    "            LR_blocks[j] += lmbda * np.eye(3)\n",
    "            \n",
    "        rhs_upper = rhs[0:12*numCameras]\n",
    "        rhs_lower = rhs[12*numCameras:]\n",
    "        \n",
    "        LR_blocks_inv = np.zeros(LR_blocks.shape)\n",
    "        LR_inv_times_rhs_lower = np.zeros(rhs_lower.shape)\n",
    "        LR_inv_times_LL = np.zeros(UR.T.shape)\n",
    "        for j in range(numPoints):\n",
    "            LR_blocks_inv[j] = np.linalg.inv(LR_blocks[j])\n",
    "            LR_inv_times_rhs_lower[3*j:3*j+3] = LR_blocks_inv[j] @ rhs_lower[3*j:3*j+3]\n",
    "            LR_inv_times_LL[3*j:3*j+3] = LR_blocks_inv[j] @ UR.T[3*j:3*j+3,:]\n",
    "            \n",
    "        dP = np.linalg.solve(UL- UR @ LR_inv_times_LL, rhs_upper - UR @ LR_inv_times_rhs_lower)\n",
    "        dX = LR_inv_times_rhs_lower - LR_inv_times_LL @ dP\n",
    "        \n",
    "        dP = np.reshape(dP,(numCameras,3,4))\n",
    "        dX = np.reshape(dX,(numPoints,3)).T\n",
    "\n",
    "        P_next = P + dP\n",
    "        X_next = X + dX\n",
    "        \n",
    "        reprojErr_next = reprojectionError(P_next, X_next, imgCoords)\n",
    "        \n",
    "        if reprojErr_next < reprojErr:\n",
    "            \n",
    "            P = P_next\n",
    "            X = X_next\n",
    "            reprojErr = reprojErr_next\n",
    "            lmbda *= reduceFactor\n",
    "\n",
    "        else:\n",
    "            lmbda *= increaseFactor\n",
    "            reprojErrors[iter] = reprojErr\n",
    "            \n",
    "        reprojErrors[iter] = reprojErr\n",
    "        print('iter: ', iter, 'reprojError: ', reprojErr_next, 'lmbda: ', lmbda)\n",
    "        \n",
    "    return P, X, reprojErrors\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intrinsic_matrix():\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO test\n",
    "def get_reference_proj(): \n",
    "    KR = np.matmul(get_intrinsic_matrix(),np.eye(3, dtype=int))\n",
    "    proj = np.zeros((3,4))\n",
    "    proj[:,:-1] = KR\n",
    "    return proj\n",
    "\n",
    "def compute_proj(R,t):\n",
    "    KR = np.matmul(get_intrinsic_matrix(),R)\n",
    "    return np.append(KR, t, axis=1) #TODO change np.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_proj_matrix(P):\n",
    "    \"\"\" Factorize the camera matrix into K,R,t as P = K[R|t]. \"\"\"\n",
    "    # factor first 3*3 part\n",
    "    R,K1 = np.linalg.qr(P[:,:3])\n",
    "    # make diagonal of K positive\n",
    "    T = np.diag(np.sign(np.diag(K1)))\n",
    "    if np.linalg.det(T) < 0:\n",
    "        T[1,1] *= -1\n",
    "    K1 = np.dot(K1,T)\n",
    "    R = np.dot(T,R) # T is its own inverse\n",
    "    t = np.dot(np.linalg.inv(K1),P[:,3])\n",
    "    return K1, R, t.reshape(3,1)\n",
    "\n",
    "\"\"\"\n",
    "#test\n",
    "P = get_reference_proj()\n",
    "print(factorize_proj_matrix(P))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ADD projmat = zeroes initialization\n",
    "def compute_ray_angle(pt1,pt2,imgIdx1,imgIdx2):\n",
    "    #k1,R1,t1,_,_,_,_ = cv.decomposeProjectionMatrix(imagesModels[imgIdx1]['projMat'])\n",
    "    #k2,R2,t2,_,_,_,_ = cv.decomposeProjectionMatrix(imagesModels[imgIdx2]['projMat'])\n",
    "    k1, R1,t1 = factorize_proj_matrix(imagesModels[imgIdx1]['projMat'])\n",
    "    k2,R2,t2 = factorize_proj_matrix(imagesModels[imgIdx2]['projMat'])\n",
    "    \n",
    "    #Should have the same K --> check\n",
    "    #print(\"[check] k1:\\n\", k1, \"k2:\\n\", k2)\n",
    "    pt1Norm = np.matmul(np.linalg.inv(k1), pt1.reshape(3,1))\n",
    "    pt2Norm = np.matmul(np.linalg.inv(k2), pt2.reshape(3,1))\n",
    "    pt1Norm = pt1Norm/pt1Norm[2]\n",
    "    pt2Norm = pt2Norm/pt2Norm[2]\n",
    "    pt1Norm[2] = -1 #t\n",
    "    pt2Norm[2] = -1\n",
    "    \n",
    "    Rtrans1 = np.transpose(R1)\n",
    "    Rtrans2 = np.transpose(R2)\n",
    "    \n",
    "    Rpt1 = np.matmul(Rtrans1, pt1Norm)\n",
    "    Rpt2 = np.matmul(Rtrans2, pt2Norm)\n",
    "    \n",
    "    pW1 = Rpt1 + t1\n",
    "    pW2 = Rpt2 + t2\n",
    "    \n",
    "    ray1 = pW1 - t1\n",
    "    ray2 = pW2 - t2\n",
    "    dot = np.dot(np.squeeze(ray2), np.squeeze(ray1))\n",
    "    \n",
    "    magnitude = np.linalg.norm(ray1)*np.linalg.norm(ray2)\n",
    "    angle = np.math.acos(dot/magnitude)\n",
    "    angle = np.math.degrees(angle)\n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(cv.decomposeProjectionMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesModels = []\n",
    "matchesIdx = [[list() for x in range(len(images))] for y in range(len(images))] \n",
    "tracks = []\n",
    "print(\"SIFT\")\n",
    "compute_sift()\n",
    "print(len(imagesModels))\n",
    "#matchScores = np.zeros((len(images), len(images))) #TODO compute from it the INIT_MIN_NUM_MATCHES\n",
    "homographyScores = []\n",
    "#model = RansacModel()\n",
    "for i in range(len(images)):\n",
    "    for j in range(i+1, len(images)):\n",
    "        pts1, pts2 = compute_matches(i,j)\n",
    "        #matchScores[i][j] = len(pts1)\n",
    "        #matchScores[j][i] = len(pts1)\n",
    "        #print(\"No. of matched features between \", str(i) , \"&\", str(j),len(pts1))\n",
    "        '''\n",
    "        #Compute Fundamental matrix\n",
    "        #Add \"t\" to every point\n",
    "        pts1Homogenous = cv.convertPointsToHomogeneous(np.float32(pts1)).reshape((-1,3))\n",
    "        pts2Homogenous = cv.convertPointsToHomogeneous(np.float32(pts2)).reshape((-1,3))\n",
    "        pts1Homogenous = np.transpose(pts1Homogenous)\n",
    "        pts2Homogenous = np.transpose(pts2Homogenous)\n",
    "        if(len(pts1) < 8):\n",
    "            print(\"Couldn't find good 8 matches to compute Fundamental matrix\")\n",
    "        else:\n",
    "            F,inliers = F_from_ransac(pts1Homogenous,pts2Homogenous,model,maxiter=2048,match_theshold=1)\n",
    "            print(\"Fundamental Matrix between \", str(i) , \"&\", str(j), F)\n",
    "            #tODO refine matches\n",
    "        '''\n",
    "        \n",
    "        pts1 = np.float32(pts1).reshape(-1,1,2)\n",
    "        pts2 = np.float32(pts2).reshape(-1,1,2)\n",
    "        if len(pts1) < 4:\n",
    "            print(\"Couldn't find good 4 matches to compute Homograhy matrix\")\n",
    "        else:  \n",
    "            H, mask = cv.findHomography(pts1, pts2, cv.RANSAC, 0.004*max(imgHeight, imgWidth))\n",
    "            HinliersNum = list(mask).count(1)\n",
    "            #print(\"HinliersNum: \", HinliersNum)\n",
    "            if len(pts1) >= INIT_MIN_NUM_MATCHES:\n",
    "                homographyScores.append({\"idx1\":i, \"idx2\": j, \"percentage\": HinliersNum/len(pts1)})\n",
    "                \n",
    "compute_tracks()\n",
    "print(\"tracks: \", tracks)\n",
    "#print(\"number of tracks: \", len(tracks))\n",
    "homographyScores =  sorted(homographyScores, key=lambda k: k[\"percentage\"])\n",
    "#print(\"homographyScores: \", homographyScores)\n",
    "img1Idx = homographyScores[0]['idx1']\n",
    "img2Idx = homographyScores[0]['idx2']\n",
    "R, t = proj_matrix_for_initial_camera(img1Idx, img2Idx)\n",
    "#TODO Assume: img1Idx is the ref\n",
    "imagesModels[img1Idx]['projMat'] = get_reference_proj()\n",
    "imagesModels[img2Idx]['projMat'] = compute_proj(R,t)\n",
    "print(\"initial images: \", img1Idx, \" & \", img2Idx)\n",
    "print(\"1st two images --> Done\")\n",
    "#get tracks visible in the two images\n",
    "#print(\"img1Idx: \", img1Idx, \"img2Idx: \", img2Idx)\n",
    "#print(\"imagesModels[img1Idx]['tracksFeaturesIdx']: \", imagesModels[img1Idx]['tracksFeaturesIdx'])\n",
    "dicTracksFeaturesIdx1 = {k:v for k, v in imagesModels[img1Idx]['tracksFeaturesIdx']}\n",
    "dicTracksFeaturesIdx2 = {k:v for k, v in imagesModels[img2Idx]['tracksFeaturesIdx']}\n",
    "#print(\"dicTracksFeaturesIdx1: \",dicTracksFeaturesIdx1, \"dicTracksFeaturesIdx2: \", dicTracksFeaturesIdx2)\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "usedTracks = []\n",
    "usedImagesIdx = []\n",
    "usedImagesIdx.append(img1Idx) #TODO may remove it from images/deepcopy of images and remove it from there to modify the outer loop of add new camera\n",
    "usedImagesIdx.append(img2Idx)\n",
    "viewPts = []\n",
    "pts3D = []\n",
    "track3D = [None] * len(tracks)\n",
    "for track in dicTracksFeaturesIdx1.keys() & dicTracksFeaturesIdx2.keys():\n",
    "    usedTracks.append(track)\n",
    "    featureIdx1 = dicTracksFeaturesIdx1[track]\n",
    "    featureIdx2 = dicTracksFeaturesIdx2[track]\n",
    "    pt1 = imagesModels[img1Idx]['keyPts'][featureIdx1].pt\n",
    "    pt2 = imagesModels[img2Idx]['keyPts'][featureIdx2].pt\n",
    "    pts1.append(pt1)#TODO may be not needed\n",
    "    pts2.append(pt2)#TODO may be not needed\n",
    "    viewPts.append([(img1Idx,pt1), (img2Idx,pt2)])\n",
    "    \n",
    "    #triangulate tracks visible in the two images\n",
    "    triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[img1Idx][\"projMat\"],imagesModels[img2Idx][\"projMat\"],np.array(pt1),np.array(pt2))\n",
    "    pt3D = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :] #divide by t\n",
    "    track3D[track] = pt3D\n",
    "    #pts3D.extend(deepcopy(triangulatedPointsHomogeneous)) #TODO deepcopy is needed                                               \n",
    "    pts3D.append(pt3D) #TODO deepcopy is needed?\n",
    "'''\n",
    "TWo frame Bundle adjustment #here\n",
    "'''\n",
    "\"\"\"\n",
    "camMatricesEst = [imagesModels[img1Idx]['projMat'], imagesModels[img2Idx]['projMat']]\n",
    "XEst = []\n",
    "imgCoords = [pts1, pts2]\n",
    "PAdjusted, ptsX, reprojErrors = bundleAdjust_sparseLM(camMatricesEst, XEst, imgCoords)\n",
    "imagesModels[img1Idx]['projMat'] = \n",
    "imagesModels[img2Idx]['projMat'] = \n",
    "\"\"\"\n",
    "'''\n",
    "Add New Camera\n",
    "'''\n",
    "terminate = False #here to add TERMINATE_TH if condition\n",
    "while len(usedImagesIdx) < len(imagesModels) and not terminate:\n",
    "    #get the camera that observes the largest number of usedTracks\n",
    "    maxObservedTracksCnt = 0\n",
    "    selectedImgIdx = -1\n",
    "    ptsTmp = []\n",
    "    selectedpts3DTmp = []\n",
    "    pts = []\n",
    "    for imgIdx in range(len(images)):\n",
    "        if imgIdx in usedImagesIdx:\n",
    "            continue\n",
    "        observedTracksCnt = 0\n",
    "        ptsTmp = []\n",
    "        selectedpts3DTmp = []\n",
    "        dicTracksFeaturesIdx = {k:v for k, v in imagesModels[imgIdx]['tracksFeaturesIdx']}\n",
    "        for track in dicTracksFeaturesIdx.keys() & usedTracks: \n",
    "            observedTracksCnt += 1\n",
    "            featureIdx = dicTracksFeaturesIdx[track]\n",
    "            ptsTmp.append((imagesModels[imgIdx]['keyPts'][featureIdx].pt[0],imagesModels[imgIdx]['keyPts'][featureIdx].pt[1],1))\n",
    "            selectedpts3DTmp.append(track3D[track])\n",
    "        if observedTracksCnt > maxObservedTracksCnt:\n",
    "            maxObservedTracksCnt = observedTracksCnt\n",
    "            selectedImgIdx = imgIdx\n",
    "            pts = deepcopy(ptsTmp) #todo deepcopy needed?\n",
    "            selectedpts3D = deepcopy(selectedpts3DTmp) #todo deepcopy needed?\n",
    "    if selectedImgIdx != -1:\n",
    "        #print(\"parameters: \", np.transpose(np.array(pts)),np.transpose(np.array(selectedpts3D)))\n",
    "        #print(\"shape: \", np.transpose(np.array(pts)).shape, np.transpose(np.squeeze(np.array(selectedpts3D))).shape)\n",
    "        imagesModels[selectedImgIdx]['projMat'] = compute_P(np.transpose(np.array(pts)),np.transpose(np.squeeze(np.array(selectedpts3D))))#TODO check dimensions\n",
    "        #R,t,inliers = cv.solvePnPRansac(np.squeeze(np.array(selectedpts3D),np.array(pts),K) #todo hst5dem l inliers?\n",
    "        #print(\"solvePnPRansac: R:\", R, \" t: \", t)\n",
    "        usedImagesIdx.append(selectedImgIdx)\n",
    "    #Add points observed by the new camera\n",
    "    addedPt = None\n",
    "    addedPt3D = None\n",
    "    maxSeparationAngle = 0\n",
    "    separationAngle = 0\n",
    "    for trackIdx,featureIdx in imagesModels[selectedImgIdx]['tracksFeaturesIdx']:\n",
    "        for imgIdx, featureIdx2 in tracks[trackIdx]:\n",
    "            if imgIdx == selectedImgIdx:\n",
    "                continue\n",
    "            if imgIdx in usedImagesIdx and not trackIdx in usedTracks:\n",
    "                pt1 = imagesModels[selectedImgIdx]['keyPts'][featureIdx].pt\n",
    "                pt2 = imagesModels[imgIdx]['keyPts'][featureIdx2].pt\n",
    "                triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[selectedImgIdx][\"projMat\"],imagesModels[imgIdx][\"projMat\"],pt1,pt2)\n",
    "                separationAngle = compute_ray_angle(np.array([pt1[0],pt1[1],1]),np.array([pt2[0],pt2[1],1]),selectedImgIdx,imgIdx)\n",
    "                if separationAngle > maxSeparationAngle:\n",
    "                    maxSeparationAngle = separationAngle  \n",
    "                    addedPt3D = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :]#divide by t #TODO deepcopy is needed? #dimension #lmfrod hna one pt #[0] #VIP\n",
    "                    addedPt = [(selectedImgIdx,pt1),(imgIdx,pt2)]\n",
    "        if maxSeparationAngle >= RAY_ANGLE_TH:\n",
    "            track3D[trackIdx] = addedPt3D\n",
    "            pts3D.append(addedPt3D) \n",
    "            viewPts.append(addedPt)\n",
    "            usedTracks.append(trackIdx)\n",
    "    #bundle adjustment#here\n",
    "    print(\"image \",selectedImgIdx ,\"--> Done\")                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_proj_matrix():\n",
    "    for i in range(len(imagesModels)):\n",
    "        outputFile = open(datasetPath+\"projection2/projection\"+filesNames[i].split(\".png\")[0][-4:]+\".txt\",mode=\"w+\")\n",
    "        outputFile.write(\"CONTOUR\\n\")\n",
    "        pString = \"\"\n",
    "        for row in imagesModels[i][\"projMat\"]:\n",
    "            for col in row:\n",
    "                pString += str('{0:0.5f}'.format(col))+\" \"\n",
    "            pString += \"\\n\"\n",
    "        outputFile.write(pString)\n",
    "        outputFile.close()\n",
    "        \n",
    "write_proj_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv.decomposeProjectionMatrix)\n",
    "\"\"\"\n",
    "tracks : [] --> imgIdx,featureIdx\n",
    "usedTracks: [] --> indices in tracks\n",
    "traks3D: [] --> 3D point of each track in usedTracks\n",
    "usedImagesIdx: [] --> indices in imageModes, indices for images already used \"whose proj matrix is already calculated\"\n",
    "###\n",
    "#input to bundle adjustment\n",
    "pts3D: [] --> patches\n",
    "viewPts = [pts3DIdx] [] --> (imgIdx, pt) #frames \n",
    "###\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Projection Matrix for initialization images BOOK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def compute_P_from_essential(E):\n",
    "    \"\"\" Computes the second camera matrix (assuming P1 = [I 0])\n",
    "    from an essential matrix. Output is a list of four\n",
    "    possible camera matrices. \"\"\"\n",
    "    # make sure E is rank 2\n",
    "    U,S,V = linalg.svd(E)\n",
    "    if linalg.det(np.dot(U,V))<0:\n",
    "        V = -V\n",
    "    E = np.dot(U,np.dot(diag([1,1,0]),V))\n",
    "    # create matrices (Hartley p 258)\n",
    "    Z = skew([0,0,-1])\n",
    "    W = array([[0,-1,0],[1,0,0],[0,0,1]])\n",
    "    # return all four solutions\n",
    "    P2 = [vstack((np.dot(U,np.dot(W,V)).T,U[:,2])).T,\n",
    "    vstack((np.dot(U,np.dot(W,V)).T,-U[:,2])).T,\n",
    "    vstack((np.dot(U,np.dot(W.T,V)).T,U[:,2])).T,\n",
    "    vstack((np.dot(U,np.dot(W.T,V)).T,-U[:,2])).T]\n",
    "    return P2\n",
    "\n",
    "def compute_essential_from_F(F):\n",
    "    E = np.matmul(np.matmul(np.transpose(K),F),K)\n",
    "    return E\n",
    "\n",
    "def triangulate_point(x1,x2,P1,P2):\n",
    "    \"\"\" Point pair triangulation from least squares solution. \"\"\"\n",
    "    M = zeros((6,6))\n",
    "    M[:3,:4] = P1\n",
    "    M[3:,:4] = P2\n",
    "    M[:3,4] = -x1\n",
    "    M[3:,5] = -x2\n",
    "    U,S,V = linalg.svd(M)\n",
    "    X = V[-1,:4]\n",
    "    return X / X[3]\n",
    "\n",
    "def triangulate(x1,x2,P1,P2):\n",
    "    \"\"\" Two-view triangulation of points in x1,x2 (3*n homog. coordinates). \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    X = [ triangulate_point(x1[:,i],x2[:,i],P1,P2) for i in range(n)]\n",
    "    return array(X).T\n",
    "\n",
    "#Test\n",
    "\n",
    "# calibration\n",
    "K = np.array([[2394,0,932],[0,2398,628],[0,0,1]])\n",
    "#[I|0]\n",
    "P1 = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0]])\n",
    "\n",
    "# compute camera matrices (P2 will be list of four solutions)\n",
    "P2 = compute_P_from_essential(E)\n",
    "#From the list of camera matrices, we pick the one that has the most scene points\n",
    "#in front of both cameras after triangulation.\n",
    "\n",
    "# pick the solution with points in front of cameras\n",
    "ind = 0\n",
    "maxres = 0\n",
    "for i in range(4):\n",
    "# triangulate inliers and compute depth for each camera\n",
    "    X = triangulate(x1n[:,inliers],x2n[:,inliers],P1,P2[i])\n",
    "    d1 = dot(P1,X)[2]\n",
    "    d2 = dot(P2[i],X)[2]\n",
    "    if sum(d1>0)+sum(d2>0) > maxres:\n",
    "        maxres = sum(d1>0)+sum(d2>0)\n",
    "        ind = i\n",
    "        infront = (d1>0) & (d2>0)\n",
    "# triangulate inliers and remove points not in front of both cameras\n",
    "X = triangulate(x1n[:,inliers],x2n[:,inliers],P1,P2[ind])\n",
    "X = X[:,infront]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Homography BOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class HomographyRansacModel(object):\n",
    "    \"\"\" Class for testing homography fit with ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC\"\"\"\n",
    "    def __init__(self,debug=False):\n",
    "        self.debug = debug\n",
    "    def fit(self, data):\n",
    "        \"\"\" Fit homography to four selected correspondences. \"\"\"\n",
    "        # transpose to fit H_from_points()\n",
    "        data = data.T\n",
    "        # from points\n",
    "        fp = data[:3,:4]\n",
    "        # target points\n",
    "        tp = data[3:,:4]\n",
    "        # fit homography and return\n",
    "        return H_from_points(fp,tp)\n",
    "    def get_error( self, data, H):\n",
    "        \"\"\" Apply homography to all correspondences,\n",
    "        return error for each transformed point. \"\"\"\n",
    "        data = data.T\n",
    "        # from points\n",
    "        fp = data[:3]\n",
    "        # target points\n",
    "        tp = data[3:]\n",
    "        # transform fp\n",
    "        fp_transformed = dot(H,fp)\n",
    "        # normalize hom. coordinates\n",
    "        for i in range(3):\n",
    "            fp_transformed[i] /= fp_transformed[2]\n",
    "        # return error per point\n",
    "        return sqrt( sum((tp-fp_transformed)**2,axis=0) )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def H_from_ransac(fp,tp,model,maxiter=1000,match_theshold=10):\n",
    "    \"\"\" Robust estimation of homography H from point\n",
    "    correspondences using RANSAC (ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC).\n",
    "    input: fp,tp (3*n arrays) points in hom. coordinates. \"\"\"\n",
    "    import ransactmp\n",
    "    # group corresponding points\n",
    "    data = vstack((fp,tp))\n",
    "    # compute H and return\n",
    "    H,ransac_data = ransac.ransac(data.T,model,4,maxiter,match_theshold,10,return_all=True)\n",
    "    return H,ransac_data['inliers']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def make_homog(points):\n",
    "    \"\"\" Convert a set of points (dim*n array) to\n",
    "    homogeneous coordinates. \"\"\"\n",
    "    return vstack((points,ones((1,points.shape[1]))))\n",
    "# function to convert the matches to hom. points\n",
    "def convert_points(j):\n",
    "    ndx = matches[j].nonzero()[0]\n",
    "    fp =  make_homog(l[j+1][ndx,:2].T)\n",
    "    ndx2 = [int(matches[j][i]) for i in ndx]\n",
    "    tp =  make_homog(l[j][ndx2,:2].T)\n",
    "    return fp,tp\n",
    "#matches de 4 points bs walla??\n",
    "\n",
    "# estimate the homographies\n",
    "model = HomographyRansacModel()\n",
    "fp,tp = convert_points(1)\n",
    "H_12, Hinliears = H_from_ransac(fp,tp,model)[0]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}