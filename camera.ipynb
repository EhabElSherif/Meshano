{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from bisect import bisect_left\n",
    "from copy import copy, deepcopy\n",
    "import os\n",
    "from PIL import Image,ExifTags\n",
    "import sba\n",
    "import cmath\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_MIN_NUM_MATCHES = 100\n",
    "RAY_ANGLE_TH = 2 #degrees\n",
    "TERMINATE_TH = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>UTILS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Data/templeRing/\"\n",
    "filesNames = glob(datasetPath+'*.png') #TODO add jpg also\n",
    "filesNames = sorted(filesNames)\n",
    "images = [cv.imread(file) for file in filesNames]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Read EXIF Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_focal_length(imgIdx):\n",
    "    ccdWidths = {\n",
    "        \"samsung SM-A307FN\": 1.7#todo for test only #1/2.8\"\n",
    "    }\n",
    "    #img = Image.open('tryexif2.jpg')\n",
    "    img = Image.open(filesNames[imgIdx])\n",
    "    exif = {\n",
    "        ExifTags.TAGS[k]: v\n",
    "        for k, v in img._getexif().items()\n",
    "        if k in ExifTags.TAGS\n",
    "    }\n",
    "    print(exif)\n",
    "    #Get Focal Length\n",
    "    focalN, focalD = exif['FocalLength']\n",
    "    focalLen = float(focalN)/float(focalD)\n",
    "\n",
    "    imgWidth = exif['ExifImageWidth']\n",
    "    imgHeight = exif['ExifImageHeight']\n",
    "    #????????#TODO\n",
    "    if imgWidth < imgHeight:\n",
    "        imgWidth,imgHeight = imgHeight,imgWidth\n",
    "    #Get CCD Width\n",
    "    ccdWidth = 1.0\n",
    "    make = exif['Make']\n",
    "    model = exif['Model']\n",
    "    #Search in the DB\n",
    "    if (make + ' ' + model) in ccdWidths:\n",
    "        ccdWidth = ccdWidths[make + ' ' + model]\n",
    "        print(\"ccdWidth: \", ccdWidth)\n",
    "    #????????#TODO\n",
    "    else:\n",
    "        fplaneN, fplaneD = exif['FocalPlaneXResolution']\n",
    "        if fplaneN != 0:\n",
    "            ccdWidth = 25.4*float(imgWidth)*float(fplaneD)/float(fplaneN)\n",
    "            print(\"ccdWidth: \", ccdWidth)\n",
    "        else:\n",
    "            ccdWidth = 0\n",
    "\n",
    "    if (imgWidth == 0 or imgHeight == 0 or focalN == 0 or ccdWidth == 0):\n",
    "        print (\"focal length can't be determined\")\n",
    "    #Get Focal Length in Pixels\n",
    "    focalLen = imgWidth * (focalLen / ccdWidth)\n",
    "    print(\"focalLen: \", focalLen)\n",
    "    return focalLen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Intrinsic Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "imgHeight, imgWidth, _ = images[0].shape   \n",
    "#focalLen =  1.2 * max(imgHeight, imgWidth)\n",
    "focalLen = compute_focal_length(0)\n",
    "pp = (imgWidth/2, imgHeight/2)\n",
    "K = [[focalLen, 0, pp[0]],\n",
    "     [0, focalLen, pp[1]],\n",
    "     [0,     0,       1]]\n",
    "'''\n",
    "focalLen = 3310.400000\n",
    "imgHeight, imgWidth, _ = images[0].shape \n",
    "pp = (316.730000, 200.550000)\n",
    "'''\n",
    "K = [[3310.400000, 0.0, 316.730000],\n",
    "     [0.0, 3325.500000, 200.550000],\n",
    "     [0.0,     0.0,       1.0]]\n",
    "'''\n",
    "\"\"\"\n",
    "#dinasore\n",
    "K_global = [[3310.400000, 0.0, 316.730000],\n",
    "     [0.0, 3310.400000, 200.550000],\n",
    "     [0.0,     0.0,       1.0]]\n",
    "\"\"\"\n",
    "#temple\n",
    "K_global = [[1520.400000, 0.0, 302.320000],\n",
    "     [0.0, 1525.900000, 246.87000],\n",
    "     [0.0,     0.0,       1.0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sift():\n",
    "    print(\"SIFT\")\n",
    "    for imgIdx, img in enumerate(images):\n",
    "        #show_images([img],[\"img\"])\n",
    "        #gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        sift = cv.xfeatures2d.SIFT_create()\n",
    "        # find keypoints and descriptors with SIFT\n",
    "        kp,des = sift.detectAndCompute(img, None)\n",
    "        imageModel = {\n",
    "            \"keyPts\": kp,\n",
    "            \"descriptors\": des,\n",
    "            \"tracksFeaturesIdx\": [],\n",
    "            \"projMat\": np.zeros((3,4))\n",
    "        }\n",
    "        imagesModels.append(imageModel)\n",
    "        print(\"image : \",imgIdx,\" number of points:\",len(kp))\n",
    "        #draw\n",
    "        #imgKp = cv.drawKeypoints(gray,kp,copy(img),flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        #show_images([imgKp],[\"img\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ORB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_orb():\n",
    "    print(\"ORB\")\n",
    "    print(\"images\",len(images))\n",
    "    for imgIdx, img in enumerate(images):\n",
    "        #show_images([img],[\"img\"])\n",
    "        gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "        # find keypoints and descriptors with SIFT\n",
    "        orb = cv.ORB_create()\n",
    "        #kp = orb.detect(img,None)\n",
    "        kp,des = orb.detectAndCompute(img, None)\n",
    "        imageModel = {\n",
    "            \"keyPts\": kp,\n",
    "            \"descriptors\": des,\n",
    "            \"tracksFeaturesIdx\": [],\n",
    "            \"projMat\": np.zeros((3,4))\n",
    "        }\n",
    "        imagesModels.append(imageModel)\n",
    "        print(\"image : \",imgIdx,\" number of points:\",len(kp))\n",
    "        #draw\n",
    "        #imgKp = cv.drawKeypoints(gray,kp,copy(img),flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        #show_images([imgKp],[\"img\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_matches(idx1,idx2): #image indices\n",
    "    #Matching descriptors\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0 #TODO try:1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(imagesModels[idx1][\"descriptors\"], imagesModels[idx2][\"descriptors\"], k=2)\n",
    "    \n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    #Need to draw only good matches, so create a mask\n",
    "    matchesMask = [[0,0] for i in range(len(matches))]\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.6*n.distance:\n",
    "            pts2.append(imagesModels[idx2][\"keyPts\"][m.trainIdx].pt)\n",
    "            pts1.append(imagesModels[idx1][\"keyPts\"][m.queryIdx].pt) \n",
    "            \n",
    "            matchesIdx[idx1][idx2].append({'idx1': m.queryIdx, 'idx2':  m.trainIdx})\n",
    "            matchesIdx[idx2][idx1].append({'idx1': m.trainIdx, 'idx2': m.queryIdx})\n",
    "            matchesMask[i] = [1,0]\n",
    "    \n",
    "    #Draw Matches\n",
    "    draw_params = dict(matchColor = (0,255,0),\n",
    "                   singlePointColor = (255,0,0),\n",
    "                   matchesMask = matchesMask,\n",
    "                   flags = cv.DrawMatchesFlags_DEFAULT)\n",
    "    img3 = cv.drawMatchesKnn(images[idx1], imagesModels[idx1][\"keyPts\"], images[idx2], imagesModels[idx2][\"keyPts\"], matches,None,**draw_params)\n",
    "    #show_images([images[idx1], images[idx2], img3], [\"img1: idx \" + str(idx1), \"img2: idx \"+str(idx2), \"matches\"])\n",
    "    \n",
    "    return pts1, pts2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyList(object):\n",
    "    # bisect doesn't accept a key function, so we build the key into our sequence.\n",
    "    def __init__(self, l, key):\n",
    "        self.l = l\n",
    "        self.key = key\n",
    "    def __len__(self):\n",
    "        return len(self.l)\n",
    "    def __getitem__(self, index):\n",
    "        return self.key(self.l[index])\n",
    "    \n",
    "\n",
    "def get_matched_idx(matchesList, searchItem):\n",
    "    i = bisect_left(KeyList(matchesList, key=lambda k: k['idx1']), searchItem) \n",
    "    if i != len(matchesList) and matchesList[i]['idx1'] == searchItem: return matchesList[i]['idx2']\n",
    "    else: return -1\n",
    "    \n",
    "#Test \n",
    "'''\n",
    "matchesList = [{'idx1': 100, 'idx2': 5}, {'idx1': 2, 'idx2': 88}, {'idx1': 7, 'idx2': 5}, {'idx1': 9, 'idx2': 10}]\n",
    "print(matchesList[0]['idx1'])\n",
    "matchesList = sorted(matchesList, key=lambda k: k[\"idx1\"]) \n",
    "print(matchesList[0]['idx1'])\n",
    "print(get_matched_idx(matchesList, 2))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tracks():\n",
    "    #Sort matchesIdx #TODO #find faster way \n",
    "    for i in range(len(images)):\n",
    "        for j in range(len(images)):\n",
    "            matchesIdx[i][j] =  sorted(matchesIdx[i][j], key=lambda k: k[\"idx1\"])\n",
    "\n",
    "    for imgIdx in range(len(images)):\n",
    "        if len(matchesIdx[imgIdx]) == 0: continue #??TODO neighbors\n",
    "        flags = np.zeros(len(imagesModels[imgIdx]['keyPts']))\n",
    "        imagesModels[imgIdx]['keyFlags'] = flags\n",
    "\n",
    "    for imgIdx in range(len(images)):\n",
    "        if len(matchesIdx[imgIdx]) == 0: continue #??TODO neighbors\n",
    "        '''\n",
    "        BFS from each feature\n",
    "        images --> Nodes\n",
    "        Features --> Egdes\n",
    "        '''\n",
    "        for featureIdx in range(len(imagesModels[imgIdx]['keyPts'])):\n",
    "            #if the feature was visited\n",
    "            if imagesModels[imgIdx]['keyFlags'][featureIdx] == 1: continue\n",
    "            featuresTrack = []\n",
    "            featuresQueue = []\n",
    "            imageVisited = np.zeros(len(images))\n",
    "            #Mark the feature as visited\n",
    "            imagesModels[imgIdx]['keyFlags'][featureIdx] = 1\n",
    "            featuresTrack.append((imgIdx, featureIdx))\n",
    "            featuresQueue.append((imgIdx, featureIdx))\n",
    "            imageVisited[imgIdx] = 1\n",
    "            while not len(featuresQueue) == 0:\n",
    "                feature = featuresQueue.pop(0)\n",
    "                parImgIdx = feature[0]\n",
    "                parFeatureIdx = feature[1]\n",
    "                for childIdx in range(len(matchesIdx[parImgIdx])): #??TODO neighbors\n",
    "                    if imageVisited[childIdx] == 1: continue\n",
    "                    childFeatureIdx = get_matched_idx(matchesIdx[parImgIdx][childIdx], parFeatureIdx)# search for parFeatureIdx get the corresponding idx\n",
    "                    if childFeatureIdx == -1: continue\n",
    "                    if imagesModels[childIdx]['keyFlags'][childFeatureIdx] == 1: continue\n",
    "                    imagesModels[childIdx]['keyFlags'][childFeatureIdx] = 1\n",
    "                    featuresTrack.append((childIdx, childFeatureIdx))\n",
    "                    featuresQueue.append((childIdx, childFeatureIdx))\n",
    "                    imageVisited[childIdx] = 1\n",
    "            if len(featuresTrack) >= 2:\n",
    "                tracks.append(featuresTrack)\n",
    "    for trackIdx in range(len(tracks)):\n",
    "        for imgIdx,featureIdx in tracks[trackIdx]:\n",
    "            imagesModels[imgIdx]['tracksFeaturesIdx'].append((trackIdx, featureIdx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Projection Matrix For initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cam2 is the ref #TODO make sure?\n",
    "#tODO test on each pair of images\n",
    "def proj_matrix_for_initial_camera(imgIdx1, imgIdx2):\n",
    "    #TODO instead of the two for loops --> Store the value of pts\n",
    "    matchIndices1 = []\n",
    "    matchIndices2 = []\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "    for item in matchesIdx[imgIdx1][imgIdx2]:\n",
    "        matchIndices1.append(item['idx1'])\n",
    "        matchIndices2.append(item['idx2'])\n",
    "    \n",
    "    for i in range(len(matchIndices1)):\n",
    "        pts1.append(imagesModels[imgIdx1]['keyPts'][matchIndices1[i]].pt)\n",
    "        pts2.append(imagesModels[imgIdx2]['keyPts'][matchIndices2[i]].pt)\n",
    "\n",
    "    E, mask = cv.findEssentialMat(np.array(pts1), np.array(pts2), \n",
    "                             focal = focalLen,\n",
    "                             pp = (imgWidth/2, imgHeight/2), #TODO may be 0,0 or imgWidth/2, imgHeight/2\n",
    "                             method = cv.RANSAC, \n",
    "                             prob = 0.999, \n",
    "                             threshold = 1.0) \n",
    "\n",
    "    '''\n",
    "   ** threshold – Parameter used for RANSAC. \n",
    "    It is the maximum distance from a point to an epipolar line in pixels, beyond which the point is considered an outlier\n",
    "    and is not used for computing the final fundamental matrix.\n",
    "    It can be set to something like 1-3, depending on the accuracy of the point localization, image resolution, and the image noise.\n",
    "   ** prob – Parameter used for the RANSAC or LMedS methods only. \n",
    "    It specifies a desirable level of confidence (probability) that the estimated matrix is correct\n",
    "    '''\n",
    "    #retval:NumOfInliers\n",
    "    retval, R, t, mask, triangulatedPoints = cv.recoverPose(E, np.array(pts1), np.array(pts2), np.array(K_global), distanceThresh = 50) #TODO  # 2pass l mask l tal3 mn l essential?\n",
    "    return R, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO test\n",
    "def get_reference_proj(): \n",
    "    KR = np.matmul(get_intrinsic_matrix(),np.eye(3, dtype=int))\n",
    "    proj = np.zeros((3,4))\n",
    "    proj[:,:-1] = KR\n",
    "    return proj\n",
    "\n",
    "def compute_proj(R,t,k = None):\n",
    "    if k == None:\n",
    "        k = get_intrinsic_matrix()\n",
    "    Rt = np.append(R, t, axis=1) #TODO change np.append\n",
    "    p = np.matmul(k,Rt) \n",
    "    #p = p / p[2,3]\n",
    "    #print(\"[comput_p]debug shape: p = \", p)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Projection Matrix From point correspondence Book\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_P(x,X):\n",
    "    \"\"\" Compute camera matrix from pairs of\n",
    "    2D-3D correspondences (in homog. coordinates). \"\"\"\n",
    "    n = x.shape[1]\n",
    "    if X.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "        \n",
    "    # create matrix for DLT solution\n",
    "    M = np.zeros((3*n,12+n))\n",
    "    for i in range(n):\n",
    "        M[3*i,0:4] = X[:,i]\n",
    "        M[3*i+1,4:8] = X[:,i]\n",
    "        M[3*i+2,8:12] = X[:,i]\n",
    "        M[3*i:3*i+3,i+12] = -x[:,i]\n",
    "    U,S,V = np.linalg.svd(M)\n",
    "    p = V[-1,:12].reshape((3,4))\n",
    "    #p = p/ p[2,3]\n",
    "    #print(\"[comput_p]debug shape: p = \", p)\n",
    "    return p\n",
    "\n",
    "def compute_proj_from_rVec_tVec(rVec,t):\n",
    "    R,_ = cv.Rodrigues(rVec) \n",
    "    return compute_proj(R,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_intrinsic_matrix():\n",
    "    return K_global\n",
    "def get_K(focalLength, ppX, ppY):\n",
    "    k = [[focalLength, 0, ppX],\n",
    "         [0, focalLength, ppY],\n",
    "         [0,     0,       1]]\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorize_proj_matrix(P):\n",
    "    \"\"\" Factorize the camera matrix into K,R,t as P = K[R|t]. \"\"\"\n",
    "    # factor first 3*3 part\n",
    "    K1,R = linalg.rq(P[:,:3])\n",
    "    # make diagonal of K positive\n",
    "    T = np.diag(np.sign(np.diag(K1)))\n",
    "    if np.linalg.det(T) < 0:\n",
    "        T[1,1] *= -1\n",
    "    K1 = np.dot(K1,T)\n",
    "    R = np.dot(T,R) # T is its own inverse\n",
    "    t = np.dot(np.linalg.inv(K1),P[:,3])\n",
    "    return K1, R, t.reshape(3,1)\n",
    "\n",
    "\"\"\"\n",
    "#test\n",
    "P = get_reference_proj()\n",
    "print(factorize_proj_matrix(P))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ADD projmat = zeroes initialization\n",
    "def compute_ray_angle(pt1,pt2,imgIdx1,imgIdx2):\n",
    "    #k1,R1,t1,_,_,_,_ = cv.decomposeProjectionMatrix(imagesModels[imgIdx1]['projMat'])\n",
    "    #k2,R2,t2,_,_,_,_ = cv.decomposeProjectionMatrix(imagesModels[imgIdx2]['projMat'])\n",
    "    k1, R1,t1 = factorize_proj_matrix(imagesModels[imgIdx1]['projMat'])\n",
    "    k2,R2,t2 = factorize_proj_matrix(imagesModels[imgIdx2]['projMat'])\n",
    "    print(\"[compute_ray_angle][check K]\")\n",
    "    print(\" k1: \",  k1, \" k2: \", k2)\n",
    "    #Should have the same K --> check\n",
    "    #print(\"[check] k1:\\n\", k1, \"k2:\\n\", k2)\n",
    "    pt1Norm = np.matmul(np.linalg.inv(k1), pt1.reshape(3,1))\n",
    "    pt2Norm = np.matmul(np.linalg.inv(k2), pt2.reshape(3,1))\n",
    "    pt1Norm = pt1Norm/pt1Norm[2]\n",
    "    pt2Norm = pt2Norm/pt2Norm[2]\n",
    "    pt1Norm[2] = -1 #t\n",
    "    pt2Norm[2] = -1\n",
    "    \n",
    "    Rtrans1 = np.transpose(R1)\n",
    "    Rtrans2 = np.transpose(R2)\n",
    "    \n",
    "    Rpt1 = np.matmul(Rtrans1, pt1Norm)\n",
    "    Rpt2 = np.matmul(Rtrans2, pt2Norm)\n",
    "    \n",
    "    pW1 = Rpt1 + t1\n",
    "    pW2 = Rpt2 + t2\n",
    "    \n",
    "    ray1 = pW1 - t1\n",
    "    ray2 = pW2 - t2\n",
    "    dot = np.dot(np.squeeze(ray2), np.squeeze(ray1))\n",
    "    \n",
    "    magnitude = np.linalg.norm(ray1)*np.linalg.norm(ray2)\n",
    "    angle = np.math.acos(dot/magnitude)\n",
    "    angle = np.math.degrees(angle)\n",
    "    return angle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_cameras(imagesIdx):\n",
    "    #fx, u0, v0, ar, s   quaternion translation\n",
    "    outputFile = open(datasetPath+\"cameras.txt\", mode=\"w\")\n",
    "    for imgIdx in imagesIdx:\n",
    "        k, R, t = factorize_proj_matrix(imagesModels[imgIdx]['projMat'])\n",
    "        print(\"[write_cameras] \", \"K: \", k, \" R: \", R, \"t: \", t)\n",
    "        outputFile.write(str(k[0][0]))\n",
    "        outputFile.write(\" \")\n",
    "        outputFile.write(str(k[0][2]))\n",
    "        outputFile.write(\" \")\n",
    "        outputFile.write(str(k[1][2]))\n",
    "        outputFile.write(\" \")\n",
    "        outputFile.write(str(1)) #aspectRatio – f_y/f_x\n",
    "        outputFile.write(\" \")\n",
    "        outputFile.write(\"0.0\")\n",
    "        outputFile.write(\" \")\n",
    "        quat = sba.quaternions.quatFromRotationMatrix(R)\n",
    "        outputFile.write(str(quat.re))\n",
    "        outputFile.write(\" \")\n",
    "        outputFile.write(str(quat.i))\n",
    "        outputFile.write(\" \")\n",
    "        outputFile.write(str(quat.j))\n",
    "        outputFile.write(\" \")\n",
    "        outputFile.write(str(quat.k))\n",
    "        outputFile.write(\" \")\n",
    "        for element in t:\n",
    "            outputFile.write(str(element[0]))\n",
    "            outputFile.write(\" \")\n",
    "        outputFile.write('\\n')\n",
    "    outputFile.close()\n",
    "    \n",
    "def write_view_pts(viewPts, pts3D):\n",
    "    # X Y Z  nframes  frame0 x0 y0  frame1 x1 y1 ...\n",
    "    outputFile = open(datasetPath+\"pts.txt\", mode=\"w\")\n",
    "    for idx,pt in enumerate(pts3D):\n",
    "        for i in range (len(pt)-1):\n",
    "            outputFile.write(str(pt[i]))\n",
    "            outputFile.write(\" \")\n",
    "        outputFile.write(str(len(viewPts[idx])))\n",
    "        outputFile.write(\" \")\n",
    "        for frame in viewPts[idx]:\n",
    "            outputFile.write(str(imgIdxusedImagesIdxMap[frame[0]]))\n",
    "            outputFile.write(\" \")\n",
    "            outputFile.write(str(frame[1][0]))\n",
    "            outputFile.write(\" \")\n",
    "            outputFile.write(str(frame[1][1]))\n",
    "            outputFile.write(\" \")\n",
    "        outputFile.write(\"\\n\")\n",
    "        \n",
    "def set_cameras_after_bundle_adj(imagesIdx, cams):\n",
    "    #[fx1[0] cx1[1] cy1[2] ar1[3] s1[4] r21[5] r41[6] t11[7] t21 r61 qi1 qj1 qk1 tx1 ty1 tz1]\n",
    "    #fu[0], u0[1], v0[2], ar[3], s[4],  quaternion[5][6][7] translation[8][9][10]\"\n",
    "    cams = cams.camarray\n",
    "    for idx,cam in enumerate(cams):\n",
    "        #q0 =  1-(length of imag part)\n",
    "        q0 = 1-np.linalg.norm([cam[5],cam[6],cam[7]]) #todo not sure from equation\n",
    "        quat = sba.quaternions.Quaternion(q0,cam[5],cam[6],cam[7])\n",
    "        R = quat.asRotationMatrix()\n",
    "        t = [cam[8],cam[9],cam[10]]\n",
    "        k = get_K(cam[0], cam[1], cam[2])\n",
    "        imagesModels[imagesIdx[idx]]['projMat'] = compute_proj(np.array(R),np.array(t).reshape(3,1), k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagesModels = []\n",
    "matchesIdx = [[list() for x in range(len(images))] for y in range(len(images))] \n",
    "tracks = []\n",
    "compute_sift()\n",
    "#compute_orb()\n",
    "print(\"Number of images: \", len(imagesModels))\n",
    "#matchScores = np.zeros((len(images), len(images))) #TODO compute from it the INIT_MIN_NUM_MATCHES\n",
    "homographyScores = []\n",
    "#model = RansacModel()\n",
    "for i in range(len(images)):\n",
    "    for j in range(i+1, len(images)):\n",
    "        pts1, pts2 = compute_matches(i,j)\n",
    "        #matchScores[i][j] = len(pts1)\n",
    "        #matchScores[j][i] = len(pts1)\n",
    "        #print(\"No. of matched features between \", str(i) , \"&\", str(j),len(pts1))\n",
    "        '''\n",
    "        #Compute Fundamental matrix\n",
    "        #Add \"t\" to every point\n",
    "        pts1Homogenous = cv.convertPointsToHomogeneous(np.float32(pts1)).reshape((-1,3))\n",
    "        pts2Homogenous = cv.convertPointsToHomogeneous(np.float32(pts2)).reshape((-1,3))\n",
    "        pts1Homogenous = np.transpose(pts1Homogenous)\n",
    "        pts2Homogenous = np.transpose(pts2Homogenous)\n",
    "        if(len(pts1) < 8):\n",
    "            print(\"Couldn't find good 8 matches to compute Fundamental matrix\")\n",
    "        else:\n",
    "            F,inliers = F_from_ransac(pts1Homogenous,pts2Homogenous,model,maxiter=2048,match_theshold=1)\n",
    "            print(\"Fundamental Matrix between \", str(i) , \"&\", str(j), F)\n",
    "            #tODO refine matches\n",
    "        '''\n",
    "        \n",
    "        pts1 = np.float32(pts1).reshape(-1,1,2)\n",
    "        pts2 = np.float32(pts2).reshape(-1,1,2)\n",
    "        if len(pts1) < 4:\n",
    "            l = 1 #remove this line\n",
    "            #print(\"Couldn't find good 4 matches to compute Homograhy matrix\")\n",
    "        else:  \n",
    "            H, mask = cv.findHomography(pts1, pts2, cv.RANSAC, 0.004*max(imgHeight, imgWidth))\n",
    "            HinliersNum = list(mask).count(1)\n",
    "            #print(\"HinliersNum: \", HinliersNum)\n",
    "            if len(pts1) >= INIT_MIN_NUM_MATCHES:\n",
    "                homographyScores.append({\"idx1\":i, \"idx2\": j, \"percentage\": HinliersNum/len(pts1)})\n",
    "                \n",
    "compute_tracks()\n",
    "#print(\"tracks: \", tracks)\n",
    "#print(\"number of tracks: \", len(tracks))\n",
    "homographyScores =  sorted(homographyScores, key=lambda k: k[\"percentage\"])\n",
    "#print(\"homographyScores: \", homographyScores)\n",
    "img1Idx = homographyScores[0]['idx1']\n",
    "img2Idx = homographyScores[0]['idx2']\n",
    "R, t = proj_matrix_for_initial_camera(img1Idx, img2Idx)\n",
    "#TODO Assume: img1Idx is the ref\n",
    "imagesModels[img1Idx]['projMat'] = get_reference_proj()\n",
    "imagesModels[img2Idx]['projMat'] = compute_proj(R,t)\n",
    "print(\"=========Debug1============\")\n",
    "p = compute_proj(R,t)\n",
    "p = p\n",
    "k1,R1,t1 = factorize_proj_matrix(p)\n",
    "print(\"P = \", p, \"type\", type(p), \"shape: \", p.shape)\n",
    "print(\"orignal k: \", K_global)\n",
    "print(\"k: \", k1) #lazm division\n",
    "print(\"orignal R: \", R)\n",
    "print(\"R: \", R1)\n",
    "print(\"orignal t: \", t)\n",
    "print(\"t: \", t1)\n",
    "print(\"=========Done Debug1========\")\n",
    "print(\"initial images: \", img1Idx, \" & \", img2Idx)\n",
    "print(\"1st two images --> Done\")\n",
    "#get tracks visible in the two images\n",
    "#print(\"img1Idx: \", img1Idx, \"img2Idx: \", img2Idx)\n",
    "#print(\"imagesModels[img1Idx]['tracksFeaturesIdx']: \", imagesModels[img1Idx]['tracksFeaturesIdx'])\n",
    "dicTracksFeaturesIdx1 = {k:v for k, v in imagesModels[img1Idx]['tracksFeaturesIdx']}\n",
    "dicTracksFeaturesIdx2 = {k:v for k, v in imagesModels[img2Idx]['tracksFeaturesIdx']}\n",
    "#print(\"dicTracksFeaturesIdx1: \",dicTracksFeaturesIdx1, \"dicTracksFeaturesIdx2: \", dicTracksFeaturesIdx2)\n",
    "pts1 = []\n",
    "pts2 = []\n",
    "usedTracks = []\n",
    "usedImagesIdx = []\n",
    "imgIdxusedImagesIdxMap = [None]*len(imagesModels)\n",
    "usedImagesIdx.append(img1Idx) #TODO may remove it from images/deepcopy of images and remove it from there to modify the outer loop of add new camera\n",
    "usedImagesIdx.append(img2Idx)\n",
    "imgIdxusedImagesIdxMap[img1Idx] = 0\n",
    "imgIdxusedImagesIdxMap[img2Idx] = 1\n",
    "viewPts = []\n",
    "pts3D = []\n",
    "track3D = [None] * len(tracks)\n",
    "pts3DIdx = 0\n",
    "for track in dicTracksFeaturesIdx1.keys() & dicTracksFeaturesIdx2.keys():\n",
    "    usedTracks.append(track)\n",
    "    featureIdx1 = dicTracksFeaturesIdx1[track]\n",
    "    featureIdx2 = dicTracksFeaturesIdx2[track]\n",
    "    pt1 = imagesModels[img1Idx]['keyPts'][featureIdx1].pt\n",
    "    pt2 = imagesModels[img2Idx]['keyPts'][featureIdx2].pt\n",
    "    pts1.append(pt1)#TODO may be not needed\n",
    "    pts2.append(pt2)#TODO may be not needed\n",
    "    viewPts.append([(img1Idx,pt1), (img2Idx,pt2)])\n",
    "    \n",
    "    #triangulate tracks visible in the two images\n",
    "    triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[img1Idx][\"projMat\"],imagesModels[img2Idx][\"projMat\"],np.array(pt1),np.array(pt2))\n",
    "    pt3D = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :] #divide by t\n",
    "    pt3D = np.squeeze(pt3D)\n",
    "    track3D[track] = pts3DIdx \n",
    "    #pts3D.extend(deepcopy(triangulatedPointsHomogeneous)) #TODO deepcopy is needed                                               \n",
    "    pts3D.append(pt3D) #TODO deepcopy is needed?\n",
    "    pts3DIdx += 1\n",
    "\n",
    "print(\"============Debug 1'=====================\")\n",
    "retval, rvec, tvec, inliers = cv.solvePnPRansac(np.ascontiguousarray(np.squeeze(np.array(pts3D))[:,:-1]).reshape(len(pts3D),1,3), np.array(pts2), np.array(K_global), np.zeros((5,1)), flags = cv.SOLVEPNP_EPNP, iterationsCount = 400, reprojectionError = 0.004*max(imgHeight, imgWidth), confidence=0.9999)#tODO l mfrood 2st5dem l inliers?\n",
    "rvec_matrix = cv.Rodrigues(rvec)[0]\n",
    "proj_matrix = np.hstack((rvec_matrix, tvec))\n",
    "print(\"original proj matrix: \",imagesModels[img2Idx]['projMat'])\n",
    "print(\"proj_matrix: \", proj_matrix)\n",
    "k1,R1,t1 = factorize_proj_matrix(proj_matrix)\n",
    "print(\"orignal k: \", K_global)\n",
    "print(\"k: \", k1) #lazm division\n",
    "print(\"orignal R: \", R)\n",
    "print(\"R: \", R1)\n",
    "print(\"orignal t: \", t)\n",
    "print(\"t / norm: \", t1/np.linalg.norm(t1))\n",
    "print(\"============Done Debug 1'=====================\")\n",
    "\n",
    "''''\n",
    "TWo frame Bundle adjustment\n",
    "'''\n",
    "write_cameras(usedImagesIdx)\n",
    "write_view_pts(viewPts, pts3D)\n",
    "cameras = sba.Cameras.fromTxt(datasetPath+'cameras.txt')\n",
    "points = sba.Points.fromTxt(datasetPath+'pts.txt',cameras.ncameras)\n",
    "options = sba.options.Options.fromInput(cameras,points)\n",
    "options.motstruct = sba.options.OPTS_MOTSTRUCT\n",
    "options.camera = sba.options.OPTS_CAMS_NODIST\n",
    "newCams, newPts, info = sba.SparseBundleAdjust(cameras,points,options)\n",
    "set_cameras_after_bundle_adj(usedImagesIdx, newCams)\n",
    "#pts3D = newpts.B.tolist()\n",
    "newPts3D = np.ones((len(pts3D),4))\n",
    "newPts3D[:,:-1] = newPts.B #deepcopy needed?\n",
    "pts3D = list(newPts3D)\n",
    "'''\n",
    "Add New Camera\n",
    "'''\n",
    "terminate = False #here to add TERMINATE_TH if condition\n",
    "while len(usedImagesIdx) < len(imagesModels) and not terminate:\n",
    "    print(\"[Adding new camera...]\")\n",
    "    #get the camera that observes the largest number of usedTracks\n",
    "    maxObservedTracksCnt = 0\n",
    "    selectedImgIdx = -1\n",
    "    ptsTmp = []\n",
    "    selectedpts3DTmp = []\n",
    "    pts = []\n",
    "    for imgIdx in range(len(images)):\n",
    "        if imgIdx in usedImagesIdx:\n",
    "            continue\n",
    "        observedTracksCnt = 0\n",
    "        ptsTmp = []\n",
    "        selectedpts3DTmp = []\n",
    "        dicTracksFeaturesIdx = {k:v for k, v in imagesModels[imgIdx]['tracksFeaturesIdx']}\n",
    "        for track in dicTracksFeaturesIdx.keys() & usedTracks: \n",
    "            observedTracksCnt += 1\n",
    "            featureIdx = dicTracksFeaturesIdx[track]\n",
    "            ptsTmp.append((imagesModels[imgIdx]['keyPts'][featureIdx].pt[0],imagesModels[imgIdx]['keyPts'][featureIdx].pt[1],1))\n",
    "            selectedpts3DTmp.append(pts3D[track3D[track]])\n",
    "        if observedTracksCnt > maxObservedTracksCnt:\n",
    "            maxObservedTracksCnt = observedTracksCnt\n",
    "            selectedImgIdx = imgIdx\n",
    "            pts = deepcopy(ptsTmp) #todo deepcopy needed?\n",
    "            selectedpts3D = deepcopy(selectedpts3DTmp) #todo deepcopy needed?\n",
    "    if maxObservedTracksCnt < TERMINATE_TH:\n",
    "        terminate = True\n",
    "        break\n",
    "    if selectedImgIdx != -1:\n",
    "        #print(\"parameters: \", np.transpose(np.array(pts)),np.transpose(np.array(selectedpts3D)))\n",
    "        #print(\"shape: \", np.transpose(np.array(pts)).shape, np.transpose(np.squeeze(np.array(selectedpts3D))).shape)\n",
    "        imagesModels[selectedImgIdx]['projMat'] = compute_P(np.transpose(np.array(pts)),np.transpose(np.squeeze(np.array(selectedpts3D))))#TODO check dimensions\n",
    "        print(\"=================Debug2'========================\")\n",
    "        print(\"debug pnp: p =\", imagesModels[selectedImgIdx]['projMat']/imagesModels[selectedImgIdx]['projMat'][2,3],\"type: \", type(imagesModels[selectedImgIdx]['projMat']), \" shape: \", imagesModels[selectedImgIdx]['projMat'].shape)\n",
    "        print(\"original K: \", np.array(K_global,dtype=np.float32))\n",
    "        output = factorize_proj_matrix(imagesModels[selectedImgIdx]['projMat']/imagesModels[selectedImgIdx]['projMat'][2,3])\n",
    "        print(\"k from factorize: \", output)\n",
    "        print(\"compute_proj: \",compute_proj(output[1],output[2],list(output[0])))\n",
    "        print(\"=================Done Debug========================\")\n",
    "        #print(\"debug compute_p: p = \", imagesModels[selectedImgIdx]['projMat']/ imagesModels[selectedImgIdx]['projMat'][2,3]) \n",
    "        ##################################\n",
    "        #print(\"debug: np.array(selectedpts3D,dtype=np.float32): \", np.ascontiguousarray(np.squeeze(np.array(selectedpts3D,dtype=np.float32))[:,:-1]).reshape(len(selectedpts3D),1,3), \"np.array(pts,dtype=np.float32)[:,:-1]: \", np.ascontiguousarray(np.array(pts,dtype=np.float32)[:,:-1]).reshape(len(pts),1,2), \"np.array(K_global,dtype=np.float32): \", type(np.array(K_global,dtype=np.float32)))\n",
    "        retval, rvec, tvec, inliers = cv.solvePnPRansac(np.ascontiguousarray(np.squeeze(np.array(selectedpts3D))[:,:-1]).reshape(len(selectedpts3D),1,3), np.ascontiguousarray(np.array(pts)[:,:-1]).reshape(len(pts),1,2), np.array(K_global), np.zeros((5,1)), flags = cv.SOLVEPNP_EPNP, iterationsCount = 400, reprojectionError = 0.004*max(imgHeight, imgWidth), confidence=0.9999)#ODO l mfrood 2st5dem l inliers\n",
    "        if not retval:\n",
    "            print(\"Fail to get camera \" ,selectedImgIdx ,\" extrinsic parameters \")\n",
    "            usedImagesIdx.append(selectedImgIdx)\n",
    "            continue\n",
    "        rvec_matrix = cv.Rodrigues(rvec)[0]\n",
    "        proj_matrix = np.hstack((rvec_matrix, tvec))\n",
    "        imagesModels[selectedImgIdx]['projMat'] = proj_matrix\n",
    "        print(\"=================Debug2========================\")\n",
    "        print(\"PNP return value: \", retval)\n",
    "        print(\"debug pnp: p =\", proj_matrix,\"type: \", type(proj_matrix), \" shape: \", proj_matrix.shape)\n",
    "        print(\"original K: \", np.array(K_global,dtype=np.float32))\n",
    "        output = factorize_proj_matrix(proj_matrix)\n",
    "        print(\"k from factorize: \", output)\n",
    "        print(\"t from factorize normalized: \", output[2]/np.linalg.norm(output[2]))\n",
    "        print(\"k  shape: \", output[0].shape)\n",
    "        print(\"k from factorize divided k[2,3]: \", output[0]/output[0][2,2])\n",
    "        print(\"k from factorize * norm t \", output[0]*np.linalg.norm(output[2]))\n",
    "        print(\"compute_proj: \",compute_proj(output[1],output[2],list(output[0])))\n",
    "        print(\"get the mul between original k and k: \", np.matmul(list(output[0]), np.linalg.inv(K_global)))\n",
    "        print(\"=================Done Debug========================\")\n",
    "        #########################\n",
    "        usedImagesIdx.append(selectedImgIdx)\n",
    "        imgIdxusedImagesIdxMap[selectedImgIdx] = len(usedImagesIdx)-1\n",
    "    #Add points observed by the new camera\n",
    "    print(\"[Add points observed by the new camera]\")\n",
    "    addedPt = None\n",
    "    addedPt3D = None\n",
    "    maxSeparationAngle = 0\n",
    "    separationAngle = 0\n",
    "    pts3DIdx = 0\n",
    "    for trackIdx,featureIdx in imagesModels[selectedImgIdx]['tracksFeaturesIdx']:\n",
    "        for imgIdx, featureIdx2 in tracks[trackIdx]:\n",
    "            if imgIdx == selectedImgIdx:\n",
    "                continue\n",
    "            if imgIdx in usedImagesIdx and not trackIdx in usedTracks:\n",
    "                pt1 = imagesModels[selectedImgIdx]['keyPts'][featureIdx].pt\n",
    "                pt2 = imagesModels[int(imgIdx)]['keyPts'][int(featureIdx2)].pt\n",
    "                triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[selectedImgIdx][\"projMat\"],imagesModels[imgIdx][\"projMat\"],pt1,pt2)\n",
    "                separationAngle = compute_ray_angle(np.array([pt1[0],pt1[1],1]),np.array([pt2[0],pt2[1],1]),selectedImgIdx,imgIdx)\n",
    "                if separationAngle > maxSeparationAngle:\n",
    "                    maxSeparationAngle = separationAngle  \n",
    "                    addedPt3D = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :]#divide by t #TODO deepcopy is needed? #dimension #lmfrod hna one pt #[0] #VIP\n",
    "                    addedPt3D = np.squeeze(addedPt3D)\n",
    "                    addedPt = [(selectedImgIdx,pt1),(imgIdx,pt2)]\n",
    "        if maxSeparationAngle >= RAY_ANGLE_TH:\n",
    "            track3D[trackIdx] = pts3DIdx\n",
    "            pts3D.append(addedPt3D) \n",
    "            viewPts.append(addedPt)\n",
    "            usedTracks.append(trackIdx)\n",
    "            pts3DIdx += 1\n",
    "    print(\"image \",selectedImgIdx ,\"--> Done\")      \n",
    "    #bundle adjustment\n",
    "    print(\"[Bundle Adjustment]\")\n",
    "    write_cameras(usedImagesIdx)\n",
    "    write_view_pts(viewPts, pts3D)\n",
    "    \n",
    "    cameras = sba.Cameras.fromTxt(datasetPath+'cameras.txt')\n",
    "    points = sba.Points.fromTxt(datasetPath+'pts.txt',cameras.ncameras)\n",
    "    options = sba.options.Options.fromInput(cameras,points)\n",
    "    options.motstruct = sba.options.OPTS_MOTSTRUCT\n",
    "    options.camera = sba.options.OPTS_CAMS_NODIST\n",
    "    newCams, newPts, info = sba.SparseBundleAdjust(cameras,points,options)\n",
    "    set_cameras_after_bundle_adj(usedImagesIdx, newCams)\n",
    "    newPts3D = np.ones((len(pts3D),4))\n",
    "\n",
    "    newPts3D[:,:-1] = newPts.B #deepcopy needed?\n",
    "    pts3D = list(newPts3D)\n",
    "print(\"[Main] Done executing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(imagesModels)):\n",
    "    print(imagesModels[i]['projMat'])\n",
    "def write_proj_matrix():\n",
    "    for i in range(len(imagesModels)):\n",
    "        outputFile = open(datasetPath+\"projection2/projection\"+filesNames[i].split(\".png\")[0][-4:]+\".txt\",mode=\"w+\")\n",
    "        outputFile.write(\"CONTOUR\\n\")\n",
    "        pString = \"\"\n",
    "        for row in imagesModels[i][\"projMat\"]:\n",
    "            for col in row:\n",
    "                pString += str(col)+\" \"\n",
    "            pString += \"\\n\"\n",
    "        outputFile.write(pString)\n",
    "        outputFile.close()\n",
    "        \n",
    "write_proj_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cv.solvePnPRansac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tracks : [] --> imgIdx,featureIdx\n",
    "usedTracks: [] --> indices in tracks\n",
    "traks3D: [] --> 3D point of each track in usedTracks\n",
    "usedImagesIdx: [] --> indices in imageModes, indices for images already used \"whose proj matrix is already calculated\"\n",
    "###\n",
    "#input to bundle adjustment\n",
    "pts3D: [] --> patches\n",
    "viewPts = [pts3DIdx] [] --> (imgIdx, pt) #frames \n",
    "###\n",
    "\n",
    "\"\"\"\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Projection Matrix for initialization images BOOK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def compute_P_from_essential(E):\n",
    "    \"\"\" Computes the second camera matrix (assuming P1 = [I 0])\n",
    "    from an essential matrix. Output is a list of four\n",
    "    possible camera matrices. \"\"\"\n",
    "    # make sure E is rank 2\n",
    "    U,S,V = linalg.svd(E)\n",
    "    if linalg.det(np.dot(U,V))<0:\n",
    "        V = -V\n",
    "    E = np.dot(U,np.dot(diag([1,1,0]),V))\n",
    "    # create matrices (Hartley p 258)\n",
    "    Z = skew([0,0,-1])\n",
    "    W = array([[0,-1,0],[1,0,0],[0,0,1]])\n",
    "    # return all four solutions\n",
    "    P2 = [vstack((np.dot(U,np.dot(W,V)).T,U[:,2])).T,\n",
    "    vstack((np.dot(U,np.dot(W,V)).T,-U[:,2])).T,\n",
    "    vstack((np.dot(U,np.dot(W.T,V)).T,U[:,2])).T,\n",
    "    vstack((np.dot(U,np.dot(W.T,V)).T,-U[:,2])).T]\n",
    "    return P2\n",
    "\n",
    "def compute_essential_from_F(F):\n",
    "    E = np.matmul(np.matmul(np.transpose(K),F),K)\n",
    "    return E\n",
    "\n",
    "def triangulate_point(x1,x2,P1,P2):\n",
    "    \"\"\" Point pair triangulation from least squares solution. \"\"\"\n",
    "    M = zeros((6,6))\n",
    "    M[:3,:4] = P1\n",
    "    M[3:,:4] = P2\n",
    "    M[:3,4] = -x1\n",
    "    M[3:,5] = -x2\n",
    "    U,S,V = linalg.svd(M)\n",
    "    X = V[-1,:4]\n",
    "    return X / X[3]\n",
    "\n",
    "def triangulate(x1,x2,P1,P2):\n",
    "    \"\"\" Two-view triangulation of points in x1,x2 (3*n homog. coordinates). \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    X = [ triangulate_point(x1[:,i],x2[:,i],P1,P2) for i in range(n)]\n",
    "    return array(X).T\n",
    "\n",
    "#Test\n",
    "\n",
    "# calibration\n",
    "K = np.array([[2394,0,932],[0,2398,628],[0,0,1]])\n",
    "#[I|0]\n",
    "P1 = np.array([[1,0,0,0],[0,1,0,0],[0,0,1,0]])\n",
    "\n",
    "# compute camera matrices (P2 will be list of four solutions)\n",
    "P2 = compute_P_from_essential(E)\n",
    "#From the list of camera matrices, we pick the one that has the most scene points\n",
    "#in front of both cameras after triangulation.\n",
    "\n",
    "# pick the solution with points in front of cameras\n",
    "ind = 0\n",
    "maxres = 0\n",
    "for i in range(4):\n",
    "# triangulate inliers and compute depth for each camera\n",
    "    X = triangulate(x1n[:,inliers],x2n[:,inliers],P1,P2[i])\n",
    "    d1 = dot(P1,X)[2]\n",
    "    d2 = dot(P2[i],X)[2]\n",
    "    if sum(d1>0)+sum(d2>0) > maxres:\n",
    "        maxres = sum(d1>0)+sum(d2>0)\n",
    "        ind = i\n",
    "        infront = (d1>0) & (d2>0)\n",
    "# triangulate inliers and remove points not in front of both cameras\n",
    "X = triangulate(x1n[:,inliers],x2n[:,inliers],P1,P2[ind])\n",
    "X = X[:,infront]\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Homography BOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "class HomographyRansacModel(object):\n",
    "    \"\"\" Class for testing homography fit with ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC\"\"\"\n",
    "    def __init__(self,debug=False):\n",
    "        self.debug = debug\n",
    "    def fit(self, data):\n",
    "        \"\"\" Fit homography to four selected correspondences. \"\"\"\n",
    "        # transpose to fit H_from_points()\n",
    "        data = data.T\n",
    "        # from points\n",
    "        fp = data[:3,:4]\n",
    "        # target points\n",
    "        tp = data[3:,:4]\n",
    "        # fit homography and return\n",
    "        return H_from_points(fp,tp)\n",
    "    def get_error( self, data, H):\n",
    "        \"\"\" Apply homography to all correspondences,\n",
    "        return error for each transformed point. \"\"\"\n",
    "        data = data.T\n",
    "        # from points\n",
    "        fp = data[:3]\n",
    "        # target points\n",
    "        tp = data[3:]\n",
    "        # transform fp\n",
    "        fp_transformed = dot(H,fp)\n",
    "        # normalize hom. coordinates\n",
    "        for i in range(3):\n",
    "            fp_transformed[i] /= fp_transformed[2]\n",
    "        # return error per point\n",
    "        return sqrt( sum((tp-fp_transformed)**2,axis=0) )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def H_from_ransac(fp,tp,model,maxiter=1000,match_theshold=10):\n",
    "    \"\"\" Robust estimation of homography H from point\n",
    "    correspondences using RANSAC (ransac.py from\n",
    "    http://www.scipy.org/Cookbook/RANSAC).\n",
    "    input: fp,tp (3*n arrays) points in hom. coordinates. \"\"\"\n",
    "    import ransactmp\n",
    "    # group corresponding points\n",
    "    data = vstack((fp,tp))\n",
    "    # compute H and return\n",
    "    H,ransac_data = ransac.ransac(data.T,model,4,maxiter,match_theshold,10,return_all=True)\n",
    "    return H,ransac_data['inliers']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def make_homog(points):\n",
    "    \"\"\" Convert a set of points (dim*n array) to\n",
    "    homogeneous coordinates. \"\"\"\n",
    "    return vstack((points,ones((1,points.shape[1]))))\n",
    "# function to convert the matches to hom. points\n",
    "def convert_points(j):\n",
    "    ndx = matches[j].nonzero()[0]\n",
    "    fp =  make_homog(l[j+1][ndx,:2].T)\n",
    "    ndx2 = [int(matches[j][i]) for i in ndx]\n",
    "    tp =  make_homog(l[j][ndx2,:2].T)\n",
    "    return fp,tp\n",
    "#matches de 4 points bs walla??\n",
    "\n",
    "# estimate the homographies\n",
    "model = HomographyRansacModel()\n",
    "fp,tp = convert_points(1)\n",
    "H_12, Hinliears = H_from_ransac(fp,tp,model)[0]\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}