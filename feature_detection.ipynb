{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from copy import copy,deepcopy\n",
    "from optical_center import getOpticalCenter\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_nth_maximum(arr,n):\n",
    "    uniqueValues = list(arr.flatten())\n",
    "    uniqueValues.sort()\n",
    "    if len(uniqueValues) < n:\n",
    "        return uniqueValues[0]\n",
    "    return uniqueValues[len(uniqueValues)-n]\n",
    "    # sortedmatrix.sort()\n",
    "    # # print(arr.shape)\n",
    "    # if sortedmatrix.size == 0:\n",
    "    #     return -1\n",
    "    # return sortedmatrix[0 if n > sortedmatrix.size else -n] \n",
    "\n",
    "def get_optical_axis(projectionMat):\n",
    "    return np.array([projectionMat[2][0],projectionMat[2][1],projectionMat[2][2],0])\n",
    "\n",
    "def outside_image_boundry(yCoord,xCoord):\n",
    "    return (xCoord < 0 or yCoord < 0 or xCoord >= len(imagesModels[0][\"image\"][0]) or yCoord >= len(imagesModels[0][\"image\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Data/dinoSparseRing/\"\n",
    "ß1 = 2\n",
    "ß2 = 32\n",
    "µ = 5       # the projection of one of its edges into R(p) is parallel to the image rows, and the smallest axis-aligned square containingits image covers a µ × µ pixel^2 area\n",
    "# We associate with p a reference image R(p),the images S(p) where p should be visible and the images T(p) where it is truly found \n",
    "gamma = 3\n",
    "\n",
    "cosMinAngle = np.math.cos(np.math.radians(20))\n",
    "cosMaxAngle = np.math.cos(np.math.radians(60))\n",
    "patchGridSize = 5\n",
    "'''\n",
    "patchModel = {\n",
    "    \"R\":None,\n",
    "    \"S\":set,\n",
    "    \"T\":set\n",
    "}\n",
    "# The cell C(i, j) keeps track of two different sets Qt(i, j) and Qf(i, j)\n",
    "cell = {\n",
    "    \"Qt\":list(),\n",
    "    \"Qf\":list()\n",
    "}\n",
    "# We associate with each image I a regular grid of β1×β1 pixel^2 cells\n",
    "imageModel = {\n",
    "    \"image\":None,\n",
    "    \"projMat\":None,\n",
    "    \"optCenter\":None,\n",
    "    \"grid\":None,\n",
    "    \"dog\":None,\n",
    "    \"harris\":None,\n",
    "    \"sparseDog\":None,\n",
    "    \"sparseHarris\":None,\n",
    "    \"dogPositions\":None,\n",
    "    \"harrisPositions\":None\n",
    "}\n",
    "'''\n",
    "cell = {\n",
    "    \"Qt\":list(),\n",
    "    \"Qf\":list()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image model from a given path\n",
    "def init_imgs(datasetPath):\n",
    "    # Read imgs\n",
    "    filesNames = glob(datasetPath+'*.png')\n",
    "    filesNames = sorted(filesNames)\n",
    "    # print(filesNames)\n",
    "    imgs = [cv.imread(file) for file in filesNames]\n",
    "    # imgs = [cv.rotate(cv.imread(file),cv.ROTATE_90_COUNTERCLOCKWISE) for file in glob(datasetPath+'*.png')]\n",
    "\n",
    "    # Construct corresponding image grid\n",
    "    #grids = [np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)]) for img in imgs]\n",
    "    grids = list()\n",
    "    for img in imgs:\n",
    "        grid = np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)])\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                \n",
    "                cell1={\n",
    "                    \"Qt\":list(),\n",
    "                    \"Qf\":list()\n",
    "                }\n",
    "                \n",
    "                grid[i][j] = cell1\n",
    "        grids.append(grid)\n",
    "        \n",
    "    return imgs,grids\n",
    "    \n",
    "# Read camera parameters and return the projection matrices for all pictures\n",
    "def read_parameters_file(datasetPath):\n",
    "    inputFile = open(datasetPath+\"dinoSR_par.txt\")\n",
    "    lines = inputFile.readlines()\n",
    "    lines.pop(0) # drop images number\n",
    "    projections = []\n",
    "    optAxes = []\n",
    "    # Every line is a parameters list for the corresponding image camera\n",
    "    for line in lines:\n",
    "        line = line[:-1]                # \\n character\n",
    "        linedata = line.split(' ')\n",
    "        imgName = linedata.pop(0)\n",
    "        k = np.zeros((3,3))\n",
    "        r = np.zeros((3,3))\n",
    "        t = np.zeros((3,1))\n",
    "\n",
    "        i = 0\n",
    "        for ridx,row in enumerate(k):\n",
    "            t[ridx][0]=linedata[ridx+18]\n",
    "            for colidx,_ in enumerate(row):\n",
    "                k[ridx][colidx]=linedata[i]\n",
    "                r[ridx][colidx]=linedata[i+9]\n",
    "                i+=1\n",
    "        x = np.concatenate((r,t),axis=1)\n",
    "        p = np.matmul(k,x)\n",
    "        projections.append(p)\n",
    "\n",
    "        optAxis = get_optical_axis(p)\n",
    "        optAxis *= np.linalg.det(p[:,:-1])\n",
    "        norm = np.linalg.norm(optAxis)\n",
    "        # optAxis[3] = p[2][3]\n",
    "        optAxis /= norm\n",
    "        optAxes.append(optAxis)\n",
    "\n",
    "        outputFile = open(datasetPath+\"projection/projection\"+imgName[6:10]+\".txt\",mode=\"w+\")\n",
    "        outputFile.write(\"CONTOUR\\n\")\n",
    "        pString = \"\"\n",
    "        for row in p:\n",
    "            for col in row:\n",
    "                pString += str('{0:0.5f}'.format(col))+\" \"\n",
    "            pString += \"\\n\"\n",
    "        outputFile.write(pString)\n",
    "        outputFile.close()\n",
    "        \n",
    "    return projections,optAxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Harris and DoG operators for a given image\n",
    "def get_dog_harris(img):\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "            \n",
    "    # Get DoG\n",
    "    g1 = cv.GaussianBlur(gray,(0,0),sigmaX=1)\n",
    "    g2 = cv.GaussianBlur(gray,(0,0),sigmaX=1*np.sqrt(2))\n",
    "    diff = cv.absdiff(g1,g2)\n",
    "    dog = diff * gray\n",
    "\n",
    "    # Get Harris\n",
    "    bSize = 3\n",
    "    kSize = 1\n",
    "    corners = cv.cornerHarris(src=gray,blockSize=bSize,ksize=kSize,k=0.06)\n",
    "    # corners = cv.dilate(corners,None)\n",
    "    \n",
    "    return dog , corners\n",
    "\n",
    "\n",
    "def sparse_dog_harris(dog,harris):\n",
    "    n = 4\n",
    "    sparseDog = copy(dog)\n",
    "    sparseHarris = copy(harris)\n",
    "    sparseDogPositions = []\n",
    "    sparseHarrisPositions = []\n",
    "    for yIdx in range(0,len(dog),ß2):\n",
    "        for xIdx in range(0,len(dog[0]),ß2):\n",
    "            nThMaximumDog = get_nth_maximum(dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumDog != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(dog[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumDog:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseDogPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseDog[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumDog)\n",
    "            nThMaximumHarris = get_nth_maximum(harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumHarris != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(harris[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumHarris:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseHarrisPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseHarris[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumHarris)\n",
    "            # show_images([dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]],['before dog','after dog','before harris','after harris'])\n",
    "\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    return sparseDog,sparseHarris,sparseDogPositions,sparseHarrisPositions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Fundmental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm.\n",
    "    each row is constructed as\n",
    "    [x’*x, x’*y, x’, y’*x, y’*y, y’, x, y, 1] \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # build matrix for equations\n",
    "    A = np.zeros((n,9))\n",
    "    for i in range(n):\n",
    "        A[i] = [x1[0,i]*x2[0,i], x1[0,i]*x2[1,i], x1[0,i]*x2[2,i],\n",
    "        x1[1,i]*x2[0,i], x1[1,i]*x2[1,i], x1[1,i]*x2[2,i],\n",
    "        x1[2,i]*x2[0,i], x1[2,i]*x2[1,i], x1[2,i]*x2[2,i] ]\n",
    "    \n",
    "    # compute linear least square solution\n",
    "    U,S,V = np.linalg.svd(A)\n",
    "    F = V[-1].reshape(3,3)\n",
    "    # constrain F\n",
    "    # make rank 2 by zeroing out last singular value\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    S[2] = 0\n",
    "    F = np.dot(U,np.dot(np.diag(S),V))\n",
    "    return F\n",
    "\n",
    "def compute_epipole(F):\n",
    "    \"\"\" Computes the (right) epipole from a\n",
    "    fundamental matrix F.\n",
    "    (Use with F.T for left epipole.) \"\"\"\n",
    "    # return null space of F (Fx=0)\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    e = V[-1]\n",
    "    return e/e[2]\n",
    "\n",
    "def plot_epipolar_line(im,F,x,epipole=None,show_epipole=True):\n",
    "    \"\"\" Plot the epipole and epipolar line F*x=0\n",
    "    in an image. F is the fundamental matrix\n",
    "    and x a point in the other image.\"\"\"\n",
    "    m,n = im.shape[:2]\n",
    "    line = np.dot(F,x)\n",
    "    # epipolar line parameter and values\n",
    "    t = np.linspace(0,n,100)\n",
    "    lt = np.array([(line[2]+line[0]*tt)/(-line[1]) for tt in t])\n",
    "    # take only line points inside the image\n",
    "    ndx = (lt>=0) & (lt<m)\n",
    "    plt.plot(t[ndx],lt[ndx],linewidth=2)\n",
    "    if show_epipole:\n",
    "        if epipole is None:\n",
    "            epipole = compute_epipole(F)\n",
    "        plt.plot(epipole[0]/epipole[2],epipole[1]/epipole[2],'r*')\n",
    "\n",
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_book(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    x1 = np.vstack( (pts1,np.ones(pts1.shape[1])) )\n",
    "    x2 = np.vstack( (pts2,np.ones(pts2.shape[1])) )\n",
    "\n",
    "    fundmentalMat = compute_fundamental(x1,x2)\n",
    "    # compute the epipole\n",
    "    e = compute_epipole(fundmentalMat)\n",
    "    \n",
    "    # plotting\n",
    "    plt.figure()\n",
    "    plt.imshow(images[0])\n",
    "    for i in range(5):\n",
    "        plot_epipolar_line(images[0],fundmentalMat,x2[:,i],e,False)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im2)\n",
    "    # plot each point individually, this gives same colors as the lines\n",
    "    for i in range(5):\n",
    "        plt.plot(x2[0,i],x2[1,i],'o')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_sift(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    fundmentalMat, _ = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewForm : skewForm(v).dot(u) = v cross u\n",
    "def skewForm(vec):\n",
    "    sk = np.zeros((3,3))\n",
    "    sk[0][0] = 0\n",
    "    sk[0][1] = -vec[2]\n",
    "    sk[0][2] = vec[1]\n",
    "    sk[1][0] = vec[2]\n",
    "    sk[1][1] = 0\n",
    "    sk[1][2] = -vec[0]\n",
    "    sk[2][0] = -vec[1]\n",
    "    sk[2][1] = vec[0]\n",
    "    sk[2][2] = 0\n",
    "    # sk = np.array(\n",
    "    #     [0,-vec[2],vec[1]],\n",
    "    #     [vec[2],0,-vec[0]],\n",
    "    #     [-vec[1],vec[0],0]\n",
    "    #     )\n",
    "\n",
    "    return sk\n",
    "\n",
    "def get_fundmental_matrix(img1,img2):\n",
    "    p00 = img1[\"projMat\"][0].reshape(1,4)\n",
    "    p01 = img1[\"projMat\"][1].reshape(1,4)\n",
    "    p02 = img1[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    p10 = img2[\"projMat\"][0].reshape(1,4)\n",
    "    p11 = img2[\"projMat\"][1].reshape(1,4)\n",
    "    p12 = img2[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    F = np.zeros((3,3))\n",
    "    \n",
    "    ppinv = np.zeros((3,3))\n",
    "\n",
    "    ppinv = np.matmul(img2[\"projMat\"], np.linalg.pinv(img1[\"projMat\"]))\n",
    "\n",
    "    epipole = np.zeros((3,1))\n",
    "\n",
    "    epipole = np.matmul(img2[\"projMat\"],img1[\"optCenter\"])\n",
    "    \n",
    "    funMat = np.zeros((3,3))\n",
    "\n",
    "    funMat = np.matmul(skewForm(epipole),ppinv)\n",
    "\n",
    "    return funMat\n",
    "\n",
    "    # F[0][0] = np.linalg.det(np.concatenate((p01, p02, p11, p12),axis=0))\n",
    "    # F[0][1] = np.linalg.det(np.concatenate((p01, p02, p12, p10),axis=0))\n",
    "    # F[0][2] = np.linalg.det(np.concatenate((p01, p02, p10, p11),axis=0))\n",
    "\n",
    "    # F[1][0] = np.linalg.det(np.concatenate((p02, p00, p11, p12),axis=0))\n",
    "    # F[1][1] = np.linalg.det(np.concatenate((p02, p00, p12, p10),axis=0))\n",
    "    # F[1][2] = np.linalg.det(np.concatenate((p02, p00, p10, p11),axis=0))\n",
    "\n",
    "    # F[2][0] = np.linalg.det(np.concatenate((p00, p01, p11, p12),axis=0))\n",
    "    # F[2][1] = np.linalg.det(np.concatenate((p00, p01, p12, p10),axis=0))\n",
    "    # F[2][2] = np.linalg.det(np.concatenate((p00, p01, p10, p11),axis=0))\n",
    "    \n",
    "    # return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Draw Epilines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the epilines corresponding to a point in the first image\n",
    "# Draw also the points satisfying epipolar consistancy \n",
    "def drawlines(img1,lines,pts1):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "\n",
    "    reducedFeaturesImage = copy(img1[\"image\"])\n",
    "    fullFeaturesImage = copy(img1[\"image\"])\n",
    "    r,c,_ = reducedFeaturesImage.shape\n",
    "    \n",
    "    for r,pt1 in zip(lines,pts1):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        cv.line(reducedFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "        cv.line(fullFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "    \n",
    "    \n",
    "    a = lines[0][0]\n",
    "    b = lines[0][1]\n",
    "    c = lines[0][2]\n",
    "    \n",
    "    maxDistance = 2 * np.sqrt((a**2)+(b**2)) \n",
    "    legalFeatures = []\n",
    "    for pt in pts1:\n",
    "        # color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        ptx = pt[0]\n",
    "        pty = pt[1]\n",
    "        if abs(a*ptx+b*pty+c) <= maxDistance :\n",
    "            cv.circle(reducedFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            legalFeatures.append(np.float32([ptx,pty]))\n",
    "        else:\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(255,0,0),-1)\n",
    "\n",
    "    return fullFeaturesImage,reducedFeaturesImage,legalFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables needed by the objective function\n",
    "referenceImgIdx = 0\n",
    "depthVec = 0    \n",
    "optimPhotos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(center, normal, photo, opticalCenter):\n",
    "    depthVector = center - opticalCenter.reshape(4,1)\n",
    "    depth = np.linalg.norm(np.array(depthVector))\n",
    "    theta = np.math.acos(normal[2])#pitch\n",
    "    phi = np.math.atan2(normal[1], normal[0])#yaw\n",
    "    depthVector /= depth\n",
    "    return depth, theta, phi, depthVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(imageModel, unitDepthVec, depth, theta, phi):\n",
    "    opticalCenter = imageModel[\"optCenter\"]\n",
    "    depthVector = depth * unitDepthVec\n",
    "    center = opticalCenter.reshape(4,1) + depthVector\n",
    "    normal = np.zeros((4,1))\n",
    "    normal[0] = np.math.sin(theta)*np.math.cos(phi)\n",
    "    normal[1] = np.math.sin(theta)*np.math.sin(phi)\n",
    "    normal[2] = np.math.cos(theta)\n",
    "    return center, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_objective(center, rightVector, upVector, refPhotoModel, targetPhotosIDs):\n",
    "\n",
    "    cell1 = project_patch(center, refPhotoModel, rightVector, upVector)#overload to get the center  #TODO\n",
    "    SumNcc = 0\n",
    "    for i in range(len(targetPhotosIDs)):\n",
    "        photo = imagesModels[targetPhotosIDs[i]['idx']]\n",
    "        cell2 = project_patch(center, photo, rightVector, upVector)\n",
    "        SumNcc += ncc_score(cell1, cell2)\n",
    "    \n",
    "    return SumNcc / len(targetPhotosIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    depth, theta, phi = x[0], x[1], x[2]\n",
    "    center, normal = decode(imagesModels[referenceImgIdx], depthVec, depth, theta, phi)\n",
    "    #TODO#some conditions\n",
    "    if np.dot(imagesModels[referenceImgIdx][\"optAxis\"], depthVec) < 0:\n",
    "        return 1.0\n",
    "    patch = {}\n",
    "    patch[\"center\"] = center\n",
    "    patch[\"normal\"] = normal\n",
    "    patch[\"referenceImgIdx\"] = referenceImgIdx\n",
    "    right, up = get_patch_vectors(patch) \n",
    "    return -ncc_objective(center, right, up, imagesModels[referenceImgIdx], optimPhotos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(depth, unitDepthVector, patchTrueSet):\n",
    "    sum = 0\n",
    "    for i in range (len(patchTrueSet)):\n",
    "        photo = imagesModels[patchTrueSet[i]['idx']]\n",
    "        depthVectorProj = np.matmul(photo['projMat'], unitDepthVector)\n",
    "        depthVectorProj /= depthVectorProj[2]\n",
    "        sum += np.linalg.norm(np.array(depthVectorProj[-1])) #remove t\n",
    "        \n",
    "    sum /= len(patchTrueSet)\n",
    "    unitDepthVector /= sum\n",
    "    depth *= sum\n",
    "    return depth, unitDepthVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_patch(patch):\n",
    "    global referenceImgIdx\n",
    "    global depthVec\n",
    "    global optimPhotos\n",
    "    refPhoto = imagesModels[patch[\"referenceImgIdx\"]][\"image\"]\n",
    "    opticalCenter = imagesModels[patch[\"referenceImgIdx\"]][\"optCenter\"]\n",
    "\n",
    "    depth, theta, phi, unitDepthVec = encode(patch[\"center\"], patch[\"normal\"], refPhoto, opticalCenter)\n",
    "    depth, unitDepthVec = normalize(depth, unitDepthVec, patch[\"trueSet\"]) #TODO add trueset to patch\n",
    "    targetPhotos = patch[\"trueSet\"]\n",
    "    referenceImgIdx, depthVec, optimPhotos = patch[\"referenceImgIdx\"], unitDepthVec, targetPhotos\n",
    "\n",
    "    option = {\n",
    "        'disp': False, #Set to True to print convergence messages.\n",
    "        'maxiter': 1000,\n",
    "        'xatol': 0.0005,\n",
    "        'adaptive': False #adaptivebool, optional#Adapt algorithm parameters to dimensionality of problem. Useful for high-dimensional minimization\n",
    "        \n",
    "    }\n",
    "    initialGuess = np.array([depth, theta, phi])\n",
    "    solution  = minimize(objective, initialGuess, method='Nelder-Mead', options = option)\n",
    "    center, normal = decode(imagesModels[patch[\"referenceImgIdx\"]], unitDepthVec, solution.x[0], solution.x[1], solution.x[2])\n",
    "    patch[\"center\"], patch[\"normal\"] = center, normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Relevent Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevent_images(imgModels,idx):\n",
    "    releventImages = []\n",
    "    myOptAxis = imgModels[idx][\"optAxis\"]\n",
    "\n",
    "    for i in range(len(imgModels)):\n",
    "        if i == idx:\n",
    "            continue\n",
    "        otherOptAxis = imgModels[i][\"optAxis\"]\n",
    "        cosAngle = np.dot(myOptAxis,otherOptAxis)\n",
    "\n",
    "        if cosMinAngle > cosAngle > cosMaxAngle:\n",
    "            releventImages.append(i)\n",
    "\n",
    "    return releventImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get v/t Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_score(cell1,cell2):\n",
    "    mean1 = np.mean(cell1)\n",
    "    mean2 = np.mean(cell2)\n",
    "    \n",
    "    std1 = std2 = product = 0\n",
    "\t\n",
    "    for i in range(len(cell1)):\n",
    "        diff1 = cell1[i] - mean1\n",
    "        diff2 = cell2[i] - mean2\n",
    "        product += diff1 * diff2\n",
    "        std1 += diff1 * diff1\n",
    "        std2 += diff2 * diff2\n",
    "\t\n",
    "    stds = std1 * std2\n",
    "    if stds == 0:\n",
    "        return 0\n",
    "\n",
    "    return product / np.math.sqrt(stds)\n",
    "\n",
    "def project_patch(patchCenter,imgModel,rightVector,upVector):\n",
    "    cell = np.zeros(patchGridSize*patchGridSize*3)\n",
    "    \n",
    "    projMat = imgModel[\"projMat\"]\n",
    "    projCenter = np.matmul(projMat,patchCenter)\n",
    "    projRight = np.matmul(projMat,rightVector).reshape(3,1)\n",
    "    projUp = np.matmul(projMat,upVector).reshape(3,1)\n",
    "\n",
    "    scale = 1/projCenter[2]\n",
    "    projCenter = scale * projCenter\n",
    "    projRight = scale * projRight\n",
    "    projUp = scale * projUp\n",
    "\n",
    "    step = (patchGridSize-1)/2\n",
    "    diagVector = projUp + projRight\n",
    "    diagVector = step * diagVector\n",
    "    topLeftVector = projCenter - diagVector\n",
    "\n",
    "    cellIdx = 0\n",
    "    for i in range(patchGridSize):\n",
    "        for j in range(patchGridSize):\n",
    "            xCoord = topLeftVector[0] + i*projUp[0] + j*projRight[0]\n",
    "            yCoord = topLeftVector[1] + i*projUp[1] + j*projRight[1]\n",
    "            yCoord = int(yCoord+0.5)\n",
    "            xCoord = int(xCoord+0.5)\n",
    "\n",
    "            # pixel is outside the image\n",
    "            if outside_image_boundry(yCoord,xCoord):\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = 0,0,0\n",
    "            else:\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = imgModel[\"image\"][yCoord][xCoord]\n",
    "\n",
    "            cellIdx +=3\n",
    "\n",
    "    return cell\n",
    "\n",
    "def get_ncc_score(patch,releventImgModel,rightVector,upVector):\n",
    "    referenceImgModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "\n",
    "    cell1 = project_patch(patch[\"center\"],referenceImgModel,rightVector,upVector)\n",
    "    cell2 = project_patch(patch[\"center\"],releventImgModel,rightVector,upVector)\n",
    "    return ncc_score(cell1,cell2)\n",
    "\n",
    "def get_patch_vectors(patch):\n",
    "    referenceImageModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "    projMat = referenceImageModel[\"projMat\"]\n",
    "\n",
    "    ppinv = np.linalg.pinv(projMat)\n",
    "\n",
    "    scale = np.dot(ppinv[:,0],patch[\"normal\"])\n",
    "    rightVector = ppinv[:,0].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "    scale = np.dot(ppinv[:,1],patch[\"normal\"])\n",
    "    upVector = ppinv[:,1].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "\n",
    "    scale = np.dot(projMat[2],patch[\"center\"])\n",
    "    rightVector = (scale/(np.dot(projMat[0],rightVector)))*rightVector\n",
    "    upVector = (scale/(np.dot(projMat[1],upVector)))*upVector\n",
    "\n",
    "    return rightVector, upVector\n",
    "\n",
    "def get_t_images(patch,alfa,visibleImgsIdx):\n",
    "    tImages = []\n",
    "\n",
    "    rightVector,upVector = get_patch_vectors(patch)\n",
    "    for visibleImageIdx in visibleImgsIdx:\n",
    "        visibleImageModel = imagesModels[visibleImageIdx]\n",
    "        \n",
    "        depthVector = np.float32([\n",
    "            visibleImageModel[\"optCenter\"][0] - patch[\"center\"][0],\n",
    "            visibleImageModel[\"optCenter\"][1] - patch[\"center\"][1],\n",
    "            visibleImageModel[\"optCenter\"][2] - patch[\"center\"][2],\n",
    "            visibleImageModel[\"optCenter\"][3] - patch[\"center\"][3]\n",
    "        ])\n",
    "\n",
    "        if np.dot(np.squeeze(depthVector), np.squeeze(patch[\"normal\"])) <= 0:\n",
    "            continue\n",
    "        \n",
    "        nccScore = get_ncc_score(patch, visibleImageModel, rightVector, upVector)\n",
    "        if nccScore > alfa:\n",
    "            imgCoord = np.matmul(visibleImageModel['projMat'], patch['center'])\n",
    "            imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "            \n",
    "            x = int(imgCoord[0][0]) // ß1\n",
    "            y = int(imgCoord[1][0]) // ß1\n",
    "            tImages.append({\n",
    "                \"idx\":visibleImageIdx,\n",
    "                \"cell\":{\n",
    "                    'ptx':x,\n",
    "                    'pty':y\n",
    "                },\n",
    "                \"ncc\":nccScore\n",
    "            }) #TODO remove nccscore if not used\n",
    "    \n",
    "    return tImages\n",
    "\n",
    "def get_visible_images(patch,baseImageIdx):\n",
    "    sImgs = []\n",
    "    for releventImgIdx in imagesModels[baseImageIdx][\"releventImgsIdxs\"]:\n",
    "        vec = imagesModels[releventImgIdx]['optCenter'].reshape(4,1) - patch['center']\n",
    "        vec = vec/(np.linalg.norm(vec))\n",
    "        if np.dot(np.squeeze(patch['normal']),np.squeeze(vec)) > np.math.cos((np.math.pi/3)):\n",
    "            sImgs.append({'idx':releventImgIdx})\n",
    "    return sImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_patch(patch):\n",
    "    for sImg in patch[\"visibleSet\"]:\n",
    "        imgModel = imagesModels[sImg['idx']]\n",
    "        imgCoord = np.matmul(imgModel['projMat'], patch['center'])\n",
    "        imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "\n",
    "        x = int(imgCoord[0][0]) // ß1\n",
    "        y = int(imgCoord[1][0]) // ß1\n",
    "        cell1 = imgModel['grid'][y][x]\n",
    "        \n",
    "        if not any(imgIdx == sImg['idx'] for imgIdx in patch['trueSet']):\n",
    "            cell1['Qf'].append(patch)\n",
    "        else:\n",
    "            cell1['Qt'].append(patch)\n",
    "        \n",
    "        sImg['cell'] = {\n",
    "            'ptx':x,\n",
    "            'pty':y,\n",
    "        }\n",
    "    patches.append(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_cell(imageID, y, x):\n",
    "    cell_y = y // ß1\n",
    "    cell_x = x // ß1\n",
    "    if len(imagesModels[imageID]['grid'][cell_y][cell_x]['Qt']) == 0 and len(imagesModels[imageID]['grid'][cell_y][cell_x]['Qf']) == 0 :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_statsify_epipoler_consistency(baseImageIdx, featurePt):\n",
    "    triangulations = list()\n",
    "    for i in range(len(imagesModels[baseImageIdx][\"releventImgsIdxs\"])):\n",
    "        releventImageIdx = imagesModels[baseImageIdx][\"releventImgsIdxs\"][i]\n",
    "        fundmentalMat = get_fundmental_matrix(imagesModels[baseImageIdx],imagesModels[releventImageIdx])\n",
    "\n",
    "        if fundmentalMat is None:\n",
    "            continue\n",
    "        pt1 = featurePt\n",
    "        pts1 = np.int32([pt1])\n",
    "        pts2 = np.int32(imagesModels[releventImageIdx][\"dogPositions\"])\n",
    "\n",
    "        originalWithFeaturePt = imagesModels[baseImageIdx][\"image\"].copy()\n",
    "        cv.circle(originalWithFeaturePt,tuple(pt1),5,(0,0,255),-1)\n",
    "\n",
    "        # Get the epilines of features in left image on the right image\n",
    "        # parameter1: points required to get its epilines in the other image\n",
    "        # parameter2: which image that points are belong, 1-left 2-right\n",
    "        # parameter3: fundmental matrix between the 2 images\n",
    "        # returns list of epilines that lie on the other image and corresponding to the points\n",
    "        lines = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,fundmentalMat)\n",
    "        lines = lines.reshape(-1,3)\n",
    "        #sara_im = plot_epipolar_line(imagesModels[i][\"image\"],fundmentalMat,[pt1[0],pt1[1],1])\n",
    "\n",
    "        # draw the epiline on the other image\n",
    "        # parameter1: the second image\n",
    "        # parameter2: the epilines that lie on the second image\n",
    "        # parameter3: the features lie on the second image\n",
    "        fullFeaturesImage,reducedFeaturesImage,legalFeatures = drawlines(imagesModels[releventImageIdx],lines,pts2)\n",
    "\n",
    "        #Triangulation\n",
    "        for j in range(len(legalFeatures)):\n",
    "            if not(empty_cell(releventImageIdx, int(legalFeatures[j][1]), int(legalFeatures[j][0]))): #TODO check t = 1\n",
    "                continue\n",
    "                \n",
    "            triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[baseImageIdx][\"projMat\"],imagesModels[releventImageIdx][\"projMat\"],pt1,legalFeatures[j])\n",
    "            triangulatedPoint = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :]\n",
    "\n",
    "            #triangulatedPoint = triangulate_point(np.array([pt1[0], pt1[1],1]),legalFeatures[j],imagesModels[baseImageIdx][\"projMat\"],imagesModels[i][\"projMat\"])\n",
    "\n",
    "            distFromcenter = abs(abs(np.linalg.norm(np.array(imagesModels[baseImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))) - abs(np.linalg.norm(np.array(imagesModels[releventImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))))\n",
    "\n",
    "            triangulation = {\n",
    "                \"originalImg\": releventImageIdx,\n",
    "                \"position\": triangulatedPoint,\n",
    "                \"distFromCenter\": distFromcenter,\n",
    "                \"ptx\": legalFeatures[j][0],\n",
    "                \"pty\": legalFeatures[j][1]\n",
    "            }\n",
    "\n",
    "            triangulations.append(triangulation)\n",
    "\n",
    "        #show_images([imagesModels[baseImageIdx][\"image\"],imagesModels[releventImageIdx][\"image\"],fullFeaturesImage,reducedFeaturesImage, originalWithFeaturePt],[\"image\"+str(baseImageIdx),\"image\"+str(releventImageIdx),\"fullfeatures in image\"+str(releventImageIdx),\"reducedfeatures in image\"+str(releventImageIdx), \"originalWithFeaturePt\"+str(releventImageIdx)])\n",
    "\n",
    "    triangulations = sorted(triangulations, key=lambda k: k[\"distFromCenter\"]) \n",
    "    #for i in range(len(triangulations)):\n",
    "        #print(\"triangulations: \", triangulations[i][\"originalImg\"], \"ptx\", triangulations[i][\"ptx\"], \"pty\", triangulations[i][\"pty\"], triangulations[i][\"distFromCenter\"])\n",
    "    \n",
    "    return triangulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_patches(baseImageIdx, triangulations):\n",
    "    #print(\"construct_patches ...\")\n",
    "    baseOptCenter = imagesModels[baseImageIdx][\"optCenter\"]\n",
    "    for candidate in triangulations:\n",
    "\n",
    "        patch = {}\n",
    "        patch[\"referenceImgIdx\"] = baseImageIdx\n",
    "        patch[\"center\"] = candidate[\"position\"]\n",
    "        patch[\"normal\"] = np.float32([\n",
    "                baseOptCenter[0] - candidate[\"position\"][0],\n",
    "                baseOptCenter[1] - candidate[\"position\"][1],\n",
    "                baseOptCenter[2] - candidate[\"position\"][2],\n",
    "                baseOptCenter[3] - candidate[\"position\"][3],\n",
    "            ])\n",
    "        patch[\"normal\"] = patch[\"normal\"] / np.linalg.norm(patch[\"normal\"])\n",
    "\n",
    "        sImgs = []\n",
    "        for releventImgIdx in imagesModels[baseImageIdx][\"releventImgsIdxs\"]:\n",
    "            vec = imagesModels[releventImgIdx]['optCenter'].reshape(4,1) - patch['center']\n",
    "            vec = vec/(np.linalg.norm(vec))\n",
    "            if np.dot(np.squeeze(patch['normal']),np.squeeze(vec)) > np.math.cos((np.math.pi/3)):\n",
    "                sImgs.append(releventImgIdx)\n",
    "        # print(len(sImgs),len(imagesModels[baseImageIdx][\"releventImgsIdxs\"]))\n",
    "        #TODO add alpha1,2 to constants in paper, 0.4,0.7....0.6,0.3\n",
    "        patch[\"trueSet\"] = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"]) \n",
    "\n",
    "        #print(\"len(patch[trueSet]): \", len(patch[\"trueSet\"]))\n",
    "        if len(patch[\"trueSet\"]) <= 1 : \n",
    "            continue\n",
    "\n",
    "        optimize_patch(patch)\n",
    "        patch[\"visibleSet\"] = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"]) \n",
    "        patch[\"trueSet\"] = get_t_images(patch,0.7,imagesModels[baseImageIdx][\"releventImgsIdxs\"])\n",
    "        #print(\"len(patch[trueSet]): \", len(patch[\"trueSet\"]), \" gamma: \", gamma)\n",
    "        if len(patch[\"trueSet\"]) >= gamma:\n",
    "            register_patch(patch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Read Input---->DONE\nFeature Detection---->DONE\nGet Relevent Images---->DONE\n"
    }
   ],
   "source": [
    "images,grids = init_imgs(datasetPath)\n",
    "projections,optAxes = read_parameters_file(datasetPath)\n",
    "print(\"Read Input---->DONE\")\n",
    "imagesModels = list()\n",
    "\n",
    "for idx,image in enumerate(images):\n",
    "    dog,harris = get_dog_harris(image)\n",
    "    sparseDog,sparseHarris,dogPositions,harrisPositions = sparse_dog_harris(dog,harris)\n",
    "    opticalCenter = getOpticalCenter(projections[idx])\n",
    "    imgModel={\n",
    "        \"image\": images[idx],\n",
    "        \"projMat\": projections[idx],\n",
    "        \"optCenter\": opticalCenter,\n",
    "        \"optAxis\": optAxes[idx],\n",
    "        \"grid\": grids[idx],\n",
    "        \"dog\": dog,\n",
    "        \"harris\": harris,\n",
    "        \"sparseDog\": sparseDog,\n",
    "        \"sparseHarris\": sparseHarris,\n",
    "        \"dogPositions\": dogPositions,\n",
    "        \"harrisPositions\": harrisPositions\n",
    "    }\n",
    "    \n",
    "    imagesModels.append(imgModel)\n",
    "\n",
    "print(\"Feature Detection---->DONE\")\n",
    "\n",
    "for i in range(len(imagesModels)):\n",
    "    imagesModels[i][\"releventImgsIdxs\"] = get_relevent_images(imagesModels,i)\n",
    "    \n",
    "print(\"Get Relevent Images---->DONE\")\n",
    "# show_images([imagesModels[0][\"dog\"],imagesModels[0][\"sparseDog\"],imagesModels[0][\"harris\"],imagesModels[0][\"sparseHarris\"]],['dog','sparse dog','harris','sparse harris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Start Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start Matching....\nTotal number of patches:  0\nImageID:  0  Number of Features:  276\nImageID:  0 ----> Done\t Number of constructed patches:  84\nImageID:  1  Number of Features:  283\nImageID:  1 ----> Done\t Number of constructed patches:  126\nImageID:  2  Number of Features:  212\nImageID:  2 ----> Done\t Number of constructed patches:  101\nImageID:  3  Number of Features:  183\nImageID:  3 ----> Done\t Number of constructed patches:  80\nImageID:  4  Number of Features:  237\nImageID:  4 ----> Done\t Number of constructed patches:  67\nImageID:  5  Number of Features:  214\nImageID:  5 ----> Done\t Number of constructed patches:  54\nImageID:  6  Number of Features:  232\nImageID:  6 ----> Done\t Number of constructed patches:  79\nImageID:  7  Number of Features:  264\nImageID:  7 ----> Done\t Number of constructed patches:  118\nImageID:  8  Number of Features:  285\nImageID:  8 ----> Done\t Number of constructed patches:  123\nImageID:  9  Number of Features:  285\nImageID:  9 ----> Done\t Number of constructed patches:  132\nImageID:  10  Number of Features:  282\nImageID:  10 ----> Done\t Number of constructed patches:  101\nImageID:  11  Number of Features:  218\nImageID:  11 ----> Done\t Number of constructed patches:  64\nImageID:  12  Number of Features:  186\nImageID:  12 ----> Done\t Number of constructed patches:  43\nImageID:  13  Number of Features:  168\nImageID:  13 ----> Done\t Number of constructed patches:  68\nImageID:  14  Number of Features:  198\nImageID:  14 ----> Done\t Number of constructed patches:  86\nImageID:  15  Number of Features:  258\nImageID:  15 ----> Done\t Number of constructed patches:  73\nTotal number of patches:  1399\n"
    }
   ],
   "source": [
    "print(\"Start Matching....\")\n",
    "patches = list()\n",
    "numberOfPatches = 0\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "for i in range(len(imagesModels)):\n",
    "    baseImageIdx = i\n",
    "    print(\"ImageID: \", str(baseImageIdx),\" Number of Features: \", str(len(imagesModels[baseImageIdx][\"dogPositions\"])))\n",
    "    for featurePt in imagesModels[baseImageIdx][\"dogPositions\"]:\n",
    "        if not(empty_cell(baseImageIdx, featurePt[1], featurePt[0])):\n",
    "            # print(\"non empty cell\")\n",
    "            continue\n",
    "        #print(\"empty cell\")\n",
    "        features  = get_features_statsify_epipoler_consistency(baseImageIdx, featurePt)\n",
    "        construct_patches(baseImageIdx, features)\n",
    "    print(\"ImageID: \", str(baseImageIdx), \"----> Done\\t\",\"Number of constructed patches: \", str(len(patches) - numberOfPatches))\n",
    "    numberOfPatches = len(patches)\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "originalImageModels = deepcopy(imagesModels)\n",
    "originalPatches = deepcopy(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_header(file):\n",
    "    file.write(\"ply\\n\")\n",
    "    file.write(\"format ascii 1.0\\n\")\n",
    "    file.write( \"element vertex \"+ str(len(patches)) + \"\\n\")\n",
    "    file.write( \"property float x\\n\")\n",
    "    file.write(\"property float y\\n\")\n",
    "    file.write(\"property float z\\n\")\n",
    "    file.write(\"property float nx\\n\")\n",
    "    file.write(\"property float ny\\n\")\n",
    "    file.write(\"property float nz\\n\")\n",
    "    file.write(\"property uchar diffuse_red\\n\")\n",
    "    file.write(\"property uchar diffuse_green\\n\")\n",
    "    file.write(\"property uchar diffuse_blue\\n\")\n",
    "    file.write( \"end_header\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply(): \n",
    "    file = open(\"pointcloud.txt.ply\", \"w\")\n",
    "    write_header(file)\n",
    "    for patch in patches:\n",
    "        file.write(str(patch[\"center\"][0][0]) + \" \" +  str(patch[\"center\"][1][0]) + \" \" + str(patch[\"center\"][2][0]) + \" \")\n",
    "        file.write(str(patch[\"normal\"][0][0]) + \" \" +  str(patch[\"normal\"][1][0]) + \" \" + str(patch[\"normal\"][2][0]) + \" \")\n",
    "        file.write(\"255\"+ \" \" + \"0\" + \" \"+\"0\")\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "write_ply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud = np.loadtxt('pointcloud.txt.ply',skiprows=13)\n",
    "pcd = o3d.geometry.PointCloud()\n",
    "pcd.points = o3d.utility.Vector3dVector(point_cloud[:,:3])\n",
    "pcd.colors = o3d.utility.Vector3dVector(point_cloud[:,6:9]/255)\n",
    "pcd.normals = o3d.utility.Vector3dVector(point_cloud[:,3:6])\n",
    "bbox = pcd.get_axis_aligned_bounding_box()\n",
    "print(np.asarray(bbox.get_box_points()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "patches: 320\nThe total number of patches now: 10011 \tremaining patches: 319\nThe total number of patches now: 10012 \tremaining patches: 318\nThe total number of patches now: 10012 \tremaining patches: 317\nThe total number of patches now: 10013 \tremaining patches: 316\nThe total number of patches now: 10022 \tremaining patches: 315\nThe total number of patches now: 10035 \tremaining patches: 314\nThe total number of patches now: 10050 \tremaining patches: 313\nThe total number of patches now: 10054 \tremaining patches: 312\nThe total number of patches now: 10057 \tremaining patches: 311\nThe total number of patches now: 10060 \tremaining patches: 310\nThe total number of patches now: 10064 \tremaining patches: 309\nThe total number of patches now: 10071 \tremaining patches: 308\nThe total number of patches now: 10078 \tremaining patches: 307\nThe total number of patches now: 10083 \tremaining patches: 306\nThe total number of patches now: 10097 \tremaining patches: 305\nThe total number of patches now: 10109 \tremaining patches: 304\nThe total number of patches now: 10120 \tremaining patches: 303\nThe total number of patches now: 10129 \tremaining patches: 302\nThe total number of patches now: 10134 \tremaining patches: 301\nThe total number of patches now: 10136 \tremaining patches: 300\nThe total number of patches now: 10140 \tremaining patches: 299\nThe total number of patches now: 10149 \tremaining patches: 298\nThe total number of patches now: 10161 \tremaining patches: 297\nThe total number of patches now: 10169 \tremaining patches: 296\nThe total number of patches now: 10177 \tremaining patches: 295\nThe total number of patches now: 10178 \tremaining patches: 294\nThe total number of patches now: 10185 \tremaining patches: 293\nThe total number of patches now: 10192 \tremaining patches: 292\nThe total number of patches now: 10201 \tremaining patches: 291\nThe total number of patches now: 10210 \tremaining patches:290\nThe total number of patches now: 10214 \tremaining patches: 289\nThe total number of patches now: 10215 \tremaining patches: 288\nThe total number of patches now: 10221 \tremaining patches: 287\nThe total number of patches now: 10227 \tremaining patches: 286\nThe total number of patches now: 10239 \tremaining patches: 285\nThe total number of patches now: 10245 \tremaining patches: 284\nThe total number of patches now: 10245 \tremaining patches: 283\nThe total number of patches now: 10249 \tremaining patches: 282\nThe total number of patches now: 10260 \tremaining patches: 281\nThe total number of patches now: 10268 \tremaining patches: 280\nThe total number of patches now: 10272 \tremaining patches: 279\nThe total number of patches now: 10277 \tremaining patches: 278\nThe total number of patches now: 10281 \tremaining patches: 277\nThe total number of patches now: 10282 \tremaining patches: 276\nThe total number of patches now: 10286 \tremaining patches: 275\nThe total number of patches now: 10290 \tremaining patches: 274\nThe total number of patches now: 10290 \tremaining patches: 273\nThe total number of patches now: 10293 \tremaining patches: 272\nThe total number of patches now: 10300 \tremaining patches: 271\nThe total number of patches now: 10300 \tremaining patches: 270\nThe total number of patches now: 10300 \tremaining patches: 269\nThe total number of patches now: 10301 \tremaining patches: 268\nThe total number of patches now: 10301 \tremaining patches: 267\nThe total number of patches now: 10301 \tremaining patches: 266\nThe total number of patches now: 10301 \tremaining patches: 265\nThe total number of patches now: 10301 \tremaining patches: 264\nThe total number of patches now: 10301 \tremaining patches: 263\nThe total number of patches now: 10301 \tremaining patches: 262\nThe total number of patches now: 10301 \tremaining patches: 261\nThe total number of patches now: 10310 \tremaining patches: 260\nThe total number of patches now: 10323 \tremaining patches: 259\nThe total number of patches now: 10323 \tremaining patches: 258\nThe total number of patches now: 10323 \tremaining patches: 257\nThe total number of patches now: 10323 \tremaining patches: 256\nThe total number of patches now: 10325 \tremaining patches: 255\nThe total number of patches now: 10329 \tremaining patches: 254\nThe total number of patches now: 10329 \tremaining patches: 253\nThe total number of patches now: 10331 \tremaining patches: 252\nThe total number of patches now: 10347 \tremaining patches: 251\nThe total number of patches now: 10355 \tremaining patches: 250\nThe total number of patches now: 10355 \tremaining patches: 249\nThe total number of patches now: 10355 \tremaining patches: 248\nThe total number of patches now: 10356 \tremaining patches: 247\nThe total number of patches now: 10356 \tremaining patches: 246\nThe total number of patches now: 10356 \tremaining patches: 245\nThe total number of patches now: 10359 \tremaining patches: 244\nThe total number of patches now: 10362 \tremaining patches: 243\nThe total number of patches now: 10365 \tremaining patches: 242\nThe total number of patches now: 10369 \tremaining patches: 241\nThe total number of patches now: 10369 \tremaining patches: 240\nThe total number of patches now: 10369 \tremaining patches: 239\nThe total number of patches now: 10369 \tremaining patches: 238\nThe total number of patches now: 10372 \tremaining patches: 237\nThe total number of patches now: 10374 \tremaining patches: 236\nThe total number of patches now: 10376 \tremaining patches: 235\nThe total number of patches now: 10379 \tremaining patches: 234\nThe total number of patches now: 10379 \tremaining patches: 233\nThe total number of patches now: 10380 \tremaining patches: 232\nThe total number of patches now: 10383 \tremaining patches: 231\nThe total number of patches now: 10387 \tremaining patches: 230\nThe total number of patches now: 10391 \tremaining patches: 229\nThe total number of patches now: 10393 \tremaining patches: 228\nThe total number of patches now: 10396 \tremaining patches: 227\nThe total number of patches now: 10396 \tremaining patches: 226\nThe total number of patches now: 10398 \tremaining patches: 225\nThe total number of patches now: 10398 \tremaining patches: 224\nThe total number of patches now: 10398 \tremaining patches: 223\nThe total number of patches now: 10398 \tremaining patches: 222\nThe total number of patches now: 10402 \tremaining patches: 221\nThe total number of patches now: 10418 \tremaining patches: 220\nThe total number of patches now: 10418 \tremaining patches: 219\nThe total number of patches now: 10418 \tremaining patches: 218\nThe total number of patches now: 10423 \tremaining patches: 217\nThe total number of patches now: 10429 \tremaining patches: 216\nThe total number of patches now: 10430 \tremaining patches: 215\nThe total number of patches now: 10430 \tremaining patches: 214\nThe total number of patches now: 10431 \tremaining patches: 213\nThe total number of patches now: 10442 \tremaining patches: 212\nThe total number of patches now: 10459 \tremaining patches: 211\nThe total number of patches now: 10476 \tremaining patches: 210\nThe total number of patches now: 10488 \tremaining patches: 209\nThe total number of patches now: 10495 \tremaining patches: 208\nThe total number of patches now: 10501 \tremaining patches: 207\nThe total number of patches now: 10506 \tremaining patches: 206\nThe total number of patches now: 10506 \tremaining patches: 205\nThe total number of patches now: 10509 \tremaining patches: 204\nThe total number of patches now: 10509 \tremaining patches: 203\nThe total number of patches now: 10509 \tremaining patches: 202\nThe total number of patches now: 10510 \tremaining patches: 201\nThe total number of patches now: 10520 \tremaining patches: 200\nThe total number of patches now: 10530 \tremaining patches: 199\nThe total number of patches now: 10536 \tremaining patches: 198\nThe total number of patches now: 10553 \tremaining patches: 197\nThe total number of patches now: 10571 \tremaining patches: 196\nThe total number of patches now: 10591 \tremaining patches: 195\nThe total number of patches now: 10603 \tremaining patches: 194\nThe total number of patches now: 10614 \tremaining patches: 193\nThe total number of patches now: 10622 \tremaining patches: 192\nThe total number of patches now: 10622 \tremaining patches: 191\nThe total number of patches now: 10623 \tremaining patches: 190\nThe total number of patches now: 10633 \tremaining patches: 189\nThe total number of patches now: 10639 \tremaining patches: 188\nThe total number of patches now: 10651 \tremaining patches: 187\nThe total number of patches now: 10670 \tremaining patches: 186\nThe total number of patches now: 10682 \tremaining patches: 185\nThe total number of patches now: 10683 \tremaining patches: 184\nThe total number of patches now: 10700 \tremaining patches: 183\nThe total number of patches now: 10711 \tremaining patches: 182\nThe total number of patches now: 10711 \tremaining patches: 181\nThe total number of patches now: 10711 \tremaining patches: 180\nThe total number of patches now: 10731 \tremaining patches: 179\nThe total number of patches now: 10743 \tremaining patches: 178\nThe total number of patches now: 10763 \tremaining patches: 177\nThe total number of patches now: 10763 \tremaining patches: 176\nThe total number of patches now: 10763 \tremaining patches: 175\nThe total number of patches now: 10774 \tremaining patches: 174\nThe total number of patches now: 10774 \tremaining patches: 173\nThe total number of patches now: 10774 \tremaining patches: 172\nThe total number of patches now: 10774 \tremaining patches: 171\nThe total number of patches now: 10774 \tremaining patches: 170\nThe total number of patches now: 10774 \tremaining patches: 169\nThe total number of patches now: 10774 \tremaining patches: 168\nThe total number of patches now: 10775 \tremaining patches: 167\nThe total number of patches now: 10775 \tremaining patches: 166\nThe total number of patches now: 10776 \tremaining patches: 165\nThe total number of patches now: 10776 \tremaining patches: 164\nThe total number of patches now: 10778 \tremaining patches: 163\nThe total number of patches now: 10778 \tremaining patches: 162\nThe total number of patches now: 10783 \tremaining patches: 161\nThe total number of patches now: 10783 \tremaining patches: 160\nThe total number of patches now: 10787 \tremaining patches: 159\nThe total number of patches now: 10787 \tremaining patches: 158\nThe total number of patches now: 10791 \tremaining patches: 157\nThe total number of patches now: 10791 \tremaining patches: 156\nThe total number of patches now: 10791 \tremaining patches: 155\nThe total number of patches now: 10791 \tremaining patches: 154\nThe total number of patches now: 10791 \tremaining patches: 153\nThe total number of patches now: 10791 \tremaining patches: 152\nThe total number of patches now: 10791 \tremaining patches: 151\nThe total number of patches now: 10791 \tremaining patches: 150\nThe total number of patches now: 10795 \tremaining patches: 149\nThe total number of patches now: 10807 \tremaining patches: 148\nThe total number of patches now: 10807 \tremaining patches: 147\nThe total number of patches now: 10807 \tremaining patches: 146\nThe total number of patches now: 10807 \tremaining patches: 145\nThe total number of patches now: 10813 \tremaining patches: 144\nThe total number of patches now: 10831 \tremaining patches: 143\nThe total number of patches now: 10846 \tremaining patches: 142\nThe total number of patches now: 10857 \tremaining patches: 141\nThe total number of patches now: 10865 \tremaining patches: 140\nThe total number of patches now: 10865 \tremaining patches: 139\nThe total number of patches now: 10865 \tremaining patches: 138\nThe total number of patches now: 10868 \tremaining patches: 137\nThe total number of patches now: 10879 \tremaining patches: 136\nThe total number of patches now: 10893 \tremaining patches: 135\nThe total number of patches now: 10913 \tremaining patches: 134\nThe total number of patches now: 10931 \tremaining patches: 133\nThe total number of patches now: 10943 \tremaining patches: 132\nThe total number of patches now: 10943 \tremaining patches: 131\nThe total number of patches now: 10943 \tremaining patches: 130\nThe total number of patches now: 10951 \tremaining patches: 129\nThe total number of patches now: 10958 \tremaining patches: 128\nThe total number of patches now: 10974 \tremaining patches: 127\nThe total number of patches now: 10990 \tremaining patches: 126\nThe total number of patches now: 11009 \tremaining patches: 125\nThe total number of patches now: 11029 \tremaining patches: 124\nThe total number of patches now: 11039 \tremaining patches: 123\nThe total number of patches now: 11053 \tremaining patches: 122\nThe total number of patches now: 11061 \tremaining patches: 121\nThe total number of patches now: 11062 \tremaining patches: 120\nThe total number of patches now: 11064 \tremaining patches: 119\nThe total number of patches now: 11083 \tremaining patches: 118\nThe total number of patches now: 11094 \tremaining patches: 117\nThe total number of patches now: 11110 \tremaining patches: 116\nThe total number of patches now: 11126 \tremaining patches: 115\nThe total number of patches now: 11142 \tremaining patches: 114\nThe total number of patches now: 11162 \tremaining patches: 113\nThe total number of patches now: 11182 \tremaining patches: 112\nThe total number of patches now: 11194 \tremaining patches: 111\nThe total number of patches now: 11206 \tremaining patches: 110\nThe total number of patches now: 11215 \tremaining patches: 109\nThe total number of patches now: 11215 \tremaining patches: 108\nThe total number of patches now: 11215 \tremaining patches: 107\nThe total number of patches now: 11226 \tremaining patches: 106\nThe total number of patches now: 11237 \tremaining patches: 105\nThe total number of patches now: 11256 \tremaining patches: 104\nThe total number of patches now: 11272 \tremaining patches: 103\nThe total number of patches now: 11283 \tremaining patches: 102\nThe total number of patches now: 11291 \tremaining patches: 101\nThe total number of patches now: 11294 \tremaining patches: 100\nThe total number of patches now: 11313 \tremaining patches: 99\nThe total number of patches now: 11332 \tremaining patches: 98\nThe total number of patches now: 11340 \tremaining patches: 97\nThe total number of patches now: 11340 \tremaining patches: 96\nThe total number of patches now: 11340 \tremaining patches: 95\nThe total number of patches now: 11347 \tremaining patches: 94\nThe total number of patches now: 11365 \tremaining patches: 93\nThe total number of patches now: 11377 \tremaining patches: 92\nThe total number of patches now: 11389 \tremaining patches: 91\nThe total number of patches now: 11389 \tremaining patches: 90\nThe total number of patches now: 11408 \tremaining patches: 89\nThe total number of patches now: 11426 \tremaining patches: 88\nThe total number of patches now: 11446 \tremaining patches: 87\nThe total number of patches now: 11448 \tremaining patches: 86\nThe total number of patches now: 11454 \tremaining patches: 85\nThe total number of patches now: 11462 \tremaining patches: 84\nThe total number of patches now: 11473 \tremaining patches: 83\nThe total number of patches now: 11485 \tremaining patches: 82\nThe total number of patches now: 11496 \tremaining patches: 81\nThe total number of patches now: 11496 \tremaining patches: 80\nThe total number of patches now: 11496 \tremaining patches: 79\nThe total number of patches now: 11496 \tremaining patches: 78\nThe total number of patches now: 11496 \tremaining patches: 77\nThe total number of patches now: 11498 \tremaining patches: 76\nThe total number of patches now: 11507 \tremaining patches: 75\nThe total number of patches now: 11514 \tremaining patches: 74\nThe total number of patches now: 11515 \tremaining patches: 73\nThe total number of patches now: 11515 \tremaining patches: 72\nThe total number of patches now: 11515 \tremaining patches: 71\nThe total number of patches now: 11515 \tremaining patches: 70\nThe total number of patches now: 11515 \tremaining patches: 69\nThe total number of patches now: 11515 \tremaining patches: 68\nThe total number of patches now: 11515 \tremaining patches: 67\nThe total number of patches now: 11527 \tremaining patches: 66\nThe total number of patches now: 11539 \tremaining patches: 65\nThe total number of patches now: 11546 \tremaining patches: 64\nThe total number of patches now: 11547 \tremaining patches: 63\nThe total number of patches now: 11547 \tremaining patches: 62\nThe total number of patches now: 11553 \tremaining patches: 61\nThe total number of patches now: 11553 \tremaining patches: 60\nThe total number of patches now: 11553 \tremaining patches: 59\nThe total number of patches now: 11553 \tremaining patches: 58\nThe total number of patches now: 11555 \tremaining patches: 57\nThe total number of patches now: 11555 \tremaining patches: 56\nThe total number of patches now: 11563 \tremaining patches: 55\nThe total number of patches now: 11575 \tremaining patches: 54\nThe total number of patches now: 11590 \tremaining patches: 53\nThe total number of patches now: 11606 \tremaining patches: 52\nThe total number of patches now: 11614 \tremaining patches: 51\nThe total number of patches now: 11614 \tremaining patches: 50\nThe total number of patches now: 11630 \tremaining patches: 49\nThe total number of patches now: 11646 \tremaining patches: 48\nThe total number of patches now: 11660 \tremaining patches: 47\nThe total number of patches now: 11661 \tremaining patches: 46\nThe total number of patches now: 11661 \tremaining patches: 45\nThe total number of patches now: 11661 \tremaining patches: 44\nThe total number of patches now: 11662 \tremaining patches: 43\nThe total number of patches now: 11662 \tremaining patches: 42\nThe total number of patches now: 11674 \tremaining patches: 41\nThe total number of patches now: 11686 \tremaining patches:40\nThe total number of patches now: 11702 \tremaining patches: 39\nThe total number of patches now: 11718 \tremaining patches: 38\nThe total number of patches now: 11734 \tremaining patches: 37\nThe total number of patches now: 11738 \tremaining patches: 36\nThe total number of patches now: 11738 \tremaining patches: 35\nThe total number of patches now: 11739 \tremaining patches: 34\nThe total number of patches now: 11745 \tremaining patches: 33\nThe total number of patches now: 11756 \tremaining patches: 32\nThe total number of patches now: 11772 \tremaining patches: 31\nThe total number of patches now: 11787 \tremaining patches: 30\nThe total number of patches now: 11798 \tremaining patches: 29\nThe total number of patches now: 11814 \tremaining patches: 28\nThe total number of patches now: 11825 \tremaining patches: 27\nThe total number of patches now: 11831 \tremaining patches: 26\nThe total number of patches now: 11843 \tremaining patches: 25\nThe total number of patches now: 11843 \tremaining patches: 24\nThe total number of patches now: 11843 \tremaining patches: 23\nThe total number of patches now: 11854 \tremaining patches: 22\nThe total number of patches now: 11870 \tremaining patches: 21\nThe total number of patches now: 11886 \tremaining patches: 20\nThe total number of patches now: 11902 \tremaining patches: 19\nThe total number of patches now: 11916 \tremaining patches: 18\nThe total number of patches now: 11916 \tremaining patches: 17\nThe total number of patches now: 11916 \tremaining patches: 16\nThe total number of patches now: 11932 \tremaining patches: 15\nThe total number of patches now: 11940 \tremaining patches: 14\nThe total number of patches now: 11940 \tremaining patches: 13\nThe total number of patches now: 11940 \tremaining patches: 12\nThe total number of patches now: 11949 \tremaining patches: 11\nThe total number of patches now: 11961 \tremaining patches: 10\nThe total number of patches now: 11972 \tremaining patches: 9\nThe total number of patches now: 11982 \tremaining patches: 8\nThe total number of patches now: 11986 \tremaining patches: 7\nThe total number of patches now: 11987 \tremaining patches: 6\nThe total number of patches now: 11988 \tremaining patches: 5\nThe total number of patches now: 11998 \tremaining patches: 4\nThe total number of patches now: 12008 \tremaining patches: 3\nThe total number of patches now: 12008 \tremaining patches: 2\nThe total number of patches now: 12012 \tremaining patches: 1\n"
    }
   ],
   "source": [
    "print(\"Start Expansion....\")\n",
    "patches = deepcopy(originalPatches)\n",
    "totalPatches = deepcopy(originalPatches)\n",
    "patchesStack = deepcopy(originalPatches)\n",
    "expandedPatches =[]\n",
    "imagesModels = deepcopy(originalImageModels)\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "while len(patchesStack) != 0:\n",
    "    print(\"The total number of patches now:\",len(totalPatches),\"\\tremaining patches:\",len(patchesStack))\n",
    "    patch = patchesStack.pop(0)\n",
    "    neighborCells = []\n",
    "\n",
    "    # Get neighbor cells\n",
    "    for idx,visibleImage in enumerate(patch['visibleSet']):\n",
    "        x = visibleImage['cell']['ptx']\n",
    "        y = visibleImage['cell']['pty']\n",
    "        \n",
    "        # if id(patch) in [id(otherPatch) for otherPatch in imagesModels[visibleImage['idx']]['grid'][y][x]['Qf']]:\n",
    "        #     continue\n",
    "            \n",
    "        # Get neighbor cells\n",
    "        for neighborY in range(y-1,y+2,1):\n",
    "            for neighborX in range(x-1,x+2,1):\n",
    "                # diagonal cells\n",
    "                if (abs(neighborY-y) + abs(neighborX-x)) != 1:\n",
    "                    continue\n",
    "\n",
    "                if not outside_image_boundry(neighborY,neighborX):\n",
    "                    neighborCell = imagesModels[visibleImage['idx']]['grid'][neighborY][neighborX]\n",
    "                    # non empty cell Qt\n",
    "                    if len(neighborCell['Qt']) != 0:\n",
    "                        continue\n",
    "                        \n",
    "                    projMat = imagesModels[visibleImage['idx']]['projMat']\n",
    "                    projCenter = np.matmul(projMat,patch['center'])\n",
    "                    scale = 1/projCenter[2]\n",
    "                    projCenter = scale * projCenter\n",
    "                    hasNeighbor = False\n",
    "                    \n",
    "                    for otherPatch in neighborCell['Qf']:\n",
    "                        otherProjCenter = np.matmul(projMat,otherPatch['center'])\n",
    "                        scale = 1/otherProjCenter[2]\n",
    "                        otherProjCenter = scale * otherProjCenter\n",
    "                        \n",
    "                        left =  np.abs(np.dot(np.squeeze(otherPatch['center']-patch['center']),np.squeeze(patch['normal']))) + np.abs(np.dot(np.squeeze(otherPatch['center']-patch['center']),np.squeeze(otherPatch['normal'])))\n",
    "                        right = np.linalg.norm(projCenter-otherProjCenter)\n",
    "\n",
    "                        rowProj = np.matmul(imagesModels[patch[\"referenceImgIdx\"]]['projMat'],(imagesModels[patch[\"referenceImgIdx\"]]['optCenter'].reshape(4,1) - ((patch['center']+otherPatch['center'])/2)))\n",
    "\n",
    "                        if left < 2* right :\n",
    "                            hasNeighbor = True\n",
    "                            break\n",
    "\n",
    "                    if hasNeighbor == True:\n",
    "                        # print(\"ARE neighbors\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        # print(\"not neighbors\")\n",
    "                        neighborCells.append({\n",
    "                              \"x\":neighborX,\n",
    "                              \"y\":neighborY,\n",
    "                              \"neighborCell\":neighborCell\n",
    "                            })\n",
    "                        \n",
    "    for neighborCell in neighborCells:\n",
    "        newPatch = {}\n",
    "        newPatch[\"referenceImgIdx\"] = patch[\"referenceImgIdx\"]\n",
    "        newPatch[\"normal\"] = patch[\"normal\"]\n",
    "        newPatch[\"trueSet\"] = patch[\"trueSet\"]\n",
    "\n",
    "        # Get the ray\n",
    "        cellCenter = np.array([neighborCell['x'],neighborCell['y'],1]).reshape(3,1)\n",
    "        projMat = imagesModels[patch['referenceImgIdx']][\"projMat\"]\n",
    "        ppinv = np.linalg.pinv(projMat)\n",
    "        ray = np.matmul(ppinv,cellCenter)+imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)\n",
    "        ray = ray / np.linalg.norm(ray)\n",
    "        \n",
    "        if abs(np.dot(np.squeeze(ray),np.squeeze(newPatch['normal']))) < 10**-6:\n",
    "          print(\"ray parallel to patch\")\n",
    "          continue\n",
    "\n",
    "        # Get the intersection\n",
    "        t = (- np.dot(np.squeeze(patch['normal']),np.squeeze(imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1) - patch['center'])))/(np.dot(np.squeeze(patch['normal']),np.squeeze(ray)))\n",
    "        intersection = t*ray + imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)\n",
    "        intersection = intersection/(np.linalg.norm(intersection))\n",
    "        newPatch['center'] = intersection\n",
    "        optimize_patch(newPatch)\n",
    "        newPatch[\"visibleSet\"] = patch['trueSet']\n",
    "        newVImgs = get_t_images(newPatch,0.6,imagesModels[newPatch[\"referenceImgIdx\"]][\"releventImgsIdxs\"])\n",
    "\n",
    "        for newVImg in newVImgs:\n",
    "            found = False\n",
    "            for vImg in newPatch[\"visibleSet\"]:\n",
    "                if newVImg['idx'] == vImg['idx']:\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                newPatch[\"visibleSet\"].append(newVImg)\n",
    "        \n",
    "        visibleIdxs = [vImg['idx'] for vImg in newPatch[\"visibleSet\"]]\n",
    "        newPatch[\"trueSet\"] = get_t_images(newPatch,0.7,visibleIdxs)\n",
    "        #print(\"len(newPatch[trueSet]): \", len(newPatch[\"trueSet\"]), \" gamma: \", gamma)\n",
    "        if len(newPatch[\"trueSet\"]) >= gamma:\n",
    "            register_patch(newPatch)\n",
    "            expandedPatches.append(newPatch)\n",
    "            totalPatches.append(newPatch)\n",
    "\n",
    "        # print(intersection)\n",
    "        # d = - np.dot(np.squeeze(patch['normal']),np.squeeze(imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1))) \n",
    "        # xx, yy = np.meshgrid(range(10), range(10))\n",
    "        # z = (-patch['normal'][0] * xx - patch['normal'][1] * yy - d) * 1. /patch['normal'][2]\n",
    "        # plt3d = plt.figure().gca(projection='3d')\n",
    "        # plt3d.plot_surface(xx, yy, z)\n",
    "        # x = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[0]]\n",
    "        # y = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[1]]\n",
    "        # z = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[2]]\n",
    "        # xi = [intersection[0]]\n",
    "        # yi = [intersection[1]]\n",
    "        # zi = [intersection[2]]\n",
    "        # plt3d.scatter(x,y,z,c='r')\n",
    "        # plt3d.scatter(xi,yi,zi,c='y')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_expanded_header(file):\n",
    "    file.write(\"ply\\n\")\n",
    "    file.write(\"format ascii 1.0\\n\")\n",
    "    file.write( \"element vertex \"+ str(len(expandedPatches)) + \"\\n\")\n",
    "    file.write( \"property float x\\n\")\n",
    "    file.write(\"property float y\\n\")\n",
    "    file.write(\"property float z\\n\")\n",
    "    file.write(\"property float nx\\n\")\n",
    "    file.write(\"property float ny\\n\")\n",
    "    file.write(\"property float nz\\n\")\n",
    "    file.write(\"property uchar diffuse_red\\n\")\n",
    "    file.write(\"property uchar diffuse_green\\n\")\n",
    "    file.write(\"property uchar diffuse_blue\\n\")\n",
    "    file.write( \"end_header\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "12018\n10619\n1399\n"
    }
   ],
   "source": [
    "def write_expanded_ply(): \n",
    "    file = open(\"expandedpointcloud.txt.ply\", \"w\")\n",
    "    write_expanded_header(file)\n",
    "    for idx,patch in enumerate(expandedPatches):\n",
    "        file.write(str(patch[\"center\"][0][0]) + \" \" +  str(patch[\"center\"][1][0]) + \" \" + str(patch[\"center\"][2][0]) + \" \")\n",
    "        file.write(str(patch[\"normal\"][0][0]) + \" \" +  str(patch[\"normal\"][1][0]) + \" \" + str(patch[\"normal\"][2][0]) + \" \")\n",
    "        file.write(\"0\"+ \" \" + \"0\" + \" \"+\"255\")\n",
    "\n",
    "        file.write(\"\\n\")\n",
    "        #i+=1\n",
    "    file.close()\n",
    "\n",
    "print(len(totalPatches))   \n",
    "print(len(expandedPatches)) \n",
    "print(len(originalPatches)) \n",
    "write_expanded_ply()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python36764bitbaseconda671ffe7150094cd9ba8c9cb5c362aaeb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}