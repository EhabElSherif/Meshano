{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from copy import copy\n",
    "from optical_center import getOpticalCenter\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_nth_maximum(arr,n):\n",
    "    uniqueValues = list(arr.flatten())\n",
    "    uniqueValues.sort()\n",
    "    if len(uniqueValues) < n:\n",
    "        return uniqueValues[0]\n",
    "    return uniqueValues[len(uniqueValues)-n]\n",
    "    # sortedmatrix.sort()\n",
    "    # # print(arr.shape)\n",
    "    # if sortedmatrix.size == 0:\n",
    "    #     return -1\n",
    "    # return sortedmatrix[0 if n > sortedmatrix.size else -n] \n",
    "\n",
    "def get_optical_axis(projectionMat):\n",
    "    return np.array([projectionMat[2][0],projectionMat[2][1],projectionMat[2][2],0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Data/dinoSparseRing/\"\n",
    "ß1 = 2\n",
    "ß2 = 32\n",
    "µ = 5       # the projection of one of its edges into R(p) is parallel to the image rows, and the smallest axis-aligned square containingits image covers a µ × µ pixel^2 area\n",
    "# We associate with p a reference image R(p),the images S(p) where p should be visible and the images T(p) where it is truly found \n",
    "\n",
    "cosMinAngle = np.math.cos(np.math.radians(20))\n",
    "cosMaxAngle = np.math.cos(np.math.radians(60))\n",
    "patchGridSize = 5\n",
    "\n",
    "patchModel = {\n",
    "    \"R\":None,\n",
    "    \"S\":set,\n",
    "    \"T\":set\n",
    "}\n",
    "# The cell C(i, j) keeps track of two different sets Qt(i, j) and Qf(i, j)\n",
    "cell = {\n",
    "    \"Qt\":set,\n",
    "    \"Qf\":set\n",
    "}\n",
    "# We associate with each image I a regular grid of β1×β1 pixel^2 cells\n",
    "imageModel = {\n",
    "    \"image\":None,\n",
    "    \"projMat\":None,\n",
    "    \"optCenter\":None,\n",
    "    \"grid\":None,\n",
    "    \"dog\":None,\n",
    "    \"harris\":None,\n",
    "    \"sparseDog\":None,\n",
    "    \"sparseHarris\":None,\n",
    "    \"dogPositions\":None,\n",
    "    \"harrisPositions\":None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image model from a given path\n",
    "def init_imgs(datasetPath):\n",
    "    # Read imgs\n",
    "    imgs = [cv.imread(file) for file in glob(datasetPath+'*.png')]\n",
    "    # imgs = [cv.rotate(cv.imread(file),cv.ROTATE_90_COUNTERCLOCKWISE) for file in glob(datasetPath+'*.png')]\n",
    "\n",
    "    # Construct corresponding image grid\n",
    "    grids = [np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)]) for img in imgs]\n",
    "\n",
    "    return imgs,grids\n",
    "    \n",
    "# Read camera parameters and return the projection matrices for all pictures\n",
    "def read_parameters_file(datasetPath):\n",
    "    inputFile = open(datasetPath+\"dinoSR_par.txt\")\n",
    "    lines = inputFile.readlines()\n",
    "    lines.pop(0) # drop images number\n",
    "    projections = []\n",
    "    optAxes = []\n",
    "    # Every line is a parameters list for the corresponding image camera\n",
    "    for line in lines:\n",
    "        line = line[:-1]                # \\n character\n",
    "        linedata = line.split(' ')\n",
    "        imgName = linedata.pop(0)\n",
    "        k = np.zeros((3,3))\n",
    "        r = np.zeros((3,3))\n",
    "        t = np.zeros((3,1))\n",
    "\n",
    "        i = 0\n",
    "        for ridx,row in enumerate(k):\n",
    "            t[ridx][0]=linedata[ridx+18]\n",
    "            for colidx,_ in enumerate(row):\n",
    "                k[ridx][colidx]=linedata[i]\n",
    "                r[ridx][colidx]=linedata[i+9]\n",
    "                i+=1\n",
    "        x = np.concatenate((r,t),axis=1)\n",
    "        p = np.matmul(k,x)\n",
    "        projections.append(p)\n",
    "\n",
    "        optAxis = get_optical_axis(p)\n",
    "        optAxis *= np.linalg.det(p[:,:-1])\n",
    "        norm = np.linalg.norm(optAxis)\n",
    "        # optAxis[3] = p[2][3]\n",
    "        optAxis /= norm\n",
    "        optAxes.append(optAxis)\n",
    "\n",
    "        outputFile = open(datasetPath+\"projection/projection\"+imgName[6:10]+\".txt\",mode=\"w+\")\n",
    "        outputFile.write(\"CONTOUR\\n\")\n",
    "        pString = \"\"\n",
    "        for row in p:\n",
    "            for col in row:\n",
    "                pString += str('{0:0.5f}'.format(col))+\" \"\n",
    "            pString += \"\\n\"\n",
    "        outputFile.write(pString)\n",
    "        outputFile.close()\n",
    "        \n",
    "    return projections,optAxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Harris and DoG operators for a given image\n",
    "def get_dog_harris(img):\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "            \n",
    "    # Get DoG\n",
    "    g1 = cv.GaussianBlur(gray,(0,0),sigmaX=1)\n",
    "    g2 = cv.GaussianBlur(gray,(0,0),sigmaX=1*np.sqrt(2))\n",
    "    diff = cv.absdiff(g1,g2)\n",
    "    dog = diff * gray\n",
    "\n",
    "    # Get Harris\n",
    "    bSize = 3\n",
    "    kSize = 1\n",
    "    corners = cv.cornerHarris(src=gray,blockSize=bSize,ksize=kSize,k=0.06)\n",
    "    # corners = cv.dilate(corners,None)\n",
    "    \n",
    "    return dog , corners\n",
    "\n",
    "\n",
    "def sparse_dog_harris(dog,harris):\n",
    "    n = 4\n",
    "    sparseDog = copy(dog)\n",
    "    sparseHarris = copy(harris)\n",
    "    sparseDogPositions = []\n",
    "    sparseHarrisPositions = []\n",
    "    for yIdx in range(0,len(dog),ß2):\n",
    "        for xIdx in range(0,len(dog[0]),ß2):\n",
    "            nThMaximumDog = get_nth_maximum(dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumDog != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(dog[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumDog:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseDogPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseDog[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumDog)\n",
    "            nThMaximumHarris = get_nth_maximum(harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumHarris != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(harris[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumHarris:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseHarrisPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseHarris[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumHarris)\n",
    "            # show_images([dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]],['before dog','after dog','before harris','after harris'])\n",
    "\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    return sparseDog,sparseHarris,sparseDogPositions,sparseHarrisPositions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Fundmental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm.\n",
    "    each row is constructed as\n",
    "    [x’*x, x’*y, x’, y’*x, y’*y, y’, x, y, 1] \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # build matrix for equations\n",
    "    A = np.zeros((n,9))\n",
    "    for i in range(n):\n",
    "        A[i] = [x1[0,i]*x2[0,i], x1[0,i]*x2[1,i], x1[0,i]*x2[2,i],\n",
    "        x1[1,i]*x2[0,i], x1[1,i]*x2[1,i], x1[1,i]*x2[2,i],\n",
    "        x1[2,i]*x2[0,i], x1[2,i]*x2[1,i], x1[2,i]*x2[2,i] ]\n",
    "    \n",
    "    # compute linear least square solution\n",
    "    U,S,V = np.linalg.svd(A)\n",
    "    F = V[-1].reshape(3,3)\n",
    "    # constrain F\n",
    "    # make rank 2 by zeroing out last singular value\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    S[2] = 0\n",
    "    F = np.dot(U,np.dot(np.diag(S),V))\n",
    "    return F\n",
    "\n",
    "def compute_epipole(F):\n",
    "    \"\"\" Computes the (right) epipole from a\n",
    "    fundamental matrix F.\n",
    "    (Use with F.T for left epipole.) \"\"\"\n",
    "    # return null space of F (Fx=0)\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    e = V[-1]\n",
    "    return e/e[2]\n",
    "\n",
    "def plot_epipolar_line(im,F,x,epipole=None,show_epipole=True):\n",
    "    \"\"\" Plot the epipole and epipolar line F*x=0\n",
    "    in an image. F is the fundamental matrix\n",
    "    and x a point in the other image.\"\"\"\n",
    "    m,n = im.shape[:2]\n",
    "    line = np.dot(F,x)\n",
    "    # epipolar line parameter and values\n",
    "    t = np.linspace(0,n,100)\n",
    "    lt = np.array([(line[2]+line[0]*tt)/(-line[1]) for tt in t])\n",
    "    # take only line points inside the image\n",
    "    ndx = (lt>=0) & (lt<m)\n",
    "    plt.plot(t[ndx],lt[ndx],linewidth=2)\n",
    "    if show_epipole:\n",
    "        if epipole is None:\n",
    "            epipole = compute_epipole(F)\n",
    "        plt.plot(epipole[0]/epipole[2],epipole[1]/epipole[2],'r*')\n",
    "\n",
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_book(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    x1 = np.vstack( (pts1,np.ones(pts1.shape[1])) )\n",
    "    x2 = np.vstack( (pts2,np.ones(pts2.shape[1])) )\n",
    "\n",
    "    fundmentalMat = compute_fundamental(x1,x2)\n",
    "    # compute the epipole\n",
    "    e = compute_epipole(fundmentalMat)\n",
    "    \n",
    "    # plotting\n",
    "    plt.figure()\n",
    "    plt.imshow(images[0])\n",
    "    for i in range(5):\n",
    "        plot_epipolar_line(images[0],fundmentalMat,x2[:,i],e,False)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im2)\n",
    "    # plot each point individually, this gives same colors as the lines\n",
    "    for i in range(5):\n",
    "        plt.plot(x2[0,i],x2[1,i],'o')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_sift(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    fundmentalMat, _ = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewForm : skewForm(v).dot(u) = v cross u\n",
    "def skewForm(vec):\n",
    "    sk = np.zeros((3,3))\n",
    "    sk[0][0] = 0\n",
    "    sk[0][1] = -vec[2]\n",
    "    sk[0][2] = vec[1]\n",
    "    sk[1][0] = vec[2]\n",
    "    sk[1][1] = 0\n",
    "    sk[1][2] = -vec[0]\n",
    "    sk[2][0] = -vec[1]\n",
    "    sk[2][1] = vec[0]\n",
    "    sk[2][2] = 0\n",
    "    # sk = np.array(\n",
    "    #     [0,-vec[2],vec[1]],\n",
    "    #     [vec[2],0,-vec[0]],\n",
    "    #     [-vec[1],vec[0],0]\n",
    "    #     )\n",
    "\n",
    "    return sk\n",
    "\n",
    "def get_fundmental_matrix(img1,img2):\n",
    "    p00 = img1[\"projMat\"][0].reshape(1,4)\n",
    "    p01 = img1[\"projMat\"][1].reshape(1,4)\n",
    "    p02 = img1[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    p10 = img2[\"projMat\"][0].reshape(1,4)\n",
    "    p11 = img2[\"projMat\"][1].reshape(1,4)\n",
    "    p12 = img2[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    F = np.zeros((3,3))\n",
    "    \n",
    "    ppinv = np.zeros((3,3))\n",
    "\n",
    "    ppinv = np.matmul(img2[\"projMat\"], np.linalg.pinv(img1[\"projMat\"]))\n",
    "\n",
    "    epipole = np.zeros((3,1))\n",
    "\n",
    "    epipole = np.matmul(img2[\"projMat\"],img1[\"optCenter\"])\n",
    "    \n",
    "    funMat = np.zeros((3,3))\n",
    "\n",
    "    funMat = np.matmul(skewForm(epipole),ppinv)\n",
    "\n",
    "    return funMat\n",
    "\n",
    "    # F[0][0] = np.linalg.det(np.concatenate((p01, p02, p11, p12),axis=0))\n",
    "    # F[0][1] = np.linalg.det(np.concatenate((p01, p02, p12, p10),axis=0))\n",
    "    # F[0][2] = np.linalg.det(np.concatenate((p01, p02, p10, p11),axis=0))\n",
    "\n",
    "    # F[1][0] = np.linalg.det(np.concatenate((p02, p00, p11, p12),axis=0))\n",
    "    # F[1][1] = np.linalg.det(np.concatenate((p02, p00, p12, p10),axis=0))\n",
    "    # F[1][2] = np.linalg.det(np.concatenate((p02, p00, p10, p11),axis=0))\n",
    "\n",
    "    # F[2][0] = np.linalg.det(np.concatenate((p00, p01, p11, p12),axis=0))\n",
    "    # F[2][1] = np.linalg.det(np.concatenate((p00, p01, p12, p10),axis=0))\n",
    "    # F[2][2] = np.linalg.det(np.concatenate((p00, p01, p10, p11),axis=0))\n",
    "    \n",
    "    # return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Draw Epilines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the epilines corresponding to a point in the first image\n",
    "# Draw also the points satisfying epipolar consistancy \n",
    "def drawlines(img1,lines,pts1):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "\n",
    "    reducedFeaturesImage = copy(img1[\"image\"])\n",
    "    fullFeaturesImage = copy(img1[\"image\"])\n",
    "    r,c,_ = reducedFeaturesImage.shape\n",
    "    \n",
    "    for r,pt1 in zip(lines,pts1):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        cv.line(reducedFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "        cv.line(fullFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "    \n",
    "    \n",
    "    a = lines[0][0]\n",
    "    b = lines[0][1]\n",
    "    c = lines[0][2]\n",
    "    \n",
    "    maxDistance = 2 * np.sqrt((a**2)+(b**2)) \n",
    "    legalFeatures = []\n",
    "    for pt in pts1:\n",
    "        # color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        ptx = pt[0]\n",
    "        pty = pt[1]\n",
    "        if abs(a*ptx+b*pty+c) <= maxDistance :\n",
    "            cv.circle(reducedFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            legalFeatures.append(np.float32([ptx,pty]))\n",
    "        else:\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(255,0,0),-1)\n",
    "\n",
    "    return fullFeaturesImage,reducedFeaturesImage,legalFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Relevent Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevent_images(imgModels,idx):\n",
    "    releventImages = []\n",
    "    myOptAxis = imgModels[idx][\"optAxis\"]\n",
    "\n",
    "    for i in range(len(imgModels)):\n",
    "        if i == idx:\n",
    "            continue\n",
    "        otherOptAxis = imgModels[i][\"optAxis\"]\n",
    "        cosAngle = np.dot(myOptAxis,otherOptAxis)\n",
    "\n",
    "        if cosMinAngle > cosAngle > cosMaxAngle:\n",
    "            releventImages.append(i)\n",
    "\n",
    "    return releventImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get tImages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_score(cell1,cell2):\n",
    "    mean1 = np.mean(cell1)\n",
    "    mean2 = np.mean(cell2)\n",
    "    \n",
    "    std1 = std2 = product = 0\n",
    "\t\n",
    "    for i in range(len(cell1)):\n",
    "        diff1 = cell1[i] - mean1\n",
    "        diff2 = cell2[i] - mean2\n",
    "        product += diff1 * diff2\n",
    "        std1 += diff1 * diff1\n",
    "        std2 += diff2 * diff2\n",
    "\t\n",
    "    stds = std1 * std2\n",
    "    if stds == 0:\n",
    "        return 0\n",
    "\n",
    "    return product / np.math.sqrt(stds)\n",
    "\n",
    "def project_patch(patchCenter,imgModel,rightVector,upVector):\n",
    "    cell = np.zeros(patchGridSize*patchGridSize*3)\n",
    "    \n",
    "    projMat = imgModel[\"projMat\"]\n",
    "    projCenter = np.matmul(projMat,patchCenter)\n",
    "    projRight = np.matmul(projMat,rightVector).reshape(3,1)\n",
    "    projUp = np.matmul(projMat,upVector).reshape(3,1)\n",
    "\n",
    "    scale = 1/projCenter[2]\n",
    "    projCenter = scale * projCenter\n",
    "    projRight = scale * projRight\n",
    "    projUp = scale * projUp\n",
    "\n",
    "    step = (patchGridSize-1)/2\n",
    "    diagVector = projUp + projRight\n",
    "    diagVector = step * diagVector\n",
    "    topLeftVector = projCenter - diagVector\n",
    "\n",
    "    cellIdx = 0\n",
    "    for i in range(patchGridSize):\n",
    "        for j in range(patchGridSize):\n",
    "            xCoord = topLeftVector[0] + i*projUp[0] + j*projRight[0]\n",
    "            yCoord = topLeftVector[1] + i*projUp[1] + j*projRight[1]\n",
    "            yCoord = int(yCoord+0.5)\n",
    "            xCoord = int(xCoord+0.5)\n",
    "\n",
    "            # pixel is outside the image\n",
    "            if xCoord < 0 or yCoord < 0 or xCoord >= len(imgModel[\"image\"][0]) or yCoord >= len(imgModel[\"image\"]):\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = 0,0,0\n",
    "            else:\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = imgModel[\"image\"][yCoord][xCoord]\n",
    "\n",
    "            cellIdx +=3\n",
    "\n",
    "    return cell\n",
    "\n",
    "def get_ncc_score(patch,releventImgModel,rightVector,upVector):\n",
    "\n",
    "    referenceImgModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "\n",
    "    cell1 = project_patch(patch[\"center\"],referenceImgModel,rightVector,upVector)\n",
    "    cell2 = project_patch(patch[\"center\"],releventImgModel,rightVector,upVector)\n",
    "    return ncc_score(cell1,cell2)\n",
    "\n",
    "def get_patch_vectors(patch):\n",
    "    referenceImageModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "    projMat = referenceImageModel[\"projMat\"]\n",
    "\n",
    "    ppinv = np.linalg.pinv(projMat)\n",
    "\n",
    "    scale = np.dot(ppinv[:,0],patch[\"normal\"])\n",
    "    rightVector = ppinv[:,0].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "    scale = np.dot(ppinv[:,1],patch[\"normal\"])\n",
    "    upVector = ppinv[:,1].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "\n",
    "    scale = np.dot(projMat[2],patch[\"center\"])\n",
    "    rightVector = (scale/(np.dot(projMat[0],rightVector)))*rightVector\n",
    "    upVector = (scale/(np.dot(projMat[1],upVector)))*upVector\n",
    "\n",
    "    return rightVector, upVector\n",
    "\n",
    "def get_t_images(patch,alfa,releventIgmsIdxs):\n",
    "    tImages = []\n",
    "\n",
    "    rightVector,upVector = get_patch_vectors(patch)\n",
    "    for releventImageIdx in releventIgmsIdxs:\n",
    "        releventImageModel = imagesModels[releventImageIdx]\n",
    "        \n",
    "        depthVector = np.float32([\n",
    "            releventImageModel[\"optCenter\"][0] - patch[\"center\"][0],\n",
    "            releventImageModel[\"optCenter\"][1] - patch[\"center\"][1],\n",
    "            releventImageModel[\"optCenter\"][2] - patch[\"center\"][2],\n",
    "            releventImageModel[\"optCenter\"][3] - patch[\"center\"][3]\n",
    "        ])\n",
    "\n",
    "        if np.dot(np.squeeze(depthVector), np.squeeze(patch[\"normal\"])) <= 0:\n",
    "            continue\n",
    "        \n",
    "        nccScore = get_ncc_score(patch, releventImageModel, rightVector, upVector)\n",
    "        if nccScore >= alfa:\n",
    "            tImages.append({\"idx\":releventImageIdx,\"ncc\":nccScore})\n",
    "    \n",
    "    return tImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,grids = init_imgs(datasetPath)\n",
    "projections,optAxes = read_parameters_file(datasetPath)\n",
    "print(\"Read Input---->DONE\")\n",
    "imagesModels = list()\n",
    "for idx,image in enumerate(images):\n",
    "    dog,harris = get_dog_harris(image)\n",
    "    sparseDog,sparseHarris,dogPositions,harrisPositions = sparse_dog_harris(dog,harris)\n",
    "    opticalCenter = getOpticalCenter(projections[idx])\n",
    "\n",
    "    imgModel={\n",
    "        \"image\": images[idx],\n",
    "        \"projMat\": projections[idx],\n",
    "        \"optCenter\": opticalCenter,\n",
    "        \"optAxis\": optAxes[idx],\n",
    "        \"grid\": grids[idx],\n",
    "        \"dog\": dog,\n",
    "        \"harris\": harris,\n",
    "        \"sparseDog\": sparseDog,\n",
    "        \"sparseHarris\": sparseHarris,\n",
    "        \"dogPositions\": dogPositions,\n",
    "        \"harrisPositions\": harrisPositions\n",
    "    }\n",
    "    \n",
    "    imagesModels.append(imgModel)\n",
    "\n",
    "print(\"Feature Detection---->DONE\")\n",
    "\n",
    "for i in range(len(imagesModels)):\n",
    "    imagesModels[i][\"releventImgsIdxs\"] = get_relevent_images(imagesModels,i)\n",
    "    \n",
    "print(\"Get Relevent Images---->DONE\")\n",
    "# show_images([imagesFeatures[0][\"dog\"],imagesFeatures[0][\"sparseDog\"],imagesFeatures[0][\"harris\"],imagesFeatures[0][\"sparseHarris\"]],['dog','sparse dog','harris','sparse harris'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangulations = list()\n",
    "baseImageIdx = 0\n",
    "for i in range(len(imagesModels[baseImageIdx][\"releventImgsIdxs\"])):\n",
    "    releventImageIdx = imagesModels[baseImageIdx][\"releventImgsIdxs\"][i]\n",
    "    fundmentalMat = get_fundmental_matrix(imagesModels[baseImageIdx],imagesModels[releventImageIdx])\n",
    " \n",
    "    if fundmentalMat is None:\n",
    "        continue\n",
    "    pt1 = imagesModels[baseImageIdx][\"dogPositions\"][100]\n",
    "    pts1 = np.int32([pt1])\n",
    "    pts2 = np.int32(imagesModels[releventImageIdx][\"dogPositions\"])\n",
    "    \n",
    "    originalWithFeaturePt = imagesModels[baseImageIdx][\"image\"].copy()\n",
    "    cv.circle(originalWithFeaturePt,tuple(pt1),5,(0,0,255),-1)\n",
    "    \n",
    "    # Get the epilines of features in left image on the right image\n",
    "    # parameter1: points required to get its epilines in the other image\n",
    "    # parameter2: which image that points are belong, 1-left 2-right\n",
    "    # parameter3: fundmental matrix between the 2 images\n",
    "    # returns list of epilines that lie on the other image and corresponding to the points\n",
    "    lines = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,fundmentalMat)\n",
    "    lines = lines.reshape(-1,3)\n",
    "    #sara_im = plot_epipolar_line(imagesModels[i][\"image\"],fundmentalMat,[pt1[0],pt1[1],1])\n",
    "\n",
    "    # draw the epiline on the other image\n",
    "    # parameter1: the second image\n",
    "    # parameter2: the epilines that lie on the second image\n",
    "    # parameter3: the features lie on the second image\n",
    "    fullFeaturesImage,reducedFeaturesImage,legalFeatures = drawlines(imagesModels[releventImageIdx],lines,pts2)\n",
    "    \n",
    "    #Triangulation\n",
    "    for j in range(len(legalFeatures)):\n",
    "        triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[baseImageIdx][\"projMat\"],imagesModels[releventImageIdx][\"projMat\"],pt1,legalFeatures[j])\n",
    "        triangulatedPoint = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :]\n",
    "\n",
    "        #triangulatedPoint = triangulate_point(np.array([pt1[0], pt1[1],1]),legalFeatures[j],imagesModels[baseImageIdx][\"projMat\"],imagesModels[i][\"projMat\"])\n",
    "        \n",
    "        distFromcenter = abs(abs(np.linalg.norm(np.array(imagesModels[baseImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))) - abs(np.linalg.norm(np.array(imagesModels[releventImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))))\n",
    "\n",
    "        triangulation = {\n",
    "            \"originalImg\": releventImageIdx,\n",
    "            \"position\": triangulatedPoint,\n",
    "            \"distFromCenter\": distFromcenter,\n",
    "            \"ptx\": legalFeatures[j][0],\n",
    "            \"pty\": legalFeatures[j][1]\n",
    "        }\n",
    "        \n",
    "        triangulations.append(triangulation)\n",
    "\n",
    "    show_images([imagesModels[baseImageIdx][\"image\"],imagesModels[releventImageIdx][\"image\"],fullFeaturesImage,reducedFeaturesImage, originalWithFeaturePt],[\"image\"+str(baseImageIdx),\"image\"+str(releventImageIdx),\"fullfeatures in image\"+str(releventImageIdx),\"reducedfeatures in image\"+str(releventImageIdx), \"originalWithFeaturePt\"+str(releventImageIdx)])\n",
    "\n",
    "triangulations = sorted(triangulations, key=lambda k: k[\"distFromCenter\"]) \n",
    "for i in range(len(triangulations)):\n",
    "    print(\"triangulations: \", triangulations[i][\"originalImg\"], \"ptx\", triangulations[i][\"ptx\"], \"pty\", triangulations[i][\"pty\"], triangulations[i][\"distFromCenter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "baseOptCenter = imagesModels[baseImageIdx][\"optCenter\"]\n",
    "for candidate in triangulations:\n",
    "\n",
    "    patch = {}\n",
    "    patch[\"referenceImgIdx\"] = baseImageIdx\n",
    "    patch[\"center\"] = candidate[\"position\"]\n",
    "    patch[\"normal\"] = np.float32([\n",
    "            baseOptCenter[0] - candidate[\"position\"][0],\n",
    "            baseOptCenter[1] - candidate[\"position\"][1],\n",
    "            baseOptCenter[2] - candidate[\"position\"][2],\n",
    "            baseOptCenter[3] - candidate[\"position\"][3],\n",
    "        ])\n",
    "    patch[\"normal\"] = patch[\"normal\"] / np.linalg.norm(patch[\"normal\"])\n",
    "\n",
    "    tImgs = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"])\n",
    "    patch[\"trueSet\"] = tImgs\n",
    "    print(len(tImgs))\n",
    "    if len(tImgs) == 0 : \n",
    "        continue\n",
    "    optimize_patch(patch)\n",
    "\n",
    "    # sImgs = []\n",
    "    # # Calculate S(p)\n",
    "    # for releventImage in imagesModels[candidate[\"originalImg\"]][\"releventImgs\"]:\n",
    "    #     if otherCandidate is candidate:\n",
    "    #         continue\n",
    "        \n",
    "    #     otherImgIdx = otherCandidate[\"originalImage\"]\n",
    "    #     otherNormalVector = np.float32([\n",
    "    #         baseOptCenter[0] - otherCandidate[\"patchCenter\"][0],\n",
    "    #         baseOptCenter[1] - otherCandidate[\"patchCenter\"][1],\n",
    "    #         baseOptCenter[2] - otherCandidate[\"patchCenter\"][2]\n",
    "    #     ])\n",
    "    #     otherNormalVector = otherNormalVector / np.linalg.norm(otherNormalVector)\n",
    "    #     if np.dot(normalVector,otherNormalVector) > np.math.cos((np.math.pi/3)):\n",
    "    #         sImgs.append(otherCandidate)\n",
    "\n",
    "    # print(candidate,sImgs)\n",
    "    # # Calculate T(p)\n",
    "    # for sImg in sImgs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables needed by the objective function\n",
    "referenceImgIdx = 0\n",
    "depthVec = 0    \n",
    "optimPhotos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(center, normal, photo, opticalCenter):\n",
    "    depthVector = center - opticalCenter.reshape(4,1)\n",
    "    depth = np.linalg.norm(np.array(depthVector))\n",
    "    theta = np.math.acos(normal[2])#pitch\n",
    "    phi = np.math.atan2(normal[1], normal[0])#yaw\n",
    "    depthVector /= depth\n",
    "    return depth, theta, phi, depthVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(imageModel, unitDepthVec, depth, theta, phi):\n",
    "    opticalCenter = imageModel[\"optCenter\"]\n",
    "    depthVector = depth * unitDepthVec\n",
    "    center = opticalCenter.reshape(4,1) + depthVector\n",
    "    normal = np.zeros((4,1))\n",
    "    normal[0] = np.math.sin(theta)*np.math.cos(phi)\n",
    "    normal[1] = np.math.sin(theta)*np.math.sin(phi)\n",
    "    normal[2] = np.math.cos(theta)\n",
    "    return center, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_objective(center, rightVector, upVector, refPhotoModel, targetPhotosIDs):\n",
    "\n",
    "    cell1 = project_patch(center, refPhotoModel, rightVector, upVector)#overload to get the center  #TODO\n",
    "    SumNcc = 0\n",
    "    for i in range(len(targetPhotosIDs)):\n",
    "        photo = imagesModels[targetPhotosIDs[i]['idx']]\n",
    "        cell2 = project_patch(center, photo, rightVector, upVector)\n",
    "        SumNcc += ncc_score(cell1, cell2)\n",
    "    \n",
    "    return SumNcc / len(targetPhotosIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    depth, theta, phi = x[0], x[1], x[2]\n",
    "    center, normal = decode(imagesModels[referenceImgIdx], depthVec, depth, theta, phi)\n",
    "    #TODO#some conditions\n",
    "    if np.dot(imagesModels[referenceImgIdx][\"optAxis\"], depthVec) < 0:\n",
    "        return 1.0\n",
    "    \n",
    "    patch[\"center\"] = center\n",
    "    patch[\"normal\"] = normal\n",
    "    patch[\"referenceImgIdx\"] = referenceImgIdx\n",
    "    right, up = get_patch_vectors(patch) \n",
    "    return -ncc_objective(center, right, up, imagesModels[referenceImgIdx], optimPhotos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(depth, unitDepthVector, patchTrueSet):\n",
    "    sum = 0\n",
    "    for i in range (len(patchTrueSet)):\n",
    "        photo = imagesModels[patchTrueSet[i]['idx']]\n",
    "        depthVectorProj = np.matmul(photo['projMat'], unitDepthVector)\n",
    "        depthVectorProj /= depthVectorProj[2]\n",
    "        sum += np.linalg.norm(np.array(depthVectorProj[-1])) #remove t\n",
    "        \n",
    "    sum /= len(patchTrueSet)\n",
    "    unitDepthVector /= sum\n",
    "    depth *= sum\n",
    "    return depth, unitDepthVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_patch(patch):\n",
    "    global referenceImgIdx\n",
    "    global depthVec\n",
    "    global optimPhotos\n",
    "    refPhoto = imagesModels[patch[\"referenceImgIdx\"]][\"image\"]\n",
    "    opticalCenter = imagesModels[patch[\"referenceImgIdx\"]][\"optCenter\"]\n",
    "\n",
    "    depth, theta, phi, unitDepthVec = encode(patch[\"center\"], patch[\"normal\"], refPhoto, opticalCenter)\n",
    "    depth, unitDepthVec = normalize(depth, unitDepthVec, patch[\"trueSet\"]) #TODO add trueset to patch\n",
    "    targetPhotos = patch[\"trueSet\"]\n",
    "    referenceImgIdx, depthVec, optimPhotos = patch[\"referenceImgIdx\"], unitDepthVec, targetPhotos\n",
    "\n",
    "    #method := optimize.NelderMead{\n",
    "    #SimplexSize: 1,\n",
    "    #}\n",
    "    #converger := optimize.FunctionConverge{\n",
    "    #    Absolute:   0.0005,\n",
    "    #    Iterations: 10,\n",
    "    #}\n",
    "    #settings := optimize.Settings{\n",
    "    #MajorIterations: 1000,\n",
    "    #Converger:       &converger,\n",
    "    #}\n",
    "    #result, _ := optimize.Minimize(problem, []float64{depth, theta, phi}, &settings, &method)\n",
    "    \n",
    "    option = {\n",
    "        'disp': False, #Set to True to print convergence messages.\n",
    "        'maxiter': 1000,\n",
    "        'xatol': 0.0005,\n",
    "        'adaptive': False #adaptivebool, optional#Adapt algorithm parameters to dimensionality of problem. Useful for high-dimensional minimization\n",
    "        \n",
    "    }\n",
    "    initialGuess = np.array([depth, theta, phi])\n",
    "    solution  = minimize(objective, initialGuess, method='Nelder-Mead', options = option)\n",
    "    center, normal = decode(imagesModels[patch[\"referenceImgIdx\"]], unitDepthVec, solution.x[0], solution.x[1], solution.x[2])\n",
    "    patch[\"center\"], patch[\"normal\"] = center, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}