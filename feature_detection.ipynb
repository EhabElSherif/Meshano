{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from copy import copy,deepcopy\n",
    "from optical_center import getOpticalCenter\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_nth_maximum(arr,n):\n",
    "    uniqueValues = list(arr.flatten())\n",
    "    uniqueValues.sort()\n",
    "    if len(uniqueValues) < n:\n",
    "        return uniqueValues[0]\n",
    "    return uniqueValues[len(uniqueValues)-n]\n",
    "    # sortedmatrix.sort()\n",
    "    # # print(arr.shape)\n",
    "    # if sortedmatrix.size == 0:\n",
    "    #     return -1\n",
    "    # return sortedmatrix[0 if n > sortedmatrix.size else -n] \n",
    "\n",
    "def get_optical_axis(projectionMat):\n",
    "    return np.array([projectionMat[2][0],projectionMat[2][1],projectionMat[2][2],0])\n",
    "\n",
    "def outside_image_boundry(yCoord,xCoord):\n",
    "    return (xCoord < 0 or yCoord < 0 or xCoord >= len(imagesModels[0][\"image\"][0]) or yCoord >= len(imagesModels[0][\"image\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Data/dinoSparseRing/\"\n",
    "ß1 = 2\n",
    "ß2 = 32\n",
    "µ = 5       # the projection of one of its edges into R(p) is parallel to the image rows, and the smallest axis-aligned square containingits image covers a µ × µ pixel^2 area\n",
    "# We associate with p a reference image R(p),the images S(p) where p should be visible and the images T(p) where it is truly found \n",
    "gamma = 3\n",
    "\n",
    "cosMinAngle = np.math.cos(np.math.radians(20))\n",
    "cosMaxAngle = np.math.cos(np.math.radians(60))\n",
    "patchGridSize = 5\n",
    "'''\n",
    "patchModel = {\n",
    "    \"R\":None,\n",
    "    \"S\":set,\n",
    "    \"T\":set\n",
    "}\n",
    "# The cell C(i, j) keeps track of two different sets Qt(i, j) and Qf(i, j)\n",
    "cell = {\n",
    "    \"Qt\":list(),\n",
    "    \"Qf\":list()\n",
    "}\n",
    "# We associate with each image I a regular grid of β1×β1 pixel^2 cells\n",
    "imageModel = {\n",
    "    \"image\":None,\n",
    "    \"projMat\":None,\n",
    "    \"optCenter\":None,\n",
    "    \"grid\":None,\n",
    "    \"dog\":None,\n",
    "    \"harris\":None,\n",
    "    \"sparseDog\":None,\n",
    "    \"sparseHarris\":None,\n",
    "    \"dogPositions\":None,\n",
    "    \"harrisPositions\":None\n",
    "}\n",
    "'''\n",
    "cell = {\n",
    "    \"Qt\":list(),\n",
    "    \"Qf\":list()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image model from a given path\n",
    "def init_imgs(datasetPath):\n",
    "    # Read imgs\n",
    "    filesNames = glob(datasetPath+'*.png')\n",
    "    filesNames = sorted(filesNames)\n",
    "    # print(filesNames)\n",
    "    imgs = [cv.imread(file) for file in filesNames]\n",
    "    # imgs = [cv.rotate(cv.imread(file),cv.ROTATE_90_COUNTERCLOCKWISE) for file in glob(datasetPath+'*.png')]\n",
    "\n",
    "    # Construct corresponding image grid\n",
    "    #grids = [np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)]) for img in imgs]\n",
    "    grids = list()\n",
    "    for img in imgs:\n",
    "        grid = np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)])\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                \n",
    "                cell1={\n",
    "                    \"Qt\":list(),\n",
    "                    \"Qf\":list()\n",
    "                }\n",
    "                \n",
    "                grid[i][j] = cell1\n",
    "        grids.append(grid)\n",
    "        \n",
    "    return imgs,grids\n",
    "    \n",
    "# Read camera parameters and return the projection matrices for all pictures\n",
    "def read_parameters_file(datasetPath):\n",
    "    inputFile = open(datasetPath+\"dinoSR_par.txt\")\n",
    "    lines = inputFile.readlines()\n",
    "    lines.pop(0) # drop images number\n",
    "    projections = []\n",
    "    optAxes = []\n",
    "    # Every line is a parameters list for the corresponding image camera\n",
    "    for line in lines:\n",
    "        line = line[:-1]                # \\n character\n",
    "        linedata = line.split(' ')\n",
    "        imgName = linedata.pop(0)\n",
    "        k = np.zeros((3,3))\n",
    "        r = np.zeros((3,3))\n",
    "        t = np.zeros((3,1))\n",
    "\n",
    "        i = 0\n",
    "        for ridx,row in enumerate(k):\n",
    "            t[ridx][0]=linedata[ridx+18]\n",
    "            for colidx,_ in enumerate(row):\n",
    "                k[ridx][colidx]=linedata[i]\n",
    "                r[ridx][colidx]=linedata[i+9]\n",
    "                i+=1\n",
    "        x = np.concatenate((r,t),axis=1)\n",
    "        p = np.matmul(k,x)\n",
    "        projections.append(p)\n",
    "\n",
    "        optAxis = get_optical_axis(p)\n",
    "        optAxis *= np.linalg.det(p[:,:-1])\n",
    "        norm = np.linalg.norm(optAxis)\n",
    "        # optAxis[3] = p[2][3]\n",
    "        optAxis /= norm\n",
    "        optAxes.append(optAxis)\n",
    "\n",
    "        outputFile = open(datasetPath+\"projection/projection\"+imgName[6:10]+\".txt\",mode=\"w+\")\n",
    "        outputFile.write(\"CONTOUR\\n\")\n",
    "        pString = \"\"\n",
    "        for row in p:\n",
    "            for col in row:\n",
    "                pString += str('{0:0.5f}'.format(col))+\" \"\n",
    "            pString += \"\\n\"\n",
    "        outputFile.write(pString)\n",
    "        outputFile.close()\n",
    "        \n",
    "    return projections,optAxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Harris and DoG operators for a given image\n",
    "def get_dog_harris(img):\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "            \n",
    "    # Get DoG\n",
    "    g1 = cv.GaussianBlur(gray,(0,0),sigmaX=1)\n",
    "    g2 = cv.GaussianBlur(gray,(0,0),sigmaX=1*np.sqrt(2))\n",
    "    diff = cv.absdiff(g1,g2)\n",
    "    dog = diff * gray\n",
    "\n",
    "    # Get Harris\n",
    "    bSize = 3\n",
    "    kSize = 1\n",
    "    corners = cv.cornerHarris(src=gray,blockSize=bSize,ksize=kSize,k=0.06)\n",
    "    # corners = cv.dilate(corners,None)\n",
    "    \n",
    "    return dog , corners\n",
    "\n",
    "\n",
    "def sparse_dog_harris(dog,harris):\n",
    "    n = 4\n",
    "    sparseDog = copy(dog)\n",
    "    sparseHarris = copy(harris)\n",
    "    sparseDogPositions = []\n",
    "    sparseHarrisPositions = []\n",
    "    for yIdx in range(0,len(dog),ß2):\n",
    "        for xIdx in range(0,len(dog[0]),ß2):\n",
    "            nThMaximumDog = get_nth_maximum(dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumDog != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(dog[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumDog:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseDogPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseDog[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumDog)\n",
    "            nThMaximumHarris = get_nth_maximum(harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumHarris != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(harris[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumHarris:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseHarrisPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseHarris[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumHarris)\n",
    "            # show_images([dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]],['before dog','after dog','before harris','after harris'])\n",
    "\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    return sparseDog,sparseHarris,sparseDogPositions,sparseHarrisPositions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Fundmental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm.\n",
    "    each row is constructed as\n",
    "    [x’*x, x’*y, x’, y’*x, y’*y, y’, x, y, 1] \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # build matrix for equations\n",
    "    A = np.zeros((n,9))\n",
    "    for i in range(n):\n",
    "        A[i] = [x1[0,i]*x2[0,i], x1[0,i]*x2[1,i], x1[0,i]*x2[2,i],\n",
    "        x1[1,i]*x2[0,i], x1[1,i]*x2[1,i], x1[1,i]*x2[2,i],\n",
    "        x1[2,i]*x2[0,i], x1[2,i]*x2[1,i], x1[2,i]*x2[2,i] ]\n",
    "    \n",
    "    # compute linear least square solution\n",
    "    U,S,V = np.linalg.svd(A)\n",
    "    F = V[-1].reshape(3,3)\n",
    "    # constrain F\n",
    "    # make rank 2 by zeroing out last singular value\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    S[2] = 0\n",
    "    F = np.dot(U,np.dot(np.diag(S),V))\n",
    "    return F\n",
    "\n",
    "def compute_epipole(F):\n",
    "    \"\"\" Computes the (right) epipole from a\n",
    "    fundamental matrix F.\n",
    "    (Use with F.T for left epipole.) \"\"\"\n",
    "    # return null space of F (Fx=0)\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    e = V[-1]\n",
    "    return e/e[2]\n",
    "\n",
    "def plot_epipolar_line(im,F,x,epipole=None,show_epipole=True):\n",
    "    \"\"\" Plot the epipole and epipolar line F*x=0\n",
    "    in an image. F is the fundamental matrix\n",
    "    and x a point in the other image.\"\"\"\n",
    "    m,n = im.shape[:2]\n",
    "    line = np.dot(F,x)\n",
    "    # epipolar line parameter and values\n",
    "    t = np.linspace(0,n,100)\n",
    "    lt = np.array([(line[2]+line[0]*tt)/(-line[1]) for tt in t])\n",
    "    # take only line points inside the image\n",
    "    ndx = (lt>=0) & (lt<m)\n",
    "    plt.plot(t[ndx],lt[ndx],linewidth=2)\n",
    "    if show_epipole:\n",
    "        if epipole is None:\n",
    "            epipole = compute_epipole(F)\n",
    "        plt.plot(epipole[0]/epipole[2],epipole[1]/epipole[2],'r*')\n",
    "\n",
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_book(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    x1 = np.vstack( (pts1,np.ones(pts1.shape[1])) )\n",
    "    x2 = np.vstack( (pts2,np.ones(pts2.shape[1])) )\n",
    "\n",
    "    fundmentalMat = compute_fundamental(x1,x2)\n",
    "    # compute the epipole\n",
    "    e = compute_epipole(fundmentalMat)\n",
    "    \n",
    "    # plotting\n",
    "    plt.figure()\n",
    "    plt.imshow(images[0])\n",
    "    for i in range(5):\n",
    "        plot_epipolar_line(images[0],fundmentalMat,x2[:,i],e,False)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im2)\n",
    "    # plot each point individually, this gives same colors as the lines\n",
    "    for i in range(5):\n",
    "        plt.plot(x2[0,i],x2[1,i],'o')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_sift(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    fundmentalMat, _ = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewForm : skewForm(v).dot(u) = v cross u\n",
    "def skewForm(vec):\n",
    "    sk = np.zeros((3,3))\n",
    "    sk[0][0] = 0\n",
    "    sk[0][1] = -vec[2]\n",
    "    sk[0][2] = vec[1]\n",
    "    sk[1][0] = vec[2]\n",
    "    sk[1][1] = 0\n",
    "    sk[1][2] = -vec[0]\n",
    "    sk[2][0] = -vec[1]\n",
    "    sk[2][1] = vec[0]\n",
    "    sk[2][2] = 0\n",
    "    # sk = np.array(\n",
    "    #     [0,-vec[2],vec[1]],\n",
    "    #     [vec[2],0,-vec[0]],\n",
    "    #     [-vec[1],vec[0],0]\n",
    "    #     )\n",
    "\n",
    "    return sk\n",
    "\n",
    "def get_fundmental_matrix(img1,img2):\n",
    "    p00 = img1[\"projMat\"][0].reshape(1,4)\n",
    "    p01 = img1[\"projMat\"][1].reshape(1,4)\n",
    "    p02 = img1[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    p10 = img2[\"projMat\"][0].reshape(1,4)\n",
    "    p11 = img2[\"projMat\"][1].reshape(1,4)\n",
    "    p12 = img2[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    F = np.zeros((3,3))\n",
    "    \n",
    "    ppinv = np.zeros((3,3))\n",
    "\n",
    "    ppinv = np.matmul(img2[\"projMat\"], np.linalg.pinv(img1[\"projMat\"]))\n",
    "\n",
    "    epipole = np.zeros((3,1))\n",
    "\n",
    "    epipole = np.matmul(img2[\"projMat\"],img1[\"optCenter\"])\n",
    "    \n",
    "    funMat = np.zeros((3,3))\n",
    "\n",
    "    funMat = np.matmul(skewForm(epipole),ppinv)\n",
    "\n",
    "    return funMat\n",
    "\n",
    "    # F[0][0] = np.linalg.det(np.concatenate((p01, p02, p11, p12),axis=0))\n",
    "    # F[0][1] = np.linalg.det(np.concatenate((p01, p02, p12, p10),axis=0))\n",
    "    # F[0][2] = np.linalg.det(np.concatenate((p01, p02, p10, p11),axis=0))\n",
    "\n",
    "    # F[1][0] = np.linalg.det(np.concatenate((p02, p00, p11, p12),axis=0))\n",
    "    # F[1][1] = np.linalg.det(np.concatenate((p02, p00, p12, p10),axis=0))\n",
    "    # F[1][2] = np.linalg.det(np.concatenate((p02, p00, p10, p11),axis=0))\n",
    "\n",
    "    # F[2][0] = np.linalg.det(np.concatenate((p00, p01, p11, p12),axis=0))\n",
    "    # F[2][1] = np.linalg.det(np.concatenate((p00, p01, p12, p10),axis=0))\n",
    "    # F[2][2] = np.linalg.det(np.concatenate((p00, p01, p10, p11),axis=0))\n",
    "    \n",
    "    # return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Draw Epilines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the epilines corresponding to a point in the first image\n",
    "# Draw also the points satisfying epipolar consistancy \n",
    "def drawlines(img1,lines,pts1):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "\n",
    "    reducedFeaturesImage = copy(img1[\"image\"])\n",
    "    fullFeaturesImage = copy(img1[\"image\"])\n",
    "    r,c,_ = reducedFeaturesImage.shape\n",
    "    \n",
    "    for r,pt1 in zip(lines,pts1):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        cv.line(reducedFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "        cv.line(fullFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "    \n",
    "    \n",
    "    a = lines[0][0]\n",
    "    b = lines[0][1]\n",
    "    c = lines[0][2]\n",
    "    \n",
    "    maxDistance = 2 * np.sqrt((a**2)+(b**2)) \n",
    "    legalFeatures = []\n",
    "    for pt in pts1:\n",
    "        # color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        ptx = pt[0]\n",
    "        pty = pt[1]\n",
    "        if abs(a*ptx+b*pty+c) <= maxDistance :\n",
    "            cv.circle(reducedFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            legalFeatures.append(np.float32([ptx,pty]))\n",
    "        else:\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(255,0,0),-1)\n",
    "\n",
    "    return fullFeaturesImage,reducedFeaturesImage,legalFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables needed by the objective function\n",
    "referenceImgIdx = 0\n",
    "depthVec = 0    \n",
    "optimPhotos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(center, normal, photo, opticalCenter):\n",
    "    depthVector = center - opticalCenter.reshape(4,1)\n",
    "    depth = np.linalg.norm(np.array(depthVector))\n",
    "    theta = np.math.acos(normal[2])#pitch\n",
    "    phi = np.math.atan2(normal[1], normal[0])#yaw\n",
    "    depthVector /= depth\n",
    "    return depth, theta, phi, depthVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(imageModel, unitDepthVec, depth, theta, phi):\n",
    "    opticalCenter = imageModel[\"optCenter\"]\n",
    "    depthVector = depth * unitDepthVec\n",
    "    center = opticalCenter.reshape(4,1) + depthVector\n",
    "    normal = np.zeros((4,1))\n",
    "    normal[0] = np.math.sin(theta)*np.math.cos(phi)\n",
    "    normal[1] = np.math.sin(theta)*np.math.sin(phi)\n",
    "    normal[2] = np.math.cos(theta)\n",
    "    return center, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_objective(center, rightVector, upVector, refPhotoModel, targetPhotosIDs):\n",
    "\n",
    "    cell1 = project_patch(center, refPhotoModel, rightVector, upVector)#overload to get the center  #TODO\n",
    "    SumNcc = 0\n",
    "    for i in range(len(targetPhotosIDs)):\n",
    "        photo = imagesModels[targetPhotosIDs[i]['idx']]\n",
    "        cell2 = project_patch(center, photo, rightVector, upVector)\n",
    "        SumNcc += ncc_score(cell1, cell2)\n",
    "    \n",
    "    return SumNcc / len(targetPhotosIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    depth, theta, phi = x[0], x[1], x[2]\n",
    "    center, normal = decode(imagesModels[referenceImgIdx], depthVec, depth, theta, phi)\n",
    "    #TODO#some conditions\n",
    "    if np.dot(imagesModels[referenceImgIdx][\"optAxis\"], depthVec) < 0:\n",
    "        return 1.0\n",
    "    patch = {}\n",
    "    patch[\"center\"] = center\n",
    "    patch[\"normal\"] = normal\n",
    "    patch[\"referenceImgIdx\"] = referenceImgIdx\n",
    "    right, up = get_patch_vectors(patch) \n",
    "    return -ncc_objective(center, right, up, imagesModels[referenceImgIdx], optimPhotos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(depth, unitDepthVector, patchTrueSet):\n",
    "    sum = 0\n",
    "    for i in range (len(patchTrueSet)):\n",
    "        photo = imagesModels[patchTrueSet[i]['idx']]\n",
    "        depthVectorProj = np.matmul(photo['projMat'], unitDepthVector)\n",
    "        depthVectorProj /= depthVectorProj[2]\n",
    "        sum += np.linalg.norm(np.array(depthVectorProj[-1])) #remove t\n",
    "        \n",
    "    sum /= len(patchTrueSet)\n",
    "    unitDepthVector /= sum\n",
    "    depth *= sum\n",
    "    return depth, unitDepthVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_patch(patch):\n",
    "    global referenceImgIdx\n",
    "    global depthVec\n",
    "    global optimPhotos\n",
    "    refPhoto = imagesModels[patch[\"referenceImgIdx\"]][\"image\"]\n",
    "    opticalCenter = imagesModels[patch[\"referenceImgIdx\"]][\"optCenter\"]\n",
    "\n",
    "    depth, theta, phi, unitDepthVec = encode(patch[\"center\"], patch[\"normal\"], refPhoto, opticalCenter)\n",
    "    depth, unitDepthVec = normalize(depth, unitDepthVec, patch[\"trueSet\"]) #TODO add trueset to patch\n",
    "    targetPhotos = patch[\"trueSet\"]\n",
    "    referenceImgIdx, depthVec, optimPhotos = patch[\"referenceImgIdx\"], unitDepthVec, targetPhotos\n",
    "\n",
    "    option = {\n",
    "        'disp': False, #Set to True to print convergence messages.\n",
    "        'maxiter': 1000,\n",
    "        'xatol': 0.0005,\n",
    "        'adaptive': False #adaptivebool, optional#Adapt algorithm parameters to dimensionality of problem. Useful for high-dimensional minimization\n",
    "        \n",
    "    }\n",
    "    initialGuess = np.array([depth, theta, phi])\n",
    "    solution  = minimize(objective, initialGuess, method='Nelder-Mead', options = option)\n",
    "    center, normal = decode(imagesModels[patch[\"referenceImgIdx\"]], unitDepthVec, solution.x[0], solution.x[1], solution.x[2])\n",
    "    patch[\"center\"], patch[\"normal\"] = center, normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Relevent Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevent_images(imgModels,idx):\n",
    "    releventImages = []\n",
    "    myOptAxis = imgModels[idx][\"optAxis\"]\n",
    "\n",
    "    for i in range(len(imgModels)):\n",
    "        if i == idx:\n",
    "            continue\n",
    "        otherOptAxis = imgModels[i][\"optAxis\"]\n",
    "        cosAngle = np.dot(myOptAxis,otherOptAxis)\n",
    "\n",
    "        if cosMinAngle > cosAngle > cosMaxAngle:\n",
    "            releventImages.append(i)\n",
    "\n",
    "    return releventImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get v/t Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_score(cell1,cell2):\n",
    "    mean1 = np.mean(cell1)\n",
    "    mean2 = np.mean(cell2)\n",
    "    \n",
    "    std1 = std2 = product = 0\n",
    "\t\n",
    "    for i in range(len(cell1)):\n",
    "        diff1 = cell1[i] - mean1\n",
    "        diff2 = cell2[i] - mean2\n",
    "        product += diff1 * diff2\n",
    "        std1 += diff1 * diff1\n",
    "        std2 += diff2 * diff2\n",
    "\t\n",
    "    stds = std1 * std2\n",
    "    if stds == 0:\n",
    "        return 0\n",
    "\n",
    "    return product / np.math.sqrt(stds)\n",
    "\n",
    "def project_patch(patchCenter,imgModel,rightVector,upVector):\n",
    "    cell = np.zeros(patchGridSize*patchGridSize*3)\n",
    "    \n",
    "    projMat = imgModel[\"projMat\"]\n",
    "    projCenter = np.matmul(projMat,patchCenter)\n",
    "    projRight = np.matmul(projMat,rightVector).reshape(3,1)\n",
    "    projUp = np.matmul(projMat,upVector).reshape(3,1)\n",
    "\n",
    "    scale = 1/projCenter[2]\n",
    "    projCenter = scale * projCenter\n",
    "    projRight = scale * projRight\n",
    "    projUp = scale * projUp\n",
    "\n",
    "    step = (patchGridSize-1)/2\n",
    "    diagVector = projUp + projRight\n",
    "    diagVector = step * diagVector\n",
    "    topLeftVector = projCenter - diagVector\n",
    "\n",
    "    cellIdx = 0\n",
    "    for i in range(patchGridSize):\n",
    "        for j in range(patchGridSize):\n",
    "            xCoord = topLeftVector[0] + i*projUp[0] + j*projRight[0]\n",
    "            yCoord = topLeftVector[1] + i*projUp[1] + j*projRight[1]\n",
    "            yCoord = int(yCoord+0.5)\n",
    "            xCoord = int(xCoord+0.5)\n",
    "\n",
    "            # pixel is outside the image\n",
    "            if outside_image_boundry(yCoord,xCoord):\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = 0,0,0\n",
    "            else:\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = imgModel[\"image\"][yCoord][xCoord]\n",
    "\n",
    "            cellIdx +=3\n",
    "\n",
    "    return cell\n",
    "\n",
    "def get_ncc_score(patch,releventImgModel,rightVector,upVector):\n",
    "    referenceImgModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "\n",
    "    cell1 = project_patch(patch[\"center\"],referenceImgModel,rightVector,upVector)\n",
    "    cell2 = project_patch(patch[\"center\"],releventImgModel,rightVector,upVector)\n",
    "    return ncc_score(cell1,cell2)\n",
    "\n",
    "def get_patch_vectors(patch):\n",
    "    referenceImageModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "    projMat = referenceImageModel[\"projMat\"]\n",
    "\n",
    "    ppinv = np.linalg.pinv(projMat)\n",
    "\n",
    "    scale = np.dot(ppinv[:,0],patch[\"normal\"])\n",
    "    rightVector = ppinv[:,0].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "    scale = np.dot(ppinv[:,1],patch[\"normal\"])\n",
    "    upVector = ppinv[:,1].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "\n",
    "    scale = np.dot(projMat[2],patch[\"center\"])\n",
    "    rightVector = (scale/(np.dot(projMat[0],rightVector)))*rightVector\n",
    "    upVector = (scale/(np.dot(projMat[1],upVector)))*upVector\n",
    "\n",
    "    return rightVector, upVector\n",
    "\n",
    "def get_t_images(patch,alfa,visibleImgsIdx):\n",
    "    tImages = []\n",
    "\n",
    "    rightVector,upVector = get_patch_vectors(patch)\n",
    "    for visibleImageIdx in visibleImgsIdx:\n",
    "        visibleImageModel = imagesModels[visibleImageIdx]\n",
    "        \n",
    "        depthVector = np.float32([\n",
    "            visibleImageModel[\"optCenter\"][0] - patch[\"center\"][0],\n",
    "            visibleImageModel[\"optCenter\"][1] - patch[\"center\"][1],\n",
    "            visibleImageModel[\"optCenter\"][2] - patch[\"center\"][2],\n",
    "            visibleImageModel[\"optCenter\"][3] - patch[\"center\"][3]\n",
    "        ])\n",
    "\n",
    "        if np.dot(np.squeeze(depthVector), np.squeeze(patch[\"normal\"])) <= 0:\n",
    "            continue\n",
    "        \n",
    "        nccScore = get_ncc_score(patch, visibleImageModel, rightVector, upVector)\n",
    "        if nccScore > alfa:\n",
    "            imgCoord = np.matmul(visibleImageModel['projMat'], patch['center'])\n",
    "            imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "            \n",
    "            x = int(imgCoord[0][0]) // ß1\n",
    "            y = int(imgCoord[1][0]) // ß1\n",
    "            tImages.append({\n",
    "                \"idx\":visibleImageIdx,\n",
    "                \"cell\":{\n",
    "                    'ptx':x,\n",
    "                    'pty':y\n",
    "                },\n",
    "                \"ncc\":nccScore\n",
    "            }) #TODO remove nccscore if not used\n",
    "    \n",
    "    return tImages\n",
    "\n",
    "def get_visible_images(patch,baseImageIdx):\n",
    "    sImgs = []\n",
    "    for releventImgIdx in imagesModels[baseImageIdx][\"releventImgsIdxs\"]:\n",
    "        vec = imagesModels[releventImgIdx]['optCenter'].reshape(4,1) - patch['center']\n",
    "        vec = vec/(np.linalg.norm(vec))\n",
    "        if np.dot(np.squeeze(patch['normal']),np.squeeze(vec)) > np.math.cos((np.math.pi/3)):\n",
    "            sImgs.append({'idx':releventImgIdx})\n",
    "    return sImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_patch(patch):\n",
    "    for sImg in patch[\"visibleSet\"]:\n",
    "        imgModel = imagesModels[sImg['idx']]\n",
    "        imgCoord = np.matmul(imgModel['projMat'], patch['center'])\n",
    "        imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "\n",
    "        x = int(imgCoord[0][0]) // ß1\n",
    "        y = int(imgCoord[1][0]) // ß1\n",
    "        cell1 = imgModel['grid'][y][x]\n",
    "        \n",
    "        if not any(imgIdx == sImg['idx'] for imgIdx in patch['trueSet']):\n",
    "            cell1['Qf'].append(patch)\n",
    "        else:\n",
    "            cell1['Qt'].append(patch)\n",
    "        \n",
    "        sImg['cell'] = {\n",
    "            'ptx':x,\n",
    "            'pty':y,\n",
    "        }\n",
    "    patches.append(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_cell(imageID, y, x):\n",
    "    cell_y = y // ß1\n",
    "    cell_x = x // ß1\n",
    "    if len(imagesModels[imageID]['grid'][cell_y][cell_x]['Qt']) == 0 and len(imagesModels[imageID]['grid'][cell_y][cell_x]['Qf']) == 0 :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_statsify_epipoler_consistency(baseImageIdx, featurePt):\n",
    "    triangulations = list()\n",
    "    for i in range(len(imagesModels[baseImageIdx][\"releventImgsIdxs\"])):\n",
    "        releventImageIdx = imagesModels[baseImageIdx][\"releventImgsIdxs\"][i]\n",
    "        fundmentalMat = get_fundmental_matrix(imagesModels[baseImageIdx],imagesModels[releventImageIdx])\n",
    "\n",
    "        if fundmentalMat is None:\n",
    "            continue\n",
    "        pt1 = featurePt\n",
    "        pts1 = np.int32([pt1])\n",
    "        pts2 = np.int32(imagesModels[releventImageIdx][\"dogPositions\"])\n",
    "\n",
    "        originalWithFeaturePt = imagesModels[baseImageIdx][\"image\"].copy()\n",
    "        cv.circle(originalWithFeaturePt,tuple(pt1),5,(0,0,255),-1)\n",
    "\n",
    "        # Get the epilines of features in left image on the right image\n",
    "        # parameter1: points required to get its epilines in the other image\n",
    "        # parameter2: which image that points are belong, 1-left 2-right\n",
    "        # parameter3: fundmental matrix between the 2 images\n",
    "        # returns list of epilines that lie on the other image and corresponding to the points\n",
    "        lines = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,fundmentalMat)\n",
    "        lines = lines.reshape(-1,3)\n",
    "        #sara_im = plot_epipolar_line(imagesModels[i][\"image\"],fundmentalMat,[pt1[0],pt1[1],1])\n",
    "\n",
    "        # draw the epiline on the other image\n",
    "        # parameter1: the second image\n",
    "        # parameter2: the epilines that lie on the second image\n",
    "        # parameter3: the features lie on the second image\n",
    "        fullFeaturesImage,reducedFeaturesImage,legalFeatures = drawlines(imagesModels[releventImageIdx],lines,pts2)\n",
    "\n",
    "        #Triangulation\n",
    "        for j in range(len(legalFeatures)):\n",
    "            if not(empty_cell(releventImageIdx, int(legalFeatures[j][1]), int(legalFeatures[j][0]))): #TODO check t = 1\n",
    "                continue\n",
    "                \n",
    "            triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[baseImageIdx][\"projMat\"],imagesModels[releventImageIdx][\"projMat\"],pt1,legalFeatures[j])\n",
    "            triangulatedPoint = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :]\n",
    "\n",
    "            #triangulatedPoint = triangulate_point(np.array([pt1[0], pt1[1],1]),legalFeatures[j],imagesModels[baseImageIdx][\"projMat\"],imagesModels[i][\"projMat\"])\n",
    "\n",
    "            distFromcenter = abs(abs(np.linalg.norm(np.array(imagesModels[baseImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))) - abs(np.linalg.norm(np.array(imagesModels[releventImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))))\n",
    "\n",
    "            triangulation = {\n",
    "                \"originalImg\": releventImageIdx,\n",
    "                \"position\": triangulatedPoint,\n",
    "                \"distFromCenter\": distFromcenter,\n",
    "                \"ptx\": legalFeatures[j][0],\n",
    "                \"pty\": legalFeatures[j][1]\n",
    "            }\n",
    "\n",
    "            triangulations.append(triangulation)\n",
    "\n",
    "        #show_images([imagesModels[baseImageIdx][\"image\"],imagesModels[releventImageIdx][\"image\"],fullFeaturesImage,reducedFeaturesImage, originalWithFeaturePt],[\"image\"+str(baseImageIdx),\"image\"+str(releventImageIdx),\"fullfeatures in image\"+str(releventImageIdx),\"reducedfeatures in image\"+str(releventImageIdx), \"originalWithFeaturePt\"+str(releventImageIdx)])\n",
    "\n",
    "    triangulations = sorted(triangulations, key=lambda k: k[\"distFromCenter\"]) \n",
    "    #for i in range(len(triangulations)):\n",
    "        #print(\"triangulations: \", triangulations[i][\"originalImg\"], \"ptx\", triangulations[i][\"ptx\"], \"pty\", triangulations[i][\"pty\"], triangulations[i][\"distFromCenter\"])\n",
    "    \n",
    "    return triangulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_patches(baseImageIdx, triangulations):\n",
    "    #print(\"construct_patches ...\")\n",
    "    baseOptCenter = imagesModels[baseImageIdx][\"optCenter\"]\n",
    "    for candidate in triangulations:\n",
    "\n",
    "        patch = {}\n",
    "        patch[\"referenceImgIdx\"] = baseImageIdx\n",
    "        patch[\"center\"] = candidate[\"position\"]\n",
    "        patch[\"normal\"] = np.float32([\n",
    "                baseOptCenter[0] - candidate[\"position\"][0],\n",
    "                baseOptCenter[1] - candidate[\"position\"][1],\n",
    "                baseOptCenter[2] - candidate[\"position\"][2],\n",
    "                baseOptCenter[3] - candidate[\"position\"][3],\n",
    "            ])\n",
    "        patch[\"normal\"] = patch[\"normal\"] / np.linalg.norm(patch[\"normal\"])\n",
    "\n",
    "        sImgs = []\n",
    "        for releventImgIdx in imagesModels[baseImageIdx][\"releventImgsIdxs\"]:\n",
    "            vec = imagesModels[releventImgIdx]['optCenter'].reshape(4,1) - patch['center']\n",
    "            vec = vec/(np.linalg.norm(vec))\n",
    "            if np.dot(np.squeeze(patch['normal']),np.squeeze(vec)) > np.math.cos((np.math.pi/3)):\n",
    "                sImgs.append(releventImgIdx)\n",
    "        # print(len(sImgs),len(imagesModels[baseImageIdx][\"releventImgsIdxs\"]))\n",
    "        #TODO add alpha1,2 to constants in paper, 0.4,0.7....0.6,0.3\n",
    "        patch[\"trueSet\"] = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"]) \n",
    "\n",
    "        #print(\"len(patch[trueSet]): \", len(patch[\"trueSet\"]))\n",
    "        if len(patch[\"trueSet\"]) <= 1 : \n",
    "            continue\n",
    "\n",
    "        optimize_patch(patch)\n",
    "        patch[\"visibleSet\"] = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"]) \n",
    "        patch[\"trueSet\"] = get_t_images(patch,0.7,imagesModels[baseImageIdx][\"releventImgsIdxs\"])\n",
    "        #print(\"len(patch[trueSet]): \", len(patch[\"trueSet\"]), \" gamma: \", gamma)\n",
    "        if len(patch[\"trueSet\"]) >= gamma:\n",
    "            register_patch(patch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Read Input---->DONE\nFeature Detection---->DONE\nGet Relevent Images---->DONE\n"
    }
   ],
   "source": [
    "images,grids = init_imgs(datasetPath)\n",
    "projections,optAxes = read_parameters_file(datasetPath)\n",
    "print(\"Read Input---->DONE\")\n",
    "imagesModels = list()\n",
    "\n",
    "for idx,image in enumerate(images):\n",
    "    dog,harris = get_dog_harris(image)\n",
    "    sparseDog,sparseHarris,dogPositions,harrisPositions = sparse_dog_harris(dog,harris)\n",
    "    opticalCenter = getOpticalCenter(projections[idx])\n",
    "    imgModel={\n",
    "        \"image\": images[idx],\n",
    "        \"projMat\": projections[idx],\n",
    "        \"optCenter\": opticalCenter,\n",
    "        \"optAxis\": optAxes[idx],\n",
    "        \"grid\": grids[idx],\n",
    "        \"dog\": dog,\n",
    "        \"harris\": harris,\n",
    "        \"sparseDog\": sparseDog,\n",
    "        \"sparseHarris\": sparseHarris,\n",
    "        \"dogPositions\": dogPositions,\n",
    "        \"harrisPositions\": harrisPositions\n",
    "    }\n",
    "    \n",
    "    imagesModels.append(imgModel)\n",
    "\n",
    "print(\"Feature Detection---->DONE\")\n",
    "\n",
    "for i in range(len(imagesModels)):\n",
    "    imagesModels[i][\"releventImgsIdxs\"] = get_relevent_images(imagesModels,i)\n",
    "    \n",
    "print(\"Get Relevent Images---->DONE\")\n",
    "# show_images([imagesModels[0][\"dog\"],imagesModels[0][\"sparseDog\"],imagesModels[0][\"harris\"],imagesModels[0][\"sparseHarris\"]],['dog','sparse dog','harris','sparse harris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Start Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start Matching....\nTotal number of patches:  0\nImageID:  0  Number of Features:  276\nImageID:  0 ----> Done\t Number of constructed patches:  84\nImageID:  1  Number of Features:  283\nImageID:  1 ----> Done\t Number of constructed patches:  126\nImageID:  2  Number of Features:  212\nImageID:  2 ----> Done\t Number of constructed patches:  101\nImageID:  3  Number of Features:  183\nImageID:  3 ----> Done\t Number of constructed patches:  80\nImageID:  4  Number of Features:  237\nImageID:  4 ----> Done\t Number of constructed patches:  67\nImageID:  5  Number of Features:  214\nImageID:  5 ----> Done\t Number of constructed patches:  54\nImageID:  6  Number of Features:  232\nImageID:  6 ----> Done\t Number of constructed patches:  79\nImageID:  7  Number of Features:  264\nImageID:  7 ----> Done\t Number of constructed patches:  118\nImageID:  8  Number of Features:  285\nImageID:  8 ----> Done\t Number of constructed patches:  123\nImageID:  9  Number of Features:  285\nImageID:  9 ----> Done\t Number of constructed patches:  132\nImageID:  10  Number of Features:  282\nImageID:  10 ----> Done\t Number of constructed patches:  101\nImageID:  11  Number of Features:  218\nImageID:  11 ----> Done\t Number of constructed patches:  64\nImageID:  12  Number of Features:  186\nImageID:  12 ----> Done\t Number of constructed patches:  43\nImageID:  13  Number of Features:  168\nImageID:  13 ----> Done\t Number of constructed patches:  68\nImageID:  14  Number of Features:  198\nImageID:  14 ----> Done\t Number of constructed patches:  86\nImageID:  15  Number of Features:  258\nImageID:  15 ----> Done\t Number of constructed patches:  73\nTotal number of patches:1399\n"
    }
   ],
   "source": [
    "print(\"Start Matching....\")\n",
    "patches = list()\n",
    "numberOfPatches = 0\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "for i in range(len(imagesModels)):\n",
    "    baseImageIdx = i\n",
    "    print(\"ImageID: \", str(baseImageIdx),\" Number of Features: \", str(len(imagesModels[baseImageIdx][\"dogPositions\"])))\n",
    "    for featurePt in imagesModels[baseImageIdx][\"dogPositions\"]:\n",
    "        if not(empty_cell(baseImageIdx, featurePt[1], featurePt[0])):\n",
    "            # print(\"non empty cell\")\n",
    "            continue\n",
    "        #print(\"empty cell\")\n",
    "        features  = get_features_statsify_epipoler_consistency(baseImageIdx, featurePt)\n",
    "        construct_patches(baseImageIdx, features)\n",
    "    print(\"ImageID: \", str(baseImageIdx), \"----> Done\\t\",\"Number of constructed patches: \", str(len(patches) - numberOfPatches))\n",
    "    numberOfPatches = len(patches)\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "originalImageModels = deepcopy(imagesModels)\n",
    "originalPatches = deepcopy(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_header(file):\n",
    "    file.write(\"ply\\n\")\n",
    "    file.write(\"format ascii 1.0\\n\")\n",
    "    file.write( \"element vertex \"+ str(len(patches)) + \"\\n\")\n",
    "    file.write( \"property float x\\n\")\n",
    "    file.write(\"property float y\\n\")\n",
    "    file.write(\"property float z\\n\")\n",
    "    file.write(\"property float nx\\n\")\n",
    "    file.write(\"property float ny\\n\")\n",
    "    file.write(\"property float nz\\n\")\n",
    "    file.write(\"property uchar diffuse_red\\n\")\n",
    "    file.write(\"property uchar diffuse_green\\n\")\n",
    "    file.write(\"property uchar diffuse_blue\\n\")\n",
    "    file.write( \"end_header\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply(): \n",
    "    file = open(\"pointcloud.txt.ply\", \"w\")\n",
    "    write_header(file)\n",
    "    for patch in patches:\n",
    "        file.write(str(patch[\"center\"][0][0]) + \" \" +  str(patch[\"center\"][1][0]) + \" \" + str(patch[\"center\"][2][0]) + \" \")\n",
    "        file.write(str(patch[\"normal\"][0][0]) + \" \" +  str(patch[\"normal\"][1][0]) + \" \" + str(patch[\"normal\"][2][0]) + \" \")\n",
    "        file.write(\"255\"+ \" \" + \"0\" + \" \"+\"0\")\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "write_ply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": " 4689 \tremaining patches: 4139\nThe total number of patches now: 4689 \tremaining patches: 4138\nThe total number of patches now: 4689 \tremaining patches: 4137\nThe total number of patches now: 4692 \tremaining patches: 4139\nThe total number of patches now: 4697 \tremaining patches: 4143\nThe total number of patches now: 4707 \tremaining patches: 4152\nThe total number of patches now: 4714 \tremaining patches: 4158\nThe total number of patches now: 4724 \tremaining patches: 4167\nThe total number of patches now: 4736 \tremaining patches: 4178\nThe total number of patches now: 4748 \tremaining patches: 4189\nThe total number of patches now: 4748 \tremaining patches: 4188\nThe total number of patches now: 4755 \tremaining patches: 4194\nThe total number of patches now: 4760 \tremaining patches: 4198\nThe total number of patches now: 4764 \tremaining patches: 4201\nThe total number of patches now: 4771 \tremaining patches: 4207\nThe total number of patches now: 4775 \tremaining patches: 4210\nThe total number of patches now: 4781 \tremaining patches: 4215\nThe total number of patches now: 4781 \tremaining patches: 4214\nThe total number of patches now: 4785 \tremaining patches: 4217\nThe total number of patches now: 4787 \tremaining patches: 4218\nThe total number of patches now: 4790 \tremaining patches: 4220\nThe total number of patches now: 4802 \tremaining patches: 4231\nThe total number of patches now: 4813 \tremaining patches: 4241\nThe total number of patches now: 4819 \tremaining patches: 4246\nThe total number of patches now: 4820 \tremaining patches: 4246\nThe total number of patches now: 4820 \tremaining patches: 4245\nThe total number of patches now: 4821 \tremaining patches: 4245\nThe total number of patches now: 4823 \tremaining patches: 4246\nThe total number of patches now: 4825 \tremaining patches: 4247\nThe total number of patches now: 4832 \tremaining patches: 4253\nThe total number of patches now: 4836 \tremaining patches: 4256\nThe total number of patches now: 4836 \tremaining patches: 4255\nThe total number of patches now: 4843 \tremaining patches: 4261\nThe total number of patches now: 4849 \tremaining patches: 4266\nThe total number of patches now: 4855 \tremaining patches: 4271\nThe total number of patches now: 4863 \tremaining patches: 4278\nThe total number of patches now: 4874 \tremaining patches: 4288\nThe total number of patches now: 4876 \tremaining patches: 4289\nThe total number of patches now: 4880 \tremaining patches: 4292\nThe total number of patches now: 4888 \tremaining patches: 4299\nThe total number of patches now: 4895 \tremaining patches: 4305\nThe total number of patches now: 4902 \tremaining patches: 4311\nThe total number of patches now: 4902 \tremaining patches: 4310\nThe total number of patches now: 4903 \tremaining patches: 4310\nThe total number of patches now: 4908 \tremaining patches: 4314\nThe total number of patches now: 4916 \tremaining patches: 4321\nThe total number of patches now: 4920 \tremaining patches: 4324\nThe total number of patches now: 4920 \tremaining patches: 4323\nThe total number of patches now: 4926 \tremaining patches: 4328\nThe total number of patches now: 4931 \tremaining patches: 4332\nThe total number of patches now: 4936 \tremaining patches: 4336\nThe total number of patches now: 4948 \tremaining patches: 4347\nThe total number of patches now: 4960 \tremaining patches: 4358\nThe total number of patches now: 4973 \tremaining patches: 4370\nThe total number of patches now: 4976 \tremaining patches: 4372\nThe total number of patches now: 4979 \tremaining patches: 4374\nThe total number of patches now: 4984 \tremaining patches: 4378\nThe total number of patches now: 4996 \tremaining patches: 4389\nThe total number of patches now: 5006 \tremaining patches: 4398\nThe total number of patches now: 5011 \tremaining patches: 4402\nThe total number of patches now: 5013 \tremaining patches: 4403\nThe total number of patches now: 5026 \tremaining patches: 4415\nThe total number of patches now: 5037 \tremaining patches: 4425\nThe total number of patches now: 5042 \tremaining patches: 4429\nThe total number of patches now: 5045 \tremaining patches: 4431\nThe total number of patches now: 5051 \tremaining patches: 4436\nThe total number of patches now: 5053 \tremaining patches: 4437\nThe total number of patches now: 5053 \tremaining patches: 4436\nThe total number of patches now: 5062 \tremaining patches: 4444\nThe total number of patches now: 5074 \tremaining patches: 4455\nThe total number of patches now: 5080 \tremaining patches: 4460\nThe total number of patches now: 5092 \tremaining patches: 4471\nThe total number of patches now: 5103 \tremaining patches: 4481\nThe total number of patches now: 5103 \tremaining patches: 4480\nThe total number of patches now: 5108 \tremaining patches: 4484\nThe total number of patches now: 5110 \tremaining patches: 4485\nThe total number of patches now: 5110 \tremaining patches: 4484\nThe total number of patches now: 5118 \tremaining patches: 4491\nThe total number of patches now: 5129 \tremaining patches: 4501\nThe total number of patches now: 5134 \tremaining patches: 4505\nThe total number of patches now: 5138 \tremaining patches: 4508\nThe total number of patches now: 5140 \tremaining patches: 4509\nThe total number of patches now: 5140 \tremaining patches: 4508\nThe total number of patches now: 5149 \tremaining patches: 4516\nThe total number of patches now: 5151 \tremaining patches: 4517\nThe total number of patches now: 5165 \tremaining patches: 4530\nThe total number of patches now: 5180 \tremaining patches: 4544\nThe total number of patches now: 5180 \tremaining patches: 4543\nThe total number of patches now: 5186 \tremaining patches: 4548\nThe total number of patches now: 5186 \tremaining patches: 4547\nThe total number of patches now: 5187 \tremaining patches: 4547\nThe total number of patches now: 5188 \tremaining patches: 4547\nThe total number of patches now: 5191 \tremaining patches: 4549\nThe total number of patches now: 5191 \tremaining patches: 4548\nThe total number of patches now: 5207 \tremaining patches: 4563\nThe total number of patches now: 5214 \tremaining patches: 4569\nThe total number of patches now: 5215 \tremaining patches: 4569\nThe total number of patches now: 5222 \tremaining patches: 4575\nThe total number of patches now: 5233 \tremaining patches: 4585\nThe total number of patches now: 5241 \tremaining patches: 4592\nThe total number of patches now: 5243 \tremaining patches: 4593\nThe total number of patches now: 5243 \tremaining patches: 4592\nThe total number of patches now: 5243 \tremaining patches: 4591\nThe total number of patches now: 5251 \tremaining patches: 4598\nThe total number of patches now: 5253 \tremaining patches: 4599\nThe total number of patches now: 5258 \tremaining patches: 4603\nThe total number of patches now: 5270 \tremaining patches: 4614\nThe total number of patches now: 5283 \tremaining patches: 4626\nThe total number of patches now: 5295 \tremaining patches: 4637\nThe total number of patches now: 5295 \tremaining patches: 4636\nThe total number of patches now: 5295 \tremaining patches: 4635\nThe total number of patches now: 5295 \tremaining patches: 4634\nThe total number of patches now: 5307 \tremaining patches: 4645\nThe total number of patches now: 5312 \tremaining patches: 4649\nThe total number of patches now: 5313 \tremaining patches: 4649\nThe total number of patches now: 5314 \tremaining patches: 4649\nThe total number of patches now: 5317 \tremaining patches: 4651\nThe total number of patches now: 5320 \tremaining patches: 4653\nThe total number of patches now: 5329 \tremaining patches: 4661\nThe total number of patches now: 5341 \tremaining patches: 4672\nThe total number of patches now: 5357 \tremaining patches: 4687\nThe total number of patches now: 5373 \tremaining patches: 4702\nThe total number of patches now: 5377 \tremaining patches: 4705\nThe total number of patches now: 5377 \tremaining patches: 4704\nThe total number of patches now: 5382 \tremaining patches: 4708\nThe total number of patches now: 5382 \tremaining patches: 4707\nThe total number of patches now: 5382 \tremaining patches: 4706\nThe total number of patches now: 5385 \tremaining patches: 4708\nThe total number of patches now: 5395 \tremaining patches: 4717\nThe total number of patches now: 5411 \tremaining patches: 4732\nThe total number of patches now: 5424 \tremaining patches: 4744\nThe total number of patches now: 5440 \tremaining patches: 4759\nThe total number of patches now: 5443 \tremaining patches: 4761\nThe total number of patches now: 5445 \tremaining patches: 4762\nThe total number of patches now: 5449 \tremaining patches: 4765\nThe total number of patches now: 5456 \tremaining patches: 4771\nThe total number of patches now: 5462 \tremaining patches: 4776\nThe total number of patches now: 5469 \tremaining patches: 4782\nThe total number of patches now: 5485 \tremaining patches: 4797\nThe total number of patches now: 5497 \tremaining patches: 4808\nThe total number of patches now: 5513 \tremaining patches: 4823\nThe total number of patches now: 5525 \tremaining patches: 4834\nThe total number of patches now: 5530 \tremaining patches: 4838\nThe total number of patches now: 5530 \tremaining patches: 4837\nThe total number of patches now: 5532 \tremaining patches: 4838\nThe total number of patches now: 5535 \tremaining patches: 4840\nThe total number of patches now: 5535 \tremaining patches: 4839\nThe total number of patches now: 5546 \tremaining patches: 4849\nThe total number of patches now: 5557 \tremaining patches: 4859\nThe total number of patches now: 5573 \tremaining patches: 4874\nThe total number of patches now: 5581 \tremaining patches: 4881\nThe total number of patches now: 5585 \tremaining patches: 4884\nThe total number of patches now: 5588 \tremaining patches: 4886\nThe total number of patches now: 5598 \tremaining patches: 4895\nThe total number of patches now: 5606 \tremaining patches: 4902\nThe total number of patches now: 5618 \tremaining patches: 4913\nThe total number of patches now: 5634 \tremaining patches: 4928\nThe total number of patches now: 5638 \tremaining patches: 4931\nThe total number of patches now: 5642 \tremaining patches: 4934\nThe total number of patches now: 5650 \tremaining patches: 4941\nThe total number of patches now: 5650 \tremaining patches: 4940\nThe total number of patches now: 5656 \tremaining patches: 4945\nThe total number of patches now: 5661 \tremaining patches: 4949\nThe total number of patches now: 5672 \tremaining patches: 4959\nThe total number of patches now: 5682 \tremaining patches: 4968\nThe total number of patches now: 5691 \tremaining patches: 4976\nThe total number of patches now: 5694 \tremaining patches: 4978\nThe total number of patches now: 5694 \tremaining patches: 4977\nThe total number of patches now: 5698 \tremaining patches: 4980\nThe total number of patches now: 5698 \tremaining patches: 4979\nThe total number of patches now: 5708 \tremaining patches: 4988\nThe total number of patches now: 5720 \tremaining patches: 4999\nThe total number of patches now: 5731 \tremaining patches: 5009\nThe total number of patches now: 5739 \tremaining patches: 5016\nThe total number of patches now: 5748 \tremaining patches: 5024\nThe total number of patches now: 5749 \tremaining patches: 5024\nThe total number of patches now: 5761 \tremaining patches: 5035\nThe total number of patches now: 5761 \tremaining patches: 5034\nThe total number of patches now: 5770 \tremaining patches: 5042\nThe total number of patches now: 5780 \tremaining patches: 5051\nThe total number of patches now: 5790 \tremaining patches: 5060\nThe total number of patches now: 5799 \tremaining patches: 5068\nThe total number of patches now: 5803 \tremaining patches: 5071\nThe total number of patches now: 5811 \tremaining patches: 5078\nThe total number of patches now: 5825 \tremaining patches: 5091\nThe total number of patches now: 5828 \tremaining patches: 5093\nThe total number of patches now: 5829 \tremaining patches: 5093\nThe total number of patches now: 5830 \tremaining patches: 5093\nThe total number of patches now: 5833 \tremaining patches: 5095\nThe total number of patches now: 5833 \tremaining patches: 5094\nThe total number of patches now: 5840 \tremaining patches: 5100\nThe total number of patches now: 5854 \tremaining patches: 5113\nThe total number of patches now: 5860 \tremaining patches: 5118\nThe total number of patches now: 5864 \tremaining patches: 5121\nThe total number of patches now: 5865 \tremaining patches:5121\nThe total number of patches now: 5865 \tremaining patches: 5120\nThe total number of patches now: 5868 \tremaining patches: 5122\nThe total number of patches now: 5873 \tremaining patches: 5126\nThe total number of patches now: 5885 \tremaining patches: 5137\nThe total number of patches now: 5895 \tremaining patches: 5146\nThe total number of patches now: 5895 \tremaining patches: 5145\nThe total number of patches now: 5895 \tremaining patches: 5144\nThe total number of patches now: 5897 \tremaining patches: 5145\nThe total number of patches now: 5902 \tremaining patches: 5149\nThe total number of patches now: 5912 \tremaining patches: 5158\nThe total number of patches now: 5915 \tremaining patches: 5160\nThe total number of patches now: 5917 \tremaining patches: 5161\nThe total number of patches now: 5920 \tremaining patches: 5163\nThe total number of patches now: 5927 \tremaining patches: 5169\nThe total number of patches now: 5928 \tremaining patches: 5169\nThe total number of patches now: 5936 \tremaining patches: 5176\nThe total number of patches now: 5943 \tremaining patches: 5182\nThe total number of patches now: 5944 \tremaining patches: 5182\nThe total number of patches now: 5956 \tremaining patches: 5193\nThe total number of patches now: 5972 \tremaining patches: 5208\nThe total number of patches now: 5972 \tremaining patches: 5207\nThe total number of patches now: 5977 \tremaining patches: 5211\nThe total number of patches now: 5980 \tremaining patches: 5213\nThe total number of patches now: 5992 \tremaining patches: 5224\nThe total number of patches now: 5998 \tremaining patches: 5229\nThe total number of patches now: 6011 \tremaining patches: 5241\nThe total number of patches now: 6027 \tremaining patches: 5256\nThe total number of patches now: 6035 \tremaining patches: 5263\nThe total number of patches now: 6040 \tremaining patches: 5267\nThe total number of patches now: 6040 \tremaining patches: 5266\nThe total number of patches now: 6042 \tremaining patches: 5267\nThe total number of patches now: 6047 \tremaining patches: 5271\nThe total number of patches now: 6063 \tremaining patches: 5286\nThe total number of patches now: 6078 \tremaining patches: 5300\nThe total number of patches now: 6078 \tremaining patches: 5299\nThe total number of patches now: 6079 \tremaining patches: 5299\nThe total number of patches now: 6079 \tremaining patches: 5298\nThe total number of patches now: 6083 \tremaining patches: 5301\nThe total number of patches now: 6090 \tremaining patches: 5307\nThe total number of patches now: 6096 \tremaining patches: 5312\nThe total number of patches now: 6106 \tremaining patches: 5321\nThe total number of patches now: 6122 \tremaining patches: 5336\nThe total number of patches now: 6134 \tremaining patches: 5347\nThe total number of patches now: 6142 \tremaining patches: 5354\nThe total number of patches now: 6143 \tremaining patches: 5354\nThe total number of patches now: 6143 \tremaining patches: 5353\nThe total number of patches now: 6144 \tremaining patches: 5353\nThe total number of patches now: 6146 \tremaining patches: 5354\nThe total number of patches now: 6150 \tremaining patches: 5357\nThe total number of patches now: 6166 \tremaining patches: 5372\nThe total number of patches now: 6182 \tremaining patches: 5387\nThe total number of patches now: 6197 \tremaining patches: 5401\nThe total number of patches now: 6203 \tremaining patches: 5406\nThe total number of patches now: 6203 \tremaining patches: 5405\nThe total number of patches now: 6203 \tremaining patches: 5404\nThe total number of patches now: 6205 \tremaining patches: 5405\nThe total number of patches now: 6208 \tremaining patches: 5407\nThe total number of patches now: 6218 \tremaining patches: 5416\nThe total number of patches now: 6225 \tremaining patches: 5422\nThe total number of patches now: 6229 \tremaining patches: 5425\nThe total number of patches now: 6233 \tremaining patches: 5428\nThe total number of patches now: 6244 \tremaining patches: 5438\nThe total number of patches now: 6260 \tremaining patches: 5453\nThe total number of patches now: 6262 \tremaining patches: 5454\nThe total number of patches now: 6263 \tremaining patches: 5454\nThe total number of patches now: 6266 \tremaining patches: 5456\nThe total number of patches now: 6266 \tremaining patches:5455\nThe total number of patches now: 6269 \tremaining patches: 5457\nThe total number of patches now: 6272 \tremaining patches: 5459\nThe total number of patches now: 6285 \tremaining patches: 5471\nThe total number of patches now: 6295 \tremaining patches: 5480\nThe total number of patches now: 6309 \tremaining patches: 5493\nThe total number of patches now: 6324 \tremaining patches: 5507\nThe total number of patches now: 6340 \tremaining patches: 5522\nThe total number of patches now: 6345 \tremaining patches: 5526\nThe total number of patches now: 6352 \tremaining patches: 5532\nThe total number of patches now: 6352 \tremaining patches: 5531\nThe total number of patches now: 6353 \tremaining patches: 5531\nThe total number of patches now: 6362 \tremaining patches: 5539\nThe total number of patches now: 6372 \tremaining patches: 5548\nThe total number of patches now: 6388 \tremaining patches: 5563\nThe total number of patches now: 6404 \tremaining patches: 5578\nThe total number of patches now: 6415 \tremaining patches: 5588\nThe total number of patches now: 6425 \tremaining patches: 5597\nThe total number of patches now: 6433 \tremaining patches: 5604\nThe total number of patches now: 6447 \tremaining patches: 5617\nThe total number of patches now: 6459 \tremaining patches: 5628\nThe total number of patches now: 6475 \tremaining patches: 5643\nThe total number of patches now: 6475 \tremaining patches: 5642\nThe total number of patches now: 6475 \tremaining patches: 5641\nThe total number of patches now: 6479 \tremaining patches: 5644\nThe total number of patches now: 6487 \tremaining patches: 5651\nThe total number of patches now: 6487 \tremaining patches: 5650\nThe total number of patches now: 6495 \tremaining patches: 5657\nThe total number of patches now: 6499 \tremaining patches: 5660\nThe total number of patches now: 6499 \tremaining patches: 5659\nThe total number of patches now: 6499 \tremaining patches: 5658\nThe total number of patches now: 6503 \tremaining patches: 5661\nThe total number of patches now: 6505 \tremaining patches: 5662\nThe total number of patches now: 6506 \tremaining patches: 5662\nThe total number of patches now: 6507 \tremaining patches: 5662\nThe total number of patches now: 6514 \tremaining patches: 5668\nThe total number of patches now: 6514 \tremaining patches: 5667\nThe total number of patches now: 6520 \tremaining patches: 5672\nThe total number of patches now: 6527 \tremaining patches: 5678\nThe total number of patches now: 6532 \tremaining patches: 5682\nThe total number of patches now: 6532 \tremaining patches: 5681\nThe total number of patches now: 6532 \tremaining patches: 5680\nThe total number of patches now: 6532 \tremaining patches: 5679\nThe total number of patches now: 6532 \tremaining patches: 5678\nThe total number of patches now: 6533 \tremaining patches: 5678\nThe total number of patches now: 6541 \tremaining patches: 5685\nThe total number of patches now: 6541 \tremaining patches: 5684\nThe total number of patches now: 6541 \tremaining patches: 5683\nThe total number of patches now: 6541 \tremaining patches: 5682\nThe total number of patches now: 6541 \tremaining patches: 5681\nThe total number of patches now: 6550 \tremaining patches: 5689\nThe total number of patches now: 6554 \tremaining patches: 5692\nThe total number of patches now: 6561 \tremaining patches: 5698\nThe total number of patches now: 6565 \tremaining patches: 5701\nThe total number of patches now: 6565 \tremaining patches: 5700\nThe total number of patches now: 6575 \tremaining patches: 5709\nThe total number of patches now: 6582 \tremaining patches: 5715\n"
    }
   ],
   "source": [
    "print(\"Start Expansion....\")\n",
    "patches = deepcopy(originalPatches)\n",
    "totalPatches = deepcopy(originalPatches)\n",
    "imagesModels = deepcopy(originalImageModels)\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "while len(patches) != 0:\n",
    "    print(\"The total number of patches now:\",len(totalPatches),\"\\tremaining patches:\",len(patches))\n",
    "    patch = patches.pop(0)\n",
    "    neighborCells = []\n",
    "\n",
    "    # Get neighbor cells\n",
    "    for idx,visibleImage in enumerate(patch['visibleSet']):\n",
    "        x = visibleImage['cell']['ptx']\n",
    "        y = visibleImage['cell']['pty']\n",
    "        \n",
    "        # if id(patch) in [id(otherPatch) for otherPatch in imagesModels[visibleImage['idx']]['grid'][y][x]['Qf']]:\n",
    "        #     continue\n",
    "            \n",
    "        # Get neighbor cells\n",
    "        for neighborY in range(y-1,y+2,1):\n",
    "            for neighborX in range(x-1,x+2,1):\n",
    "                # diagonal cells\n",
    "                if (abs(neighborY-y) + abs(neighborX-x)) != 1:\n",
    "                    continue\n",
    "\n",
    "                if not outside_image_boundry(neighborY,neighborX):\n",
    "                    neighborCell = imagesModels[visibleImage['idx']]['grid'][neighborY][neighborX]\n",
    "                    # non empty cell Qt\n",
    "                    if len(neighborCell['Qt']) != 0:\n",
    "                        continue\n",
    "                        \n",
    "                    projMat = imagesModels[visibleImage['idx']]['projMat']\n",
    "                    projCenter = np.matmul(projMat,patch['center'])\n",
    "                    scale = 1/projCenter[2]\n",
    "                    projCenter = scale * projCenter\n",
    "                    hasNeighbor = False\n",
    "                    \n",
    "                    for otherPatch in neighborCell['Qf']:\n",
    "                        otherProjCenter = np.matmul(projMat,otherPatch['center'])\n",
    "                        scale = 1/otherProjCenter[2]\n",
    "                        otherProjCenter = scale * otherProjCenter\n",
    "                        \n",
    "                        left =  np.abs(np.dot(np.squeeze(otherPatch['center']-patch['center']),np.squeeze(patch['normal']))) + np.abs(np.dot(np.squeeze(otherPatch['center']-patch['center']),np.squeeze(otherPatch['normal'])))\n",
    "                        right = np.linalg.norm(projCenter-otherProjCenter)\n",
    "\n",
    "                        rowProj = np.matmul(imagesModels[patch[\"referenceImgIdx\"]]['projMat'],(imagesModels[patch[\"referenceImgIdx\"]]['optCenter'].reshape(4,1) - ((patch['center']+otherPatch['center'])/2)))\n",
    "\n",
    "                        if left < 2* right :\n",
    "                            hasNeighbor = True\n",
    "                            break\n",
    "\n",
    "                    if hasNeighbor == True:\n",
    "                        # print(\"ARE neighbors\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        # print(\"not neighbors\")\n",
    "                        neighborCells.append({\n",
    "                              \"x\":neighborX,\n",
    "                              \"y\":neighborY,\n",
    "                              \"neighborCell\":neighborCell\n",
    "                            })\n",
    "                        \n",
    "    for neighborCell in neighborCells:\n",
    "        newPatch = {}\n",
    "        newPatch[\"referenceImgIdx\"] = patch[\"referenceImgIdx\"]\n",
    "        newPatch[\"normal\"] = patch[\"normal\"]\n",
    "        newPatch[\"trueSet\"] = patch[\"trueSet\"]\n",
    "\n",
    "        # Get the ray\n",
    "        cellCenter = np.array([neighborCell['x'],neighborCell['y'],1]).reshape(3,1)\n",
    "        projMat = imagesModels[patch['referenceImgIdx']][\"projMat\"]\n",
    "        ppinv = np.linalg.pinv(projMat)\n",
    "        ray = np.matmul(ppinv,cellCenter)+imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)\n",
    "        ray = ray / np.linalg.norm(ray)\n",
    "        \n",
    "        if abs(np.dot(np.squeeze(ray),np.squeeze(newPatch['normal']))) < 10**-6:\n",
    "          print(\"ray parallel to patch\")\n",
    "          continue\n",
    "\n",
    "        # Get the intersection\n",
    "        t = (- np.dot(np.squeeze(patch['normal']),np.squeeze(imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1) - patch['center'])))/(np.dot(np.squeeze(patch['normal']),np.squeeze(ray)))\n",
    "        intersection = t*ray + imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)\n",
    "\n",
    "        newPatch['center'] = intersection\n",
    "        optimize_patch(newPatch)\n",
    "        newPatch[\"visibleSet\"] = patch['trueSet']\n",
    "        newVImgs = get_t_images(newPatch,0.6,imagesModels[newPatch[\"referenceImgIdx\"]][\"releventImgsIdxs\"])\n",
    "\n",
    "        for newVImg in newVImgs:\n",
    "            found = False\n",
    "            for vImg in newPatch[\"visibleSet\"]:\n",
    "                if newVImg['idx'] == vImg['idx']:\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                newPatch[\"visibleSet\"].append(newVImg)\n",
    "        \n",
    "        visibleIdxs = [vImg['idx'] for vImg in newPatch[\"visibleSet\"]]\n",
    "        newPatch[\"trueSet\"] = get_t_images(newPatch,0.7,visibleIdxs)\n",
    "        #print(\"len(newPatch[trueSet]): \", len(newPatch[\"trueSet\"]), \" gamma: \", gamma)\n",
    "        if len(newPatch[\"trueSet\"]) >= gamma:\n",
    "            register_patch(newPatch)\n",
    "            totalPatches.append(newPatch)\n",
    "\n",
    "        # print(intersection)\n",
    "        # d = - np.dot(np.squeeze(patch['normal']),np.squeeze(imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1))) \n",
    "        # xx, yy = np.meshgrid(range(10), range(10))\n",
    "        # z = (-patch['normal'][0] * xx - patch['normal'][1] * yy - d) * 1. /patch['normal'][2]\n",
    "        # plt3d = plt.figure().gca(projection='3d')\n",
    "        # plt3d.plot_surface(xx, yy, z)\n",
    "        # x = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[0]]\n",
    "        # y = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[1]]\n",
    "        # z = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[2]]\n",
    "        # xi = [intersection[0]]\n",
    "        # yi = [intersection[1]]\n",
    "        # zi = [intersection[2]]\n",
    "        # plt3d.scatter(x,y,z,c='r')\n",
    "        # plt3d.scatter(xi,yi,zi,c='y')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherPatches = [patches[i] for i in range(0,10)]\n",
    "# patchx = patches[9]\n",
    "# id(patchx) in [id(pthPatch) for pthPatch in otherPatches]"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python36764bitbaseconda671ffe7150094cd9ba8c9cb5c362aaeb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}