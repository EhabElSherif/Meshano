{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from copy import copy,deepcopy\n",
    "from optical_center import getOpticalCenter\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_nth_maximum(arr,n):\n",
    "    uniqueValues = list(arr.flatten())\n",
    "    uniqueValues.sort()\n",
    "    if len(uniqueValues) < n:\n",
    "        return uniqueValues[0]\n",
    "    return uniqueValues[len(uniqueValues)-n]\n",
    "    # sortedmatrix.sort()\n",
    "    # # print(arr.shape)\n",
    "    # if sortedmatrix.size == 0:\n",
    "    #     return -1\n",
    "    # return sortedmatrix[0 if n > sortedmatrix.size else -n] \n",
    "\n",
    "def get_optical_axis(projectionMat):\n",
    "    return np.array([projectionMat[2][0],projectionMat[2][1],projectionMat[2][2],0])\n",
    "\n",
    "def outside_image_boundry(yCoord,xCoord):\n",
    "    return (xCoord < 0 or yCoord < 0 or xCoord >= len(imagesModels[0][\"image\"][0]) or yCoord >= len(imagesModels[0][\"image\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Data/dinoSparseRing/\"\n",
    "ß1 = 2\n",
    "ß2 = 32\n",
    "µ = 5       # the projection of one of its edges into R(p) is parallel to the image rows, and the smallest axis-aligned square containingits image covers a µ × µ pixel^2 area\n",
    "# We associate with p a reference image R(p),the images S(p) where p should be visible and the images T(p) where it is truly found \n",
    "gamma = 3\n",
    "\n",
    "cosMinAngle = np.math.cos(np.math.radians(20))\n",
    "cosMaxAngle = np.math.cos(np.math.radians(60))\n",
    "patchGridSize = 5\n",
    "'''\n",
    "patchModel = {\n",
    "    \"R\":None,\n",
    "    \"S\":set,\n",
    "    \"T\":set\n",
    "}\n",
    "# The cell C(i, j) keeps track of two different sets Qt(i, j) and Qf(i, j)\n",
    "cell = {\n",
    "    \"Qt\":list(),\n",
    "    \"Qf\":list()\n",
    "}\n",
    "# We associate with each image I a regular grid of β1×β1 pixel^2 cells\n",
    "imageModel = {\n",
    "    \"image\":None,\n",
    "    \"projMat\":None,\n",
    "    \"optCenter\":None,\n",
    "    \"grid\":None,\n",
    "    \"dog\":None,\n",
    "    \"harris\":None,\n",
    "    \"sparseDog\":None,\n",
    "    \"sparseHarris\":None,\n",
    "    \"dogPositions\":None,\n",
    "    \"harrisPositions\":None\n",
    "}\n",
    "'''\n",
    "cell = {\n",
    "    \"Qt\":list(),\n",
    "    \"Qf\":list()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image model from a given path\n",
    "def init_imgs(datasetPath):\n",
    "    # Read imgs\n",
    "    filesNames = glob(datasetPath+'*.png')\n",
    "    filesNames = sorted(filesNames)\n",
    "    # print(filesNames)\n",
    "    imgs = [cv.imread(file) for file in filesNames]\n",
    "    # imgs = [cv.rotate(cv.imread(file),cv.ROTATE_90_COUNTERCLOCKWISE) for file in glob(datasetPath+'*.png')]\n",
    "\n",
    "    # Construct corresponding image grid\n",
    "    #grids = [np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)]) for img in imgs]\n",
    "    grids = list()\n",
    "    for img in imgs:\n",
    "        grid = np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)])\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                \n",
    "                cell1={\n",
    "                    \"Qt\":list(),\n",
    "                    \"Qf\":list()\n",
    "                }\n",
    "                \n",
    "                grid[i][j] = cell1\n",
    "        grids.append(grid)\n",
    "        \n",
    "    return imgs,grids\n",
    "    \n",
    "# Read camera parameters and return the projection matrices for all pictures\n",
    "def read_parameters_file(datasetPath):\n",
    "    inputFile = open(datasetPath+\"dinoSR_par.txt\")\n",
    "    lines = inputFile.readlines()\n",
    "    lines.pop(0) # drop images number\n",
    "    projections = []\n",
    "    optAxes = []\n",
    "    # Every line is a parameters list for the corresponding image camera\n",
    "    for line in lines:\n",
    "        line = line[:-1]                # \\n character\n",
    "        linedata = line.split(' ')\n",
    "        imgName = linedata.pop(0)\n",
    "        k = np.zeros((3,3))\n",
    "        r = np.zeros((3,3))\n",
    "        t = np.zeros((3,1))\n",
    "\n",
    "        i = 0\n",
    "        for ridx,row in enumerate(k):\n",
    "            t[ridx][0]=linedata[ridx+18]\n",
    "            for colidx,_ in enumerate(row):\n",
    "                k[ridx][colidx]=linedata[i]\n",
    "                r[ridx][colidx]=linedata[i+9]\n",
    "                i+=1\n",
    "        x = np.concatenate((r,t),axis=1)\n",
    "        p = np.matmul(k,x)\n",
    "        projections.append(p)\n",
    "\n",
    "        optAxis = get_optical_axis(p)\n",
    "        optAxis *= np.linalg.det(p[:,:-1])\n",
    "        norm = np.linalg.norm(optAxis)\n",
    "        # optAxis[3] = p[2][3]\n",
    "        optAxis /= norm\n",
    "        optAxes.append(optAxis)\n",
    "\n",
    "        outputFile = open(datasetPath+\"projection/projection\"+imgName[6:10]+\".txt\",mode=\"w+\")\n",
    "        outputFile.write(\"CONTOUR\\n\")\n",
    "        pString = \"\"\n",
    "        for row in p:\n",
    "            for col in row:\n",
    "                pString += str('{0:0.5f}'.format(col))+\" \"\n",
    "            pString += \"\\n\"\n",
    "        outputFile.write(pString)\n",
    "        outputFile.close()\n",
    "        \n",
    "    return projections,optAxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Harris and DoG operators for a given image\n",
    "def get_dog_harris(img):\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "            \n",
    "    # Get DoG\n",
    "    g1 = cv.GaussianBlur(gray,(0,0),sigmaX=1)\n",
    "    g2 = cv.GaussianBlur(gray,(0,0),sigmaX=1*np.sqrt(2))\n",
    "    diff = cv.absdiff(g1,g2)\n",
    "    dog = diff * gray\n",
    "\n",
    "    # Get Harris\n",
    "    bSize = 3\n",
    "    kSize = 1\n",
    "    corners = cv.cornerHarris(src=gray,blockSize=bSize,ksize=kSize,k=0.06)\n",
    "    # corners = cv.dilate(corners,None)\n",
    "    \n",
    "    return dog , corners\n",
    "\n",
    "\n",
    "def sparse_dog_harris(dog,harris):\n",
    "    n = 4\n",
    "    sparseDog = copy(dog)\n",
    "    sparseHarris = copy(harris)\n",
    "    sparseDogPositions = []\n",
    "    sparseHarrisPositions = []\n",
    "    for yIdx in range(0,len(dog),ß2):\n",
    "        for xIdx in range(0,len(dog[0]),ß2):\n",
    "            nThMaximumDog = get_nth_maximum(dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumDog != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(dog[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumDog:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseDogPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseDog[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumDog)\n",
    "            nThMaximumHarris = get_nth_maximum(harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumHarris != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(harris[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumHarris:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseHarrisPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseHarris[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumHarris)\n",
    "            # show_images([dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]],['before dog','after dog','before harris','after harris'])\n",
    "\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    return sparseDog,sparseHarris,sparseDogPositions,sparseHarrisPositions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Fundmental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm.\n",
    "    each row is constructed as\n",
    "    [x’*x, x’*y, x’, y’*x, y’*y, y’, x, y, 1] \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # build matrix for equations\n",
    "    A = np.zeros((n,9))\n",
    "    for i in range(n):\n",
    "        A[i] = [x1[0,i]*x2[0,i], x1[0,i]*x2[1,i], x1[0,i]*x2[2,i],\n",
    "        x1[1,i]*x2[0,i], x1[1,i]*x2[1,i], x1[1,i]*x2[2,i],\n",
    "        x1[2,i]*x2[0,i], x1[2,i]*x2[1,i], x1[2,i]*x2[2,i] ]\n",
    "    \n",
    "    # compute linear least square solution\n",
    "    U,S,V = np.linalg.svd(A)\n",
    "    F = V[-1].reshape(3,3)\n",
    "    # constrain F\n",
    "    # make rank 2 by zeroing out last singular value\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    S[2] = 0\n",
    "    F = np.dot(U,np.dot(np.diag(S),V))\n",
    "    return F\n",
    "\n",
    "def compute_epipole(F):\n",
    "    \"\"\" Computes the (right) epipole from a\n",
    "    fundamental matrix F.\n",
    "    (Use with F.T for left epipole.) \"\"\"\n",
    "    # return null space of F (Fx=0)\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    e = V[-1]\n",
    "    return e/e[2]\n",
    "\n",
    "def plot_epipolar_line(im,F,x,epipole=None,show_epipole=True):\n",
    "    \"\"\" Plot the epipole and epipolar line F*x=0\n",
    "    in an image. F is the fundamental matrix\n",
    "    and x a point in the other image.\"\"\"\n",
    "    m,n = im.shape[:2]\n",
    "    line = np.dot(F,x)\n",
    "    # epipolar line parameter and values\n",
    "    t = np.linspace(0,n,100)\n",
    "    lt = np.array([(line[2]+line[0]*tt)/(-line[1]) for tt in t])\n",
    "    # take only line points inside the image\n",
    "    ndx = (lt>=0) & (lt<m)\n",
    "    plt.plot(t[ndx],lt[ndx],linewidth=2)\n",
    "    if show_epipole:\n",
    "        if epipole is None:\n",
    "            epipole = compute_epipole(F)\n",
    "        plt.plot(epipole[0]/epipole[2],epipole[1]/epipole[2],'r*')\n",
    "\n",
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_book(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    x1 = np.vstack( (pts1,np.ones(pts1.shape[1])) )\n",
    "    x2 = np.vstack( (pts2,np.ones(pts2.shape[1])) )\n",
    "\n",
    "    fundmentalMat = compute_fundamental(x1,x2)\n",
    "    # compute the epipole\n",
    "    e = compute_epipole(fundmentalMat)\n",
    "    \n",
    "    # plotting\n",
    "    plt.figure()\n",
    "    plt.imshow(images[0])\n",
    "    for i in range(5):\n",
    "        plot_epipolar_line(images[0],fundmentalMat,x2[:,i],e,False)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im2)\n",
    "    # plot each point individually, this gives same colors as the lines\n",
    "    for i in range(5):\n",
    "        plt.plot(x2[0,i],x2[1,i],'o')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_sift(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    fundmentalMat, _ = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewForm : skewForm(v).dot(u) = v cross u\n",
    "def skewForm(vec):\n",
    "    sk = np.zeros((3,3))\n",
    "    sk[0][0] = 0\n",
    "    sk[0][1] = -vec[2]\n",
    "    sk[0][2] = vec[1]\n",
    "    sk[1][0] = vec[2]\n",
    "    sk[1][1] = 0\n",
    "    sk[1][2] = -vec[0]\n",
    "    sk[2][0] = -vec[1]\n",
    "    sk[2][1] = vec[0]\n",
    "    sk[2][2] = 0\n",
    "    # sk = np.array(\n",
    "    #     [0,-vec[2],vec[1]],\n",
    "    #     [vec[2],0,-vec[0]],\n",
    "    #     [-vec[1],vec[0],0]\n",
    "    #     )\n",
    "\n",
    "    return sk\n",
    "\n",
    "def get_fundmental_matrix(img1,img2):\n",
    "    p00 = img1[\"projMat\"][0].reshape(1,4)\n",
    "    p01 = img1[\"projMat\"][1].reshape(1,4)\n",
    "    p02 = img1[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    p10 = img2[\"projMat\"][0].reshape(1,4)\n",
    "    p11 = img2[\"projMat\"][1].reshape(1,4)\n",
    "    p12 = img2[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    F = np.zeros((3,3))\n",
    "    \n",
    "    ppinv = np.zeros((3,3))\n",
    "\n",
    "    ppinv = np.matmul(img2[\"projMat\"], np.linalg.pinv(img1[\"projMat\"]))\n",
    "\n",
    "    epipole = np.zeros((3,1))\n",
    "\n",
    "    epipole = np.matmul(img2[\"projMat\"],img1[\"optCenter\"])\n",
    "    \n",
    "    funMat = np.zeros((3,3))\n",
    "\n",
    "    funMat = np.matmul(skewForm(epipole),ppinv)\n",
    "\n",
    "    return funMat\n",
    "\n",
    "    # F[0][0] = np.linalg.det(np.concatenate((p01, p02, p11, p12),axis=0))\n",
    "    # F[0][1] = np.linalg.det(np.concatenate((p01, p02, p12, p10),axis=0))\n",
    "    # F[0][2] = np.linalg.det(np.concatenate((p01, p02, p10, p11),axis=0))\n",
    "\n",
    "    # F[1][0] = np.linalg.det(np.concatenate((p02, p00, p11, p12),axis=0))\n",
    "    # F[1][1] = np.linalg.det(np.concatenate((p02, p00, p12, p10),axis=0))\n",
    "    # F[1][2] = np.linalg.det(np.concatenate((p02, p00, p10, p11),axis=0))\n",
    "\n",
    "    # F[2][0] = np.linalg.det(np.concatenate((p00, p01, p11, p12),axis=0))\n",
    "    # F[2][1] = np.linalg.det(np.concatenate((p00, p01, p12, p10),axis=0))\n",
    "    # F[2][2] = np.linalg.det(np.concatenate((p00, p01, p10, p11),axis=0))\n",
    "    \n",
    "    # return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Draw Epilines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the epilines corresponding to a point in the first image\n",
    "# Draw also the points satisfying epipolar consistancy \n",
    "def drawlines(img1,lines,pts1):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "\n",
    "    reducedFeaturesImage = copy(img1[\"image\"])\n",
    "    fullFeaturesImage = copy(img1[\"image\"])\n",
    "    r,c,_ = reducedFeaturesImage.shape\n",
    "    \n",
    "    for r,pt1 in zip(lines,pts1):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        cv.line(reducedFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "        cv.line(fullFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "    \n",
    "    \n",
    "    a = lines[0][0]\n",
    "    b = lines[0][1]\n",
    "    c = lines[0][2]\n",
    "    \n",
    "    maxDistance = 2 * np.sqrt((a**2)+(b**2)) \n",
    "    legalFeatures = []\n",
    "    for pt in pts1:\n",
    "        # color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        ptx = pt[0]\n",
    "        pty = pt[1]\n",
    "        if abs(a*ptx+b*pty+c) <= maxDistance :\n",
    "            cv.circle(reducedFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            legalFeatures.append(np.float32([ptx,pty]))\n",
    "        else:\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(255,0,0),-1)\n",
    "\n",
    "    return fullFeaturesImage,reducedFeaturesImage,legalFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables needed by the objective function\n",
    "referenceImgIdx = 0\n",
    "depthVec = 0    \n",
    "optimPhotos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(center, normal, photo, opticalCenter):\n",
    "    depthVector = center - opticalCenter.reshape(4,1)\n",
    "    depth = np.linalg.norm(np.array(depthVector))\n",
    "    theta = np.math.acos(normal[2])#pitch\n",
    "    phi = np.math.atan2(normal[1], normal[0])#yaw\n",
    "    depthVector /= depth\n",
    "    return depth, theta, phi, depthVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(imageModel, unitDepthVec, depth, theta, phi):\n",
    "    opticalCenter = imageModel[\"optCenter\"]\n",
    "    depthVector = depth * unitDepthVec\n",
    "    center = opticalCenter.reshape(4,1) + depthVector\n",
    "    normal = np.zeros((4,1))\n",
    "    normal[0] = np.math.sin(theta)*np.math.cos(phi)\n",
    "    normal[1] = np.math.sin(theta)*np.math.sin(phi)\n",
    "    normal[2] = np.math.cos(theta)\n",
    "    return center, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_objective(center, rightVector, upVector, refPhotoModel, targetPhotosIDs):\n",
    "\n",
    "    cell1 = project_patch(center, refPhotoModel, rightVector, upVector)#overload to get the center  #TODO\n",
    "    SumNcc = 0\n",
    "    for i in range(len(targetPhotosIDs)):\n",
    "        photo = imagesModels[targetPhotosIDs[i]['idx']]\n",
    "        cell2 = project_patch(center, photo, rightVector, upVector)\n",
    "        SumNcc += ncc_score(cell1, cell2)\n",
    "    \n",
    "    return SumNcc / len(targetPhotosIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    depth, theta, phi = x[0], x[1], x[2]\n",
    "    center, normal = decode(imagesModels[referenceImgIdx], depthVec, depth, theta, phi)\n",
    "    #TODO#some conditions\n",
    "    if np.dot(imagesModels[referenceImgIdx][\"optAxis\"], depthVec) < 0:\n",
    "        return 1.0\n",
    "    patch = {}\n",
    "    patch[\"center\"] = center\n",
    "    patch[\"normal\"] = normal\n",
    "    patch[\"referenceImgIdx\"] = referenceImgIdx\n",
    "    right, up = get_patch_vectors(patch) \n",
    "    return -ncc_objective(center, right, up, imagesModels[referenceImgIdx], optimPhotos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(depth, unitDepthVector, patchTrueSet):\n",
    "    sum = 0\n",
    "    for i in range (len(patchTrueSet)):\n",
    "        photo = imagesModels[patchTrueSet[i]['idx']]\n",
    "        depthVectorProj = np.matmul(photo['projMat'], unitDepthVector)\n",
    "        depthVectorProj /= depthVectorProj[2]\n",
    "        sum += np.linalg.norm(np.array(depthVectorProj[-1])) #remove t\n",
    "        \n",
    "    sum /= len(patchTrueSet)\n",
    "    unitDepthVector /= sum\n",
    "    depth *= sum\n",
    "    return depth, unitDepthVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_patch(patch):\n",
    "    global referenceImgIdx\n",
    "    global depthVec\n",
    "    global optimPhotos\n",
    "    refPhoto = imagesModels[patch[\"referenceImgIdx\"]][\"image\"]\n",
    "    opticalCenter = imagesModels[patch[\"referenceImgIdx\"]][\"optCenter\"]\n",
    "\n",
    "    depth, theta, phi, unitDepthVec = encode(patch[\"center\"], patch[\"normal\"], refPhoto, opticalCenter)\n",
    "    depth, unitDepthVec = normalize(depth, unitDepthVec, patch[\"trueSet\"]) #TODO add trueset to patch\n",
    "    targetPhotos = patch[\"trueSet\"]\n",
    "    referenceImgIdx, depthVec, optimPhotos = patch[\"referenceImgIdx\"], unitDepthVec, targetPhotos\n",
    "\n",
    "    option = {\n",
    "        'disp': False, #Set to True to print convergence messages.\n",
    "        'maxiter': 1000,\n",
    "        'xatol': 0.0005,\n",
    "        'adaptive': False #adaptivebool, optional#Adapt algorithm parameters to dimensionality of problem. Useful for high-dimensional minimization\n",
    "        \n",
    "    }\n",
    "    initialGuess = np.array([depth, theta, phi])\n",
    "    solution  = minimize(objective, initialGuess, method='Nelder-Mead', options = option)\n",
    "    center, normal = decode(imagesModels[patch[\"referenceImgIdx\"]], unitDepthVec, solution.x[0], solution.x[1], solution.x[2])\n",
    "    patch[\"center\"], patch[\"normal\"] = center, normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get Relevent Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevent_images(imgModels,idx):\n",
    "    releventImages = []\n",
    "    myOptAxis = imgModels[idx][\"optAxis\"]\n",
    "\n",
    "    for i in range(len(imgModels)):\n",
    "        if i == idx:\n",
    "            continue\n",
    "        otherOptAxis = imgModels[i][\"optAxis\"]\n",
    "        cosAngle = np.dot(myOptAxis,otherOptAxis)\n",
    "\n",
    "        if cosMinAngle > cosAngle > cosMaxAngle:\n",
    "            releventImages.append(i)\n",
    "\n",
    "    return releventImages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Get v/t Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_score(cell1,cell2):\n",
    "    mean1 = np.mean(cell1)\n",
    "    mean2 = np.mean(cell2)\n",
    "    \n",
    "    std1 = std2 = product = 0\n",
    "\t\n",
    "    for i in range(len(cell1)):\n",
    "        diff1 = cell1[i] - mean1\n",
    "        diff2 = cell2[i] - mean2\n",
    "        product += diff1 * diff2\n",
    "        std1 += diff1 * diff1\n",
    "        std2 += diff2 * diff2\n",
    "\t\n",
    "    stds = std1 * std2\n",
    "    if stds == 0:\n",
    "        return 0\n",
    "\n",
    "    return product / np.math.sqrt(stds)\n",
    "\n",
    "def project_patch(patchCenter,imgModel,rightVector,upVector):\n",
    "    cell = np.zeros(patchGridSize*patchGridSize*3)\n",
    "    \n",
    "    projMat = imgModel[\"projMat\"]\n",
    "    projCenter = np.matmul(projMat,patchCenter)\n",
    "    projRight = np.matmul(projMat,rightVector).reshape(3,1)\n",
    "    projUp = np.matmul(projMat,upVector).reshape(3,1)\n",
    "\n",
    "    scale = 1/projCenter[2]\n",
    "    projCenter = scale * projCenter\n",
    "    projRight = scale * projRight\n",
    "    projUp = scale * projUp\n",
    "\n",
    "    step = (patchGridSize-1)/2\n",
    "    diagVector = projUp + projRight\n",
    "    diagVector = step * diagVector\n",
    "    topLeftVector = projCenter - diagVector\n",
    "\n",
    "    cellIdx = 0\n",
    "    for i in range(patchGridSize):\n",
    "        for j in range(patchGridSize):\n",
    "            xCoord = topLeftVector[0] + i*projUp[0] + j*projRight[0]\n",
    "            yCoord = topLeftVector[1] + i*projUp[1] + j*projRight[1]\n",
    "            yCoord = int(yCoord+0.5)\n",
    "            xCoord = int(xCoord+0.5)\n",
    "\n",
    "            # pixel is outside the image\n",
    "            if outside_image_boundry(yCoord,xCoord):\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = 0,0,0\n",
    "            else:\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = imgModel[\"image\"][yCoord][xCoord]\n",
    "\n",
    "            cellIdx +=3\n",
    "\n",
    "    return cell\n",
    "\n",
    "def get_ncc_score(patch,releventImgModel,rightVector,upVector):\n",
    "    referenceImgModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "\n",
    "    cell1 = project_patch(patch[\"center\"],referenceImgModel,rightVector,upVector)\n",
    "    cell2 = project_patch(patch[\"center\"],releventImgModel,rightVector,upVector)\n",
    "    return ncc_score(cell1,cell2)\n",
    "\n",
    "def get_patch_vectors(patch):\n",
    "    referenceImageModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "    projMat = referenceImageModel[\"projMat\"]\n",
    "\n",
    "    ppinv = np.linalg.pinv(projMat)\n",
    "\n",
    "    scale = np.dot(ppinv[:,0],patch[\"normal\"])\n",
    "    rightVector = ppinv[:,0].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "    scale = np.dot(ppinv[:,1],patch[\"normal\"])\n",
    "    upVector = ppinv[:,1].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "\n",
    "    scale = np.dot(projMat[2],patch[\"center\"])\n",
    "    rightVector = (scale/(np.dot(projMat[0],rightVector)))*rightVector\n",
    "    upVector = (scale/(np.dot(projMat[1],upVector)))*upVector\n",
    "\n",
    "    return rightVector, upVector\n",
    "\n",
    "def get_t_images(patch,alfa,visibleImgsIdx):\n",
    "    tImages = []\n",
    "\n",
    "    rightVector,upVector = get_patch_vectors(patch)\n",
    "    for visibleImageIdx in visibleImgsIdx:\n",
    "        visibleImageModel = imagesModels[visibleImageIdx]\n",
    "        \n",
    "        depthVector = np.float32([\n",
    "            visibleImageModel[\"optCenter\"][0] - patch[\"center\"][0],\n",
    "            visibleImageModel[\"optCenter\"][1] - patch[\"center\"][1],\n",
    "            visibleImageModel[\"optCenter\"][2] - patch[\"center\"][2],\n",
    "            visibleImageModel[\"optCenter\"][3] - patch[\"center\"][3]\n",
    "        ])\n",
    "\n",
    "        if np.dot(np.squeeze(depthVector), np.squeeze(patch[\"normal\"])) <= 0:\n",
    "            continue\n",
    "        \n",
    "        nccScore = get_ncc_score(patch, visibleImageModel, rightVector, upVector)\n",
    "        if nccScore >= alfa:\n",
    "            tImages.append({\"idx\":visibleImageIdx,\"ncc\":nccScore}) #TODO remove nccscore if not used\n",
    "    \n",
    "    return tImages\n",
    "\n",
    "def get_visible_images(patch,baseImageIdx):\n",
    "    sImgs = []\n",
    "    for releventImgIdx in imagesModels[baseImageIdx][\"releventImgsIdxs\"]:\n",
    "        vec = imagesModels[releventImgIdx]['optCenter'].reshape(4,1) - patch['center']\n",
    "        vec = vec/(np.linalg.norm(vec))\n",
    "        if np.dot(np.squeeze(patch['normal']),np.squeeze(vec)) > np.math.cos((np.math.pi/3)):\n",
    "            sImgs.append({'idx':releventImgIdx})\n",
    "    return sImgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_patch(patch):\n",
    "    for sImg in patch[\"visibleSet\"]:\n",
    "        imgModel = imagesModels[sImg['idx']]\n",
    "        imgCoord = np.matmul(imgModel['projMat'], patch['center'])\n",
    "        imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "\n",
    "        x = int(imgCoord[0][0]) // ß1\n",
    "        y = int(imgCoord[1][0]) // ß1\n",
    "        cell1 = imgModel['grid'][y][x]\n",
    "        \n",
    "        if not any(imgIdx == sImg['idx'] for imgIdx in patch['trueSet']):\n",
    "            cell1['Qf'].append(patch)\n",
    "        else:\n",
    "            cell1['Qt'].append(patch)\n",
    "        \n",
    "        sImg['cell'] = {\n",
    "            'ptx':x,\n",
    "            'pty':y,\n",
    "        }\n",
    "    patches.append(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_cell(imageID, y, x):\n",
    "    cell_y = y // ß1\n",
    "    cell_x = x // ß1\n",
    "    if len(imagesModels[imageID]['grid'][cell_y][cell_x]['Qt']) == 0 and len(imagesModels[imageID]['grid'][cell_y][cell_x]['Qf']) == 0 :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_statsify_epipoler_consistency(baseImageIdx, featurePt):\n",
    "    triangulations = list()\n",
    "    for i in range(len(imagesModels[baseImageIdx][\"releventImgsIdxs\"])):\n",
    "        releventImageIdx = imagesModels[baseImageIdx][\"releventImgsIdxs\"][i]\n",
    "        fundmentalMat = get_fundmental_matrix(imagesModels[baseImageIdx],imagesModels[releventImageIdx])\n",
    "\n",
    "        if fundmentalMat is None:\n",
    "            continue\n",
    "        pt1 = featurePt\n",
    "        pts1 = np.int32([pt1])\n",
    "        pts2 = np.int32(imagesModels[releventImageIdx][\"dogPositions\"])\n",
    "\n",
    "        originalWithFeaturePt = imagesModels[baseImageIdx][\"image\"].copy()\n",
    "        cv.circle(originalWithFeaturePt,tuple(pt1),5,(0,0,255),-1)\n",
    "\n",
    "        # Get the epilines of features in left image on the right image\n",
    "        # parameter1: points required to get its epilines in the other image\n",
    "        # parameter2: which image that points are belong, 1-left 2-right\n",
    "        # parameter3: fundmental matrix between the 2 images\n",
    "        # returns list of epilines that lie on the other image and corresponding to the points\n",
    "        lines = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,fundmentalMat)\n",
    "        lines = lines.reshape(-1,3)\n",
    "        #sara_im = plot_epipolar_line(imagesModels[i][\"image\"],fundmentalMat,[pt1[0],pt1[1],1])\n",
    "\n",
    "        # draw the epiline on the other image\n",
    "        # parameter1: the second image\n",
    "        # parameter2: the epilines that lie on the second image\n",
    "        # parameter3: the features lie on the second image\n",
    "        fullFeaturesImage,reducedFeaturesImage,legalFeatures = drawlines(imagesModels[releventImageIdx],lines,pts2)\n",
    "\n",
    "        #Triangulation\n",
    "        for j in range(len(legalFeatures)):\n",
    "            if not(empty_cell(releventImageIdx, int(legalFeatures[j][1]), int(legalFeatures[j][0]))): #TODO check t = 1\n",
    "                continue\n",
    "                \n",
    "            triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[baseImageIdx][\"projMat\"],imagesModels[releventImageIdx][\"projMat\"],pt1,legalFeatures[j])\n",
    "            triangulatedPoint = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :]\n",
    "\n",
    "            #triangulatedPoint = triangulate_point(np.array([pt1[0], pt1[1],1]),legalFeatures[j],imagesModels[baseImageIdx][\"projMat\"],imagesModels[i][\"projMat\"])\n",
    "\n",
    "            distFromcenter = abs(abs(np.linalg.norm(np.array(imagesModels[baseImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))) - abs(np.linalg.norm(np.array(imagesModels[releventImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))))\n",
    "\n",
    "            triangulation = {\n",
    "                \"originalImg\": releventImageIdx,\n",
    "                \"position\": triangulatedPoint,\n",
    "                \"distFromCenter\": distFromcenter,\n",
    "                \"ptx\": legalFeatures[j][0],\n",
    "                \"pty\": legalFeatures[j][1]\n",
    "            }\n",
    "\n",
    "            triangulations.append(triangulation)\n",
    "\n",
    "        #show_images([imagesModels[baseImageIdx][\"image\"],imagesModels[releventImageIdx][\"image\"],fullFeaturesImage,reducedFeaturesImage, originalWithFeaturePt],[\"image\"+str(baseImageIdx),\"image\"+str(releventImageIdx),\"fullfeatures in image\"+str(releventImageIdx),\"reducedfeatures in image\"+str(releventImageIdx), \"originalWithFeaturePt\"+str(releventImageIdx)])\n",
    "\n",
    "    triangulations = sorted(triangulations, key=lambda k: k[\"distFromCenter\"]) \n",
    "    #for i in range(len(triangulations)):\n",
    "        #print(\"triangulations: \", triangulations[i][\"originalImg\"], \"ptx\", triangulations[i][\"ptx\"], \"pty\", triangulations[i][\"pty\"], triangulations[i][\"distFromCenter\"])\n",
    "    \n",
    "    return triangulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_patches(baseImageIdx, triangulations):\n",
    "    #print(\"construct_patches ...\")\n",
    "    baseOptCenter = imagesModels[baseImageIdx][\"optCenter\"]\n",
    "    for candidate in triangulations:\n",
    "\n",
    "        patch = {}\n",
    "        patch[\"referenceImgIdx\"] = baseImageIdx\n",
    "        patch[\"center\"] = candidate[\"position\"]\n",
    "        patch[\"normal\"] = np.float32([\n",
    "                baseOptCenter[0] - candidate[\"position\"][0],\n",
    "                baseOptCenter[1] - candidate[\"position\"][1],\n",
    "                baseOptCenter[2] - candidate[\"position\"][2],\n",
    "                baseOptCenter[3] - candidate[\"position\"][3],\n",
    "            ])\n",
    "        patch[\"normal\"] = patch[\"normal\"] / np.linalg.norm(patch[\"normal\"])\n",
    "\n",
    "        sImgs = []\n",
    "        for releventImgIdx in imagesModels[baseImageIdx][\"releventImgsIdxs\"]:\n",
    "            vec = imagesModels[releventImgIdx]['optCenter'].reshape(4,1) - patch['center']\n",
    "            vec = vec/(np.linalg.norm(vec))\n",
    "            if np.dot(np.squeeze(patch['normal']),np.squeeze(vec)) > np.math.cos((np.math.pi/3)):\n",
    "                sImgs.append(releventImgIdx)\n",
    "\n",
    "        #TODO add alpha1,2 to constants in paper, 0.4,0.7....0.6,0.3\n",
    "        patch[\"trueSet\"] = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"]) \n",
    "\n",
    "        #print(\"len(patch[trueSet]): \", len(patch[\"trueSet\"]))\n",
    "        if len(patch[\"trueSet\"]) <= 1 : \n",
    "            continue\n",
    "\n",
    "        optimize_patch(patch)\n",
    "        patch[\"visibleSet\"] = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"]) \n",
    "        patch[\"trueSet\"] = get_t_images(patch,0.7,imagesModels[baseImageIdx][\"releventImgsIdxs\"])\n",
    "        #print(\"len(patch[trueSet]): \", len(patch[\"trueSet\"]), \" gamma: \", gamma)\n",
    "        if len(patch[\"trueSet\"]) >= gamma:\n",
    "            register_patch(patch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images,grids = init_imgs(datasetPath)\n",
    "projections,optAxes = read_parameters_file(datasetPath)\n",
    "print(\"Read Input---->DONE\")\n",
    "imagesModels = list()\n",
    "patches = list()\n",
    "for idx,image in enumerate(images):\n",
    "    dog,harris = get_dog_harris(image)\n",
    "    sparseDog,sparseHarris,dogPositions,harrisPositions = sparse_dog_harris(dog,harris)\n",
    "    opticalCenter = getOpticalCenter(projections[idx])\n",
    "    imgModel={\n",
    "        \"image\": images[idx],\n",
    "        \"projMat\": projections[idx],\n",
    "        \"optCenter\": opticalCenter,\n",
    "        \"optAxis\": optAxes[idx],\n",
    "        \"grid\": grids[idx],\n",
    "        \"dog\": dog,\n",
    "        \"harris\": harris,\n",
    "        \"sparseDog\": sparseDog,\n",
    "        \"sparseHarris\": sparseHarris,\n",
    "        \"dogPositions\": dogPositions,\n",
    "        \"harrisPositions\": harrisPositions\n",
    "    }\n",
    "    \n",
    "    imagesModels.append(imgModel)\n",
    "\n",
    "print(\"Feature Detection---->DONE\")\n",
    "\n",
    "for i in range(len(imagesModels)):\n",
    "    imagesModels[i][\"releventImgsIdxs\"] = get_relevent_images(imagesModels,i)\n",
    "    \n",
    "print(\"Get Relevent Images---->DONE\")\n",
    "# show_images([imagesModels[0][\"dog\"],imagesModels[0][\"sparseDog\"],imagesModels[0][\"harris\"],imagesModels[0][\"sparseHarris\"]],['dog','sparse dog','harris','sparse harris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Start Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Matching....\")\n",
    "numberOfPatches = 0\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "for i in range(len(imagesModels)):\n",
    "    baseImageIdx = i\n",
    "    print(\"ImageID: \", str(baseImageIdx),\" Number of Features: \", str(len(imagesModels[baseImageIdx][\"dogPositions\"])))\n",
    "    for featurePt in imagesModels[baseImageIdx][\"dogPositions\"]:\n",
    "        if not(empty_cell(baseImageIdx, featurePt[1], featurePt[0])):\n",
    "            # print(\"non empty cell\")\n",
    "            continue\n",
    "        #print(\"empty cell\")\n",
    "        features  = get_features_statsify_epipoler_consistency(baseImageIdx, featurePt)\n",
    "        construct_patches(baseImageIdx, features)\n",
    "    print(\"ImageID: \", str(baseImageIdx), \"----> Done\\t\",\"Number of constructed patches: \", str(len(patches) - numberOfPatches))\n",
    "    numberOfPatches = len(patches)\n",
    "print(\"Total number of patches: \", len(patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_header(file):\n",
    "    file.write(\"ply\\n\")\n",
    "    file.write(\"format ascii 1.0\\n\")\n",
    "    file.write( \"element vertex \"+ str(len(patches)) + \"\\n\")\n",
    "    file.write( \"property float x\\n\")\n",
    "    file.write(\"property float y\\n\")\n",
    "    file.write(\"property float z\\n\")\n",
    "    file.write(\"property float nx\\n\")\n",
    "    file.write(\"property float ny\\n\")\n",
    "    file.write(\"property float nz\\n\")\n",
    "    file.write(\"property uchar diffuse_red\\n\")\n",
    "    file.write(\"property uchar diffuse_green\\n\")\n",
    "    file.write(\"property uchar diffuse_blue\\n\")\n",
    "    file.write( \"end_header\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply(): \n",
    "    file = open(\"pointcloud.txt.ply\", \"w\")\n",
    "    write_header(file)\n",
    "    for patch in patches:\n",
    "        file.write(str(patch[\"center\"][0][0]) + \" \" +  str(patch[\"center\"][1][0]) + \" \" + str(patch[\"center\"][2][0]) + \" \")\n",
    "        file.write(str(patch[\"normal\"][0][0]) + \" \" +  str(patch[\"normal\"][1][0]) + \" \" + str(patch[\"normal\"][2][0]) + \" \")\n",
    "        file.write(\"255\"+ \" \" + \"0\" + \" \"+\"0\")\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "write_ply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Start Expansion....\")\n",
    "originalPatches = deepcopy(patches)\n",
    "numberOfPatches = 0\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "while len(originalPatches) != 0:\n",
    "    patch = originalPatches.pop(0)\n",
    "    neighborCells = []\n",
    "\n",
    "    # Get neighbor cells\n",
    "    for idx,visibleImage in enumerate(patch['visibleSet']):\n",
    "        x = visibleImage['cell']['ptx']\n",
    "        y = visibleImage['cell']['pty']\n",
    "        \n",
    "        # if id(patch) in [id(otherPatch) for otherPatch in imagesModels[visibleImage['idx']]['grid'][y][x]['Qf']]:\n",
    "        #     continue\n",
    "            \n",
    "        # Get neighbor cells\n",
    "        for neighborY in range(y-1,y+2,1):\n",
    "            for neighborX in range(x-1,x+2,1):\n",
    "                # original cell\n",
    "                if neighborY == y and neighborX == x:\n",
    "                    continue\n",
    "\n",
    "                if not outside_image_boundry(neighborY,neighborX):\n",
    "                    neighborCell = imagesModels[visibleImage['idx']]['grid'][neighborY][neighborX]\n",
    "                    # non empty cell Qt\n",
    "                    if len(neighborCell['Qt']) != 0:\n",
    "                        continue\n",
    "                        \n",
    "                    projMat = imagesModels[visibleImage['idx']]['projMat']\n",
    "                    projCenter = np.matmul(projMat,patch['center'])\n",
    "                    scale = 1/projCenter[2]\n",
    "                    projCenter = scale * projCenter\n",
    "                    hasNeighbor = False\n",
    "                    \n",
    "                    for otherPatch in neighborCell['Qf']:\n",
    "                        otherProjCenter = np.matmul(projMat,otherPatch['center'])\n",
    "                        scale = 1/otherProjCenter[2]\n",
    "                        otherProjCenter = scale * otherProjCenter\n",
    "                        \n",
    "                        left =  np.abs(np.dot(np.squeeze(otherPatch['center']-patch['center']),np.squeeze(patch['normal']))) + np.abs(np.dot(np.squeeze(otherPatch['center']-patch['center']),np.squeeze(otherPatch['normal'])))\n",
    "                        right = np.linalg.norm(projCenter-otherProjCenter)\n",
    "\n",
    "                        rowProj = np.matmul(imagesModels[patch[\"referenceImgIdx\"]]['projMat'],(imagesModels[patch[\"referenceImgIdx\"]]['optCenter'].reshape(4,1) - ((patch['center']+otherPatch['center'])/2)))\n",
    "\n",
    "                        if left < 2* right :\n",
    "                            hasNeighbor = True\n",
    "                            break\n",
    "                        else:\n",
    "                            print(\"not neighbors \")\n",
    "\n",
    "                    if hasNeighbor == True:\n",
    "                        continue\n",
    "                    else:\n",
    "                        neighborCells.append({\n",
    "                              \"x\":neighborX,\n",
    "                              \"y\":neighborY,\n",
    "                              \"neighborCell\":neighborCell\n",
    "                            })\n",
    "                        \n",
    "    print(\"Number of neighbor cells:\",len(neighborCells))\n",
    "    for neighborCell in neighborCells:\n",
    "        newPatch = {}\n",
    "        newPatch[\"referenceImgIdx\"] = patch[\"referenceImgIdx\"]\n",
    "        newPatch[\"normal\"] = patch[\"normal\"]\n",
    "        newPatch[\"trueSet\"] = patch[\"trueSet\"]\n",
    "\n",
    "        # Get the ray\n",
    "        cellCenter = np.array([neighborCell['x'],neighborCell['y'],1]).reshape(3,1)\n",
    "        projMat = imagesModels[patch['referenceImgIdx']][\"projMat\"]\n",
    "        ppinv = np.linalg.pinv(projMat)\n",
    "        ray = np.matmul(ppinv,cellCenter)+imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)\n",
    "        ray = ray / np.linalg.norm(ray)\n",
    "        \n",
    "        if abs(np.dot(np.squeeze(ray),np.squeeze(newPatch['normal']))) < 10**-6:\n",
    "          print(\"ray parallel to patch\")\n",
    "          continue\n",
    "\n",
    "        # Get the intersection\n",
    "        t = (- np.dot(np.squeeze(patch['normal']),np.squeeze(imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1) - patch['center'])))/(np.dot(np.squeeze(patch['normal']),np.squeeze(ray)))\n",
    "        intersection = t*ray + imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)\n",
    "\n",
    "        newPatch['center'] = intersection\n",
    "        optimize_patch(newPatch)\n",
    "        newPatch[\"visibleSet\"] = patch['trueSet']\n",
    "        newVImgs = get_t_images(newPatch,0.6,imagesModels[newPatch[\"referenceImgIdx\"]][\"releventImgsIdxs\"])\n",
    "\n",
    "        for newVImg in newVImgs:\n",
    "            found = False\n",
    "            for vImg in newPatch[\"visibleSet\"]:\n",
    "                if newVImg['idx'] == vImg['idx']:\n",
    "                    found = True\n",
    "                    break\n",
    "\n",
    "            if not found:\n",
    "                newPatch[\"visibleSet\"].append(newVImg)\n",
    "        \n",
    "        visibleIdxs = [vImg['idx'] for vImg in newPatch[\"visibleSet\"]]\n",
    "        newPatch[\"trueSet\"] = get_t_images(newPatch,0.7,visibleIdxs)\n",
    "        #print(\"len(newPatch[trueSet]): \", len(newPatch[\"trueSet\"]), \" gamma: \", gamma)\n",
    "        if len(newPatch[\"trueSet\"]) >= gamma:\n",
    "            register_patch(newPatch)\n",
    "            originalPatches.append(newPatch)\n",
    "\n",
    "    print(\"One original patch is removed -->\\tThe total number of patches now: \",len(originalPatches))\n",
    "        # print(intersection)\n",
    "        # d = - np.dot(np.squeeze(patch['normal']),np.squeeze(imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1))) \n",
    "        # xx, yy = np.meshgrid(range(10), range(10))\n",
    "        # z = (-patch['normal'][0] * xx - patch['normal'][1] * yy - d) * 1. /patch['normal'][2]\n",
    "        # plt3d = plt.figure().gca(projection='3d')\n",
    "        # plt3d.plot_surface(xx, yy, z)\n",
    "        # x = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[0]]\n",
    "        # y = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[1]]\n",
    "        # z = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[2]]\n",
    "        # xi = [intersection[0]]\n",
    "        # yi = [intersection[1]]\n",
    "        # zi = [intersection[2]]\n",
    "        # plt3d.scatter(x,y,z,c='r')\n",
    "        # plt3d.scatter(xi,yi,zi,c='y')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# otherPatches = [patches[i] for i in range(0,10)]\n",
    "# patchx = patches[9]\n",
    "# id(patchx) in [id(pthPatch) for pthPatch in otherPatches]"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit12a28b20f4914dc8b8d3732234a9d265"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}