{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "from copy import copy,deepcopy\n",
    "from optical_center import getOpticalCenter\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_nth_maximum(arr,n):\n",
    "    uniqueValues = list(arr.flatten())\n",
    "    uniqueValues.sort()\n",
    "    if len(uniqueValues) < n:\n",
    "        return uniqueValues[0]\n",
    "    return uniqueValues[len(uniqueValues)-n]\n",
    "    # sortedmatrix.sort()\n",
    "    # # print(arr.shape)\n",
    "    # if sortedmatrix.size == 0:\n",
    "    #     return -1\n",
    "    # return sortedmatrix[0 if n > sortedmatrix.size else -n] \n",
    "\n",
    "def get_optical_axis(projectionMat):\n",
    "    return np.array([projectionMat[2][0],projectionMat[2][1],projectionMat[2][2],0])\n",
    "\n",
    "def outside_image_boundry(yCoord,xCoord,height,width):\n",
    "    return (xCoord < 0 or yCoord < 0 or xCoord >= width or yCoord >= height)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Constants</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetPath = \"Data/dinoSparseRing/\"\n",
    "ß1 = 2\n",
    "ß2 = 32\n",
    "µ = 5       # the projection of one of its edges into R(p) is parallel to the image rows, and the smallest axis-aligned square containingits image covers a µ × µ pixel^2 area\n",
    "# We associate with p a reference image R(p),the images S(p) where p should be visible and the images T(p) where it is truly found \n",
    "gamma = 3\n",
    "\n",
    "cosMinAngle = np.math.cos(np.math.radians(20))\n",
    "cosMaxAngle = np.math.cos(np.math.radians(60))\n",
    "patchGridSize = 5\n",
    "'''\n",
    "patchModel = {\n",
    "    \"R\":None,\n",
    "    \"S\":set,\n",
    "    \"T\":set\n",
    "}\n",
    "# The cell C(i, j) keeps track of two different sets Qt(i, j) and Qf(i, j)\n",
    "cell = {\n",
    "    \"Qt\":list(),\n",
    "    \"Qf\":list()\n",
    "}\n",
    "# We associate with each image I a regular grid of β1×β1 pixel^2 cells\n",
    "imageModel = {\n",
    "    \"image\":None,\n",
    "    \"projMat\":None,\n",
    "    \"optCenter\":None,\n",
    "    \"grid\":None,\n",
    "    \"dog\":None,\n",
    "    \"harris\":None,\n",
    "    \"sparseDog\":None,\n",
    "    \"sparseHarris\":None,\n",
    "    \"dogPositions\":None,\n",
    "    \"harrisPositions\":None\n",
    "}\n",
    "'''\n",
    "cell = {\n",
    "    \"Qt\":list(),\n",
    "    \"Qf\":list()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Get Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image model from a given path\n",
    "def init_imgs(datasetPath):\n",
    "    # Read imgs\n",
    "    filesNames = glob(datasetPath+'*.png')\n",
    "    filesNames = sorted(filesNames)\n",
    "    # print(filesNames)\n",
    "    imgs = [cv.imread(file) for file in filesNames]\n",
    "    # imgs = [cv.rotate(cv.imread(file),cv.ROTATE_90_COUNTERCLOCKWISE) for file in glob(datasetPath+'*.png')]\n",
    "\n",
    "    # Construct corresponding image grid\n",
    "    #grids = [np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)]) for img in imgs]\n",
    "    grids = list()\n",
    "    for img in imgs:\n",
    "        grid = np.array([np.array([cell for x in range(0,img.shape[1]//ß1)]) for y in range(0,img.shape[0]//ß1)])\n",
    "        for i in range(len(grid)):\n",
    "            for j in range(len(grid[0])):\n",
    "                \n",
    "                cell1={\n",
    "                    \"Qt\":list(),\n",
    "                    \"Qf\":list()\n",
    "                }\n",
    "                \n",
    "                grid[i][j] = cell1\n",
    "        grids.append(grid)\n",
    "        \n",
    "    return imgs,grids\n",
    "    \n",
    "# Read camera parameters and return the projection matrices for all pictures\n",
    "def read_parameters_file(datasetPath):\n",
    "    inputFile = open(datasetPath+\"dinoSR_par.txt\")\n",
    "    lines = inputFile.readlines()\n",
    "    lines.pop(0) # drop images number\n",
    "    projections = []\n",
    "    optAxes = []\n",
    "    # Every line is a parameters list for the corresponding image camera\n",
    "    for line in lines:\n",
    "        line = line[:-1]                # \\n character\n",
    "        linedata = line.split(' ')\n",
    "        imgName = linedata.pop(0)\n",
    "        k = np.zeros((3,3))\n",
    "        r = np.zeros((3,3))\n",
    "        t = np.zeros((3,1))\n",
    "\n",
    "        i = 0\n",
    "        for ridx,row in enumerate(k):\n",
    "            t[ridx][0]=linedata[ridx+18]\n",
    "            for colidx,_ in enumerate(row):\n",
    "                k[ridx][colidx]=linedata[i]\n",
    "                r[ridx][colidx]=linedata[i+9]\n",
    "                i+=1\n",
    "        x = np.concatenate((r,t),axis=1)\n",
    "        p = np.matmul(k,x)\n",
    "        projections.append(p)\n",
    "\n",
    "        optAxis = get_optical_axis(p)\n",
    "        optAxis *= np.linalg.det(p[:,:-1])\n",
    "        norm = np.linalg.norm(optAxis)\n",
    "        # optAxis[3] = p[2][3]\n",
    "        optAxis /= norm\n",
    "        optAxes.append(optAxis)\n",
    "\n",
    "        outputFile = open(datasetPath+\"projection/projection\"+imgName[6:10]+\".txt\",mode=\"w+\")\n",
    "        outputFile.write(\"CONTOUR\\n\")\n",
    "        pString = \"\"\n",
    "        for row in p:\n",
    "            for col in row:\n",
    "                pString += str('{0:0.5f}'.format(col))+\" \"\n",
    "            pString += \"\\n\"\n",
    "        outputFile.write(pString)\n",
    "        outputFile.close()\n",
    "        \n",
    "    return projections,optAxes"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Feature Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Harris and DoG operators for a given image\n",
    "def get_dog_harris(img):\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "            \n",
    "    # Get DoG\n",
    "    g1 = cv.GaussianBlur(gray,(0,0),sigmaX=1)\n",
    "    g2 = cv.GaussianBlur(gray,(0,0),sigmaX=1*np.sqrt(2))\n",
    "    diff = cv.absdiff(g1,g2)\n",
    "    dog = diff\n",
    "\n",
    "    # Get Harris\n",
    "    bSize = 3\n",
    "    kSize = 1\n",
    "    corners = cv.cornerHarris(src=gray,blockSize=bSize,ksize=kSize,k=0.06)\n",
    "    # corners = cv.dilate(corners,None)\n",
    "    \n",
    "    return dog , corners\n",
    "\n",
    "\n",
    "def sparse_dog_harris(dog,harris):\n",
    "    n = 4\n",
    "    sparseDog = copy(dog)\n",
    "    sparseHarris = copy(harris)\n",
    "    sparseDogPositions = []\n",
    "    sparseHarrisPositions = []\n",
    "    for yIdx in range(0,len(dog),ß2):\n",
    "        for xIdx in range(0,len(dog[0]),ß2):\n",
    "            nThMaximumDog = get_nth_maximum(dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumDog != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(dog[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumDog:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseDogPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseDog[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumDog)\n",
    "            nThMaximumHarris = get_nth_maximum(harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],n)\n",
    "            if nThMaximumHarris != -1:\n",
    "                found = False\n",
    "                for rowIdx,row in enumerate(harris[yIdx:yIdx+ß2]):\n",
    "                    for columnIdx,column in enumerate(row[xIdx:xIdx+ß2]):\n",
    "                        if not found and column == nThMaximumHarris:\n",
    "                            found = True\n",
    "                            if column != 0:\n",
    "                                sparseHarrisPositions.append((xIdx+columnIdx,yIdx+rowIdx))\n",
    "                        else:\n",
    "                            sparseHarris[yIdx+rowIdx,xIdx+columnIdx] = 0\n",
    "                # sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] = sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]*(sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2] == nThMaximumHarris)\n",
    "            # show_images([dog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseDog[yIdx:yIdx+ß2,xIdx:xIdx+ß2],harris[yIdx:yIdx+ß2,xIdx:xIdx+ß2],sparseHarris[yIdx:yIdx+ß2,xIdx:xIdx+ß2]],['before dog','after dog','before harris','after harris'])\n",
    "\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseDog = cv.dilate(sparseDog,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    # sparseHarris = cv.dilate(sparseHarris,None)\n",
    "    return sparseDog,sparseHarris,sparseDogPositions,sparseHarrisPositions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Get Fundmental Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fundamental(x1,x2):\n",
    "    \"\"\" Computes the fundamental matrix from corresponding points\n",
    "    (x1,x2 3*n arrays) using the normalized 8 point algorithm.\n",
    "    each row is constructed as\n",
    "    [x’*x, x’*y, x’, y’*x, y’*y, y’, x, y, 1] \"\"\"\n",
    "    n = x1.shape[1]\n",
    "    if x2.shape[1] != n:\n",
    "        raise ValueError(\"Number of points don’t match.\")\n",
    "    # build matrix for equations\n",
    "    A = np.zeros((n,9))\n",
    "    for i in range(n):\n",
    "        A[i] = [x1[0,i]*x2[0,i], x1[0,i]*x2[1,i], x1[0,i]*x2[2,i],\n",
    "        x1[1,i]*x2[0,i], x1[1,i]*x2[1,i], x1[1,i]*x2[2,i],\n",
    "        x1[2,i]*x2[0,i], x1[2,i]*x2[1,i], x1[2,i]*x2[2,i] ]\n",
    "    \n",
    "    # compute linear least square solution\n",
    "    U,S,V = np.linalg.svd(A)\n",
    "    F = V[-1].reshape(3,3)\n",
    "    # constrain F\n",
    "    # make rank 2 by zeroing out last singular value\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    S[2] = 0\n",
    "    F = np.dot(U,np.dot(np.diag(S),V))\n",
    "    return F\n",
    "\n",
    "def compute_epipole(F):\n",
    "    \"\"\" Computes the (right) epipole from a\n",
    "    fundamental matrix F.\n",
    "    (Use with F.T for left epipole.) \"\"\"\n",
    "    # return null space of F (Fx=0)\n",
    "    U,S,V = np.linalg.svd(F)\n",
    "    e = V[-1]\n",
    "    return e/e[2]\n",
    "\n",
    "def plot_epipolar_line(im,F,x,epipole=None,show_epipole=True):\n",
    "    \"\"\" Plot the epipole and epipolar line F*x=0\n",
    "    in an image. F is the fundamental matrix\n",
    "    and x a point in the other image.\"\"\"\n",
    "    m,n = im.shape[:2]\n",
    "    line = np.dot(F,x)\n",
    "    # epipolar line parameter and values\n",
    "    t = np.linspace(0,n,100)\n",
    "    lt = np.array([(line[2]+line[0]*tt)/(-line[1]) for tt in t])\n",
    "    # take only line points inside the image\n",
    "    ndx = (lt>=0) & (lt<m)\n",
    "    plt.plot(t[ndx],lt[ndx],linewidth=2)\n",
    "    if show_epipole:\n",
    "        if epipole is None:\n",
    "            epipole = compute_epipole(F)\n",
    "        plt.plot(epipole[0]/epipole[2],epipole[1]/epipole[2],'r*')\n",
    "\n",
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_book(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    x1 = np.vstack( (pts1,np.ones(pts1.shape[1])) )\n",
    "    x2 = np.vstack( (pts2,np.ones(pts2.shape[1])) )\n",
    "\n",
    "    fundmentalMat = compute_fundamental(x1,x2)\n",
    "    # compute the epipole\n",
    "    e = compute_epipole(fundmentalMat)\n",
    "    \n",
    "    # plotting\n",
    "    plt.figure()\n",
    "    plt.imshow(images[0])\n",
    "    for i in range(5):\n",
    "        plot_epipolar_line(images[0],fundmentalMat,x2[:,i],e,False)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(im2)\n",
    "    # plot each point individually, this gives same colors as the lines\n",
    "    for i in range(5):\n",
    "        plt.plot(x2[0,i],x2[1,i],'o')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the fundmental matrix between 2 pictures\n",
    "def get_fundmental_matrix_sift(idx1,idx2):\n",
    "    sift = cv.xfeatures2d.SIFT_create()\n",
    "    # find keypoints and descriptors with SIFT\n",
    "    kp1,des1 = sift.detectAndCompute(images[idx1],None)\n",
    "    kp2,des2 = sift.detectAndCompute(images[idx2],None)\n",
    "\n",
    "    # FLANN parameters\n",
    "    FLANN_INDEX_KDTREE = 0\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)\n",
    "\n",
    "    flann = cv.FlannBasedMatcher(index_params,search_params)\n",
    "    matches = flann.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    pts1 = []\n",
    "    pts2 = []\n",
    "\n",
    "    for i,(m,n) in enumerate(matches):\n",
    "        if m.distance < 0.8*n.distance:\n",
    "            pts2.append(kp2[m.trainIdx].pt)\n",
    "            pts1.append(kp1[m.queryIdx].pt)\n",
    "            \n",
    "    pts1 = np.float32(pts1)\n",
    "    pts2 = np.float32(pts2)\n",
    "    print(\"pts1.shape:%s\\tpts2.shape:%s\"%(pts1.shape,pts2.shape))\n",
    "    fundmentalMat, _ = cv.findFundamentalMat(pts1,pts2,cv.FM_LMEDS)\n",
    "    print((\"Fundmental Matrix between image[%d] and image[%d]:\\n%a\") % (idx1,idx2,fundmentalMat))\n",
    "    return fundmentalMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skewForm : skewForm(v).dot(u) = v cross u\n",
    "def skewForm(vec):\n",
    "    sk = np.zeros((3,3))\n",
    "    sk[0][0] = 0\n",
    "    sk[0][1] = -vec[2]\n",
    "    sk[0][2] = vec[1]\n",
    "    sk[1][0] = vec[2]\n",
    "    sk[1][1] = 0\n",
    "    sk[1][2] = -vec[0]\n",
    "    sk[2][0] = -vec[1]\n",
    "    sk[2][1] = vec[0]\n",
    "    sk[2][2] = 0\n",
    "    # sk = np.array(\n",
    "    #     [0,-vec[2],vec[1]],\n",
    "    #     [vec[2],0,-vec[0]],\n",
    "    #     [-vec[1],vec[0],0]\n",
    "    #     )\n",
    "\n",
    "    return sk\n",
    "\n",
    "def get_fundmental_matrix(img1,img2):\n",
    "    p00 = img1[\"projMat\"][0].reshape(1,4)\n",
    "    p01 = img1[\"projMat\"][1].reshape(1,4)\n",
    "    p02 = img1[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    p10 = img2[\"projMat\"][0].reshape(1,4)\n",
    "    p11 = img2[\"projMat\"][1].reshape(1,4)\n",
    "    p12 = img2[\"projMat\"][2].reshape(1,4)\n",
    "\n",
    "    F = np.zeros((3,3))\n",
    "    \n",
    "    ppinv = np.zeros((3,3))\n",
    "\n",
    "    ppinv = np.matmul(img2[\"projMat\"], np.linalg.pinv(img1[\"projMat\"]))\n",
    "\n",
    "    epipole = np.zeros((3,1))\n",
    "\n",
    "    epipole = np.matmul(img2[\"projMat\"],img1[\"optCenter\"])\n",
    "    \n",
    "    funMat = np.zeros((3,3))\n",
    "\n",
    "    funMat = np.matmul(skewForm(epipole),ppinv)\n",
    "\n",
    "    return funMat\n",
    "\n",
    "    # F[0][0] = np.linalg.det(np.concatenate((p01, p02, p11, p12),axis=0))\n",
    "    # F[0][1] = np.linalg.det(np.concatenate((p01, p02, p12, p10),axis=0))\n",
    "    # F[0][2] = np.linalg.det(np.concatenate((p01, p02, p10, p11),axis=0))\n",
    "\n",
    "    # F[1][0] = np.linalg.det(np.concatenate((p02, p00, p11, p12),axis=0))\n",
    "    # F[1][1] = np.linalg.det(np.concatenate((p02, p00, p12, p10),axis=0))\n",
    "    # F[1][2] = np.linalg.det(np.concatenate((p02, p00, p10, p11),axis=0))\n",
    "\n",
    "    # F[2][0] = np.linalg.det(np.concatenate((p00, p01, p11, p12),axis=0))\n",
    "    # F[2][1] = np.linalg.det(np.concatenate((p00, p01, p12, p10),axis=0))\n",
    "    # F[2][2] = np.linalg.det(np.concatenate((p00, p01, p10, p11),axis=0))\n",
    "    \n",
    "    # return F"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Draw Epilines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the epilines corresponding to a point in the first image\n",
    "# Draw also the points satisfying epipolar consistancy \n",
    "def drawlines(img1,lines,pts1):\n",
    "    ''' img1 - image on which we draw the epilines for the points in img2\n",
    "        lines - corresponding epilines '''\n",
    "\n",
    "    reducedFeaturesImage = copy(img1[\"image\"])\n",
    "    fullFeaturesImage = copy(img1[\"image\"])\n",
    "    r,c,_ = reducedFeaturesImage.shape\n",
    "    \n",
    "    for r,pt1 in zip(lines,pts1):\n",
    "        color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        x0,y0 = map(int, [0, -r[2]/r[1] ])\n",
    "        x1,y1 = map(int, [c, -(r[2]+r[0]*c)/r[1] ])\n",
    "        cv.line(reducedFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "        cv.line(fullFeaturesImage, (x0,y0), (x1,y1), color,1)\n",
    "    \n",
    "    \n",
    "    a = lines[0][0]\n",
    "    b = lines[0][1]\n",
    "    c = lines[0][2]\n",
    "    \n",
    "    maxDistance = 2 * np.sqrt((a**2)+(b**2)) \n",
    "    legalFeatures = []\n",
    "    for pt in pts1:\n",
    "        # color = tuple(np.random.randint(0,255,3).tolist())\n",
    "        ptx = pt[0]\n",
    "        pty = pt[1]\n",
    "        if abs(a*ptx+b*pty+c) <= maxDistance :\n",
    "            cv.circle(reducedFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(0,255,0),-1)\n",
    "            legalFeatures.append(np.float32([ptx,pty]))\n",
    "        else:\n",
    "            cv.circle(fullFeaturesImage,tuple(pt),5,(255,0,0),-1)\n",
    "\n",
    "    return fullFeaturesImage,reducedFeaturesImage,legalFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables needed by the objective function\n",
    "referenceImgIdx = 0\n",
    "depthVec = 0    \n",
    "optimPhotos = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(center, normal, photo, opticalCenter):\n",
    "    depthVector = center - opticalCenter.reshape(4,1)\n",
    "    depth = np.linalg.norm(np.array(depthVector))\n",
    "    theta = np.math.acos(normal[2])#pitch\n",
    "    phi = np.math.atan2(normal[1], normal[0])#yaw\n",
    "    depthVector /= depth\n",
    "    return depth, theta, phi, depthVector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(imageModel, unitDepthVec, depth, theta, phi):\n",
    "    opticalCenter = imageModel[\"optCenter\"]\n",
    "    depthVector = depth * unitDepthVec\n",
    "    center = opticalCenter.reshape(4,1) + depthVector\n",
    "    normal = np.zeros((4,1))\n",
    "    normal[0] = np.math.sin(theta)*np.math.cos(phi)\n",
    "    normal[1] = np.math.sin(theta)*np.math.sin(phi)\n",
    "    normal[2] = np.math.cos(theta)\n",
    "    return center, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_objective(center, rightVector, upVector, refPhotoModel, targetPhotosIDs):\n",
    "\n",
    "    cell1 = project_patch(center, refPhotoModel, rightVector, upVector)#overload to get the center  #TODO\n",
    "    SumNcc = 0\n",
    "    for i in range(len(targetPhotosIDs)):\n",
    "        photo = imagesModels[targetPhotosIDs[i]['idx']]\n",
    "        cell2 = project_patch(center, photo, rightVector, upVector)\n",
    "        SumNcc += ncc_score(cell1, cell2)\n",
    "    \n",
    "    return SumNcc / len(targetPhotosIDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x):\n",
    "    depth, theta, phi = x[0], x[1], x[2]\n",
    "    center, normal = decode(imagesModels[referenceImgIdx], depthVec, depth, theta, phi)\n",
    "    #TODO#some conditions\n",
    "    if np.dot(imagesModels[referenceImgIdx][\"optAxis\"], depthVec) < 0:\n",
    "        return 1.0\n",
    "    patch = {}\n",
    "    patch[\"center\"] = center\n",
    "    patch[\"normal\"] = normal\n",
    "    patch[\"referenceImgIdx\"] = referenceImgIdx\n",
    "    right, up = get_patch_vectors(patch) \n",
    "    return -ncc_objective(center, right, up, imagesModels[referenceImgIdx], optimPhotos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(depth, unitDepthVector, patchTrueSet):\n",
    "    sum = 0\n",
    "    for i in range (len(patchTrueSet)):\n",
    "        photo = imagesModels[patchTrueSet[i]['idx']]\n",
    "        depthVectorProj = np.matmul(photo['projMat'], unitDepthVector)\n",
    "        depthVectorProj /= depthVectorProj[2]\n",
    "        sum += np.linalg.norm(np.array(depthVectorProj[-1])) #remove t\n",
    "        \n",
    "    sum /= len(patchTrueSet)\n",
    "    unitDepthVector /= sum\n",
    "    depth *= sum\n",
    "    return depth, unitDepthVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_patch(patch):\n",
    "    global referenceImgIdx\n",
    "    global depthVec\n",
    "    global optimPhotos\n",
    "    refPhoto = imagesModels[patch[\"referenceImgIdx\"]][\"image\"]\n",
    "    opticalCenter = imagesModels[patch[\"referenceImgIdx\"]][\"optCenter\"]\n",
    "\n",
    "    depth, theta, phi, unitDepthVec = encode(patch[\"center\"], patch[\"normal\"], refPhoto, opticalCenter)\n",
    "    depth, unitDepthVec = normalize(depth, unitDepthVec, patch[\"trueSet\"]) #TODO add trueset to patch\n",
    "    targetPhotos = patch[\"trueSet\"]\n",
    "    referenceImgIdx, depthVec, optimPhotos = patch[\"referenceImgIdx\"], unitDepthVec, targetPhotos\n",
    "\n",
    "    option = {\n",
    "        'disp': False, #Set to True to print convergence messages.\n",
    "        'maxiter': 1000,\n",
    "        'xatol': 0.0005,\n",
    "        'adaptive': False #adaptivebool, optional#Adapt algorithm parameters to dimensionality of problem. Useful for high-dimensional minimization\n",
    "        \n",
    "    }\n",
    "    initialGuess = np.array([depth, theta, phi])\n",
    "    solution  = minimize(objective, initialGuess, method='Nelder-Mead', options = option)\n",
    "    center, normal = decode(imagesModels[patch[\"referenceImgIdx\"]], unitDepthVec, solution.x[0], solution.x[1], solution.x[2])\n",
    "    patch[\"center\"], patch[\"normal\"] = center, normal"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Get Relevent Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevent_images(imgModels,idx):\n",
    "    releventImages = []\n",
    "    myOptAxis = imgModels[idx][\"optAxis\"]\n",
    "\n",
    "    for i in range(len(imgModels)):\n",
    "        if i == idx:\n",
    "            continue\n",
    "        otherOptAxis = imgModels[i][\"optAxis\"]\n",
    "        cosAngle = np.dot(myOptAxis,otherOptAxis)\n",
    "\n",
    "        if cosAngle > np.math.cos(np.math.pi/3):\n",
    "            releventImages.append(i)\n",
    "\n",
    "    return releventImages"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Get v/t Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ncc_score(cell1,cell2):\n",
    "    mean1 = np.mean(cell1)\n",
    "    mean2 = np.mean(cell2)\n",
    "    \n",
    "    std1 = std2 = product = 0\n",
    "\t\n",
    "    for i in range(len(cell1)):\n",
    "        diff1 = cell1[i] - mean1\n",
    "        diff2 = cell2[i] - mean2\n",
    "        product += diff1 * diff2\n",
    "        std1 += diff1 * diff1\n",
    "        std2 += diff2 * diff2\n",
    "\t\n",
    "    stds = std1 * std2\n",
    "    if stds == 0:\n",
    "        return 0\n",
    "\n",
    "    return product / np.math.sqrt(stds)\n",
    "\n",
    "def project_patch(patchCenter,imgModel,rightVector,upVector):\n",
    "    cell = np.zeros(patchGridSize*patchGridSize*3)\n",
    "    \n",
    "    projMat = imgModel[\"projMat\"]\n",
    "    projCenter = np.matmul(projMat,patchCenter)\n",
    "    projRight = np.matmul(projMat,rightVector).reshape(3,1)\n",
    "    projUp = np.matmul(projMat,upVector).reshape(3,1)\n",
    "\n",
    "    scale = 1/projCenter[2]\n",
    "    projCenter = scale * projCenter\n",
    "    projRight = scale * projRight\n",
    "    projUp = scale * projUp\n",
    "\n",
    "    step = (patchGridSize-1)/2\n",
    "    diagVector = projUp + projRight\n",
    "    diagVector = step * diagVector\n",
    "    topLeftVector = projCenter - diagVector\n",
    "\n",
    "    cellIdx = 0\n",
    "    for i in range(patchGridSize):\n",
    "        for j in range(patchGridSize):\n",
    "            xCoord = topLeftVector[0] + i*projUp[0] + j*projRight[0]\n",
    "            yCoord = topLeftVector[1] + i*projUp[1] + j*projRight[1]\n",
    "            yCoord = int(yCoord+0.5)\n",
    "            xCoord = int(xCoord+0.5)\n",
    "\n",
    "            # pixel is outside the image\n",
    "            if outside_image_boundry(yCoord,xCoord,len(imgModel['image']),len(imgModel['image'][0])):\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = 0,0,0\n",
    "            else:\n",
    "                cell[cellIdx], cell[cellIdx+1], cell[cellIdx+2] = imgModel[\"image\"][yCoord][xCoord]\n",
    "\n",
    "            cellIdx +=3\n",
    "\n",
    "    return cell\n",
    "\n",
    "def get_ncc_score(patch,releventImgModel,rightVector,upVector):\n",
    "    referenceImgModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "\n",
    "    cell1 = project_patch(patch[\"center\"],referenceImgModel,rightVector,upVector)\n",
    "    cell2 = project_patch(patch[\"center\"],releventImgModel,rightVector,upVector)\n",
    "    return ncc_score(cell1,cell2)\n",
    "\n",
    "def get_patch_vectors(patch):\n",
    "    referenceImageModel = imagesModels[patch[\"referenceImgIdx\"]]\n",
    "    projMat = referenceImageModel[\"projMat\"]\n",
    "\n",
    "    ppinv = np.linalg.pinv(projMat)\n",
    "\n",
    "    scale = np.dot(ppinv[:,0],patch[\"normal\"])\n",
    "    rightVector = ppinv[:,0].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "    scale = np.dot(ppinv[:,1],patch[\"normal\"])\n",
    "    upVector = ppinv[:,1].reshape(4,1) - scale*patch[\"normal\"]\n",
    "\n",
    "\n",
    "    scale = np.dot(projMat[2],patch[\"center\"])\n",
    "    rightVector = (scale/(np.dot(projMat[0],rightVector)))*rightVector\n",
    "    upVector = (scale/(np.dot(projMat[1],upVector)))*upVector\n",
    "\n",
    "    return rightVector, upVector\n",
    "\n",
    "def get_t_images(patch,alfa,visibleImgsIdx):\n",
    "    tImages = []\n",
    "\n",
    "    rightVector,upVector = get_patch_vectors(patch)\n",
    "    for visibleImageIdx in visibleImgsIdx:\n",
    "        visibleImageModel = imagesModels[visibleImageIdx]\n",
    "        \n",
    "        depthVector = np.float32([\n",
    "            visibleImageModel[\"optCenter\"][0] - patch[\"center\"][0],\n",
    "            visibleImageModel[\"optCenter\"][1] - patch[\"center\"][1],\n",
    "            visibleImageModel[\"optCenter\"][2] - patch[\"center\"][2],\n",
    "            visibleImageModel[\"optCenter\"][3] - patch[\"center\"][3]\n",
    "        ])\n",
    "\n",
    "        if np.dot(np.squeeze(depthVector), np.squeeze(patch[\"normal\"])) <= 0:\n",
    "            continue\n",
    "        \n",
    "        nccScore = get_ncc_score(patch, visibleImageModel, rightVector, upVector)\n",
    "        if (1- nccScore) <= alfa:\n",
    "            imgCoord = np.matmul(visibleImageModel['projMat'], patch['center'])\n",
    "            imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "            \n",
    "            x = int(imgCoord[0][0]) // ß1\n",
    "            y = int(imgCoord[1][0]) // ß1\n",
    "            tImages.append({\n",
    "                \"idx\":visibleImageIdx,\n",
    "                \"cell\":{\n",
    "                    'ptx':x,\n",
    "                    'pty':y\n",
    "                },\n",
    "            }) #TODO remove nccscore if not used\n",
    "    \n",
    "    return tImages\n",
    "\n",
    "def get_visible_images(patch,releventImgsIdxs):\n",
    "    visibleSet = np.array([])\n",
    "    pNormal3 = np.array([patch['normal'][0][0],patch['normal'][1][0],patch['normal'][2][0]]).reshape(3,1)\n",
    "    for releventIdx in releventImgsIdxs:\n",
    "        if releventIdx == patch['referenceImgIdx']:\n",
    "            continue\n",
    "        \n",
    "        viewVector = imagesModels[releventIdx]['optCenter'].reshape(4,1) - patch['center']\n",
    "        viewVector3 = np.array([viewVector[0][0], viewVector[1][0], viewVector[2][0]]).reshape(3,1)\n",
    "        viewVector3 = viewVector3 / np.linalg.norm(viewVector3)\n",
    "        \n",
    "        if np.dot(np.squeeze(pNormal3),np.squeeze(viewVector3)) > np.math.cos(np.math.pi/3):\n",
    "            print(\"Normal:\",pNormal3,\"\\nviewVector\",viewVector3)\n",
    "            imgCoord = np.matmul(imagesModels[releventIdx]['projMat'], patch['center'])\n",
    "            print('Bdfore:',patch['center'],'\\n',imgCoord)\n",
    "            imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "            print('After:',patch['center'],'\\n',imgCoord)\n",
    "            \n",
    "            x = int(imgCoord[0][0]) // ß1\n",
    "            y = int(imgCoord[1][0]) // ß1\n",
    "            visibleSet = np.append(visibleSet, {\n",
    "                'idx':releventIdx,\n",
    "                \"cell\":{\n",
    "                    'ptx':x,\n",
    "                    'pty':y\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    imgCoord = np.matmul(imagesModels[releventIdx]['projMat'], patch['center'])\n",
    "    imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "\n",
    "    x = int(imgCoord[0][0]) // ß1\n",
    "    y = int(imgCoord[1][0]) // ß1\n",
    "    visibleSet = np.append(visibleSet, {\n",
    "        'idx':patch['referenceImgIdx'],\n",
    "        \"cell\":{\n",
    "            'ptx':x,\n",
    "            'pty':y\n",
    "        }\n",
    "    })\n",
    "    return visibleSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_patch(patch):\n",
    "    for sImg in patch[\"visibleSet\"]:\n",
    "        imgModel = imagesModels[sImg['idx']]\n",
    "        imgCoord = np.matmul(imgModel['projMat'], patch['center'])\n",
    "        imgCoord = imgCoord/imgCoord[2][0] #divide by t\n",
    "\n",
    "        x = int(imgCoord[0][0]) // ß1\n",
    "        y = int(imgCoord[1][0]) // ß1\n",
    "        cell1 = imgModel['grid'][y][x]\n",
    "        \n",
    "        if not any(imgIdx == sImg['idx'] for imgIdx in patch['trueSet']):\n",
    "            cell1['Qf'].append(patch)\n",
    "        else:\n",
    "            cell1['Qt'].append(patch)\n",
    "        \n",
    "        sImg['cell'] = {\n",
    "            'ptx':x,\n",
    "            'pty':y,\n",
    "        }\n",
    "    patches.append(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_cell(imageID, y, x):\n",
    "    cell_y = y // ß1\n",
    "    cell_x = x // ß1\n",
    "    if len(imagesModels[imageID]['grid'][cell_y][cell_x]['Qt']) == 0 and len(imagesModels[imageID]['grid'][cell_y][cell_x]['Qf']) == 0 :\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_statsify_epipoler_consistency(baseImageIdx, featurePt,featureType):\n",
    "    triangulations = list()\n",
    "    for i in range(len(imagesModels[baseImageIdx][\"releventImgsIdxs\"])):\n",
    "        releventImageIdx = imagesModels[baseImageIdx][\"releventImgsIdxs\"][i]\n",
    "        fundmentalMat = get_fundmental_matrix(imagesModels[baseImageIdx],imagesModels[releventImageIdx])\n",
    "\n",
    "        if fundmentalMat is None:\n",
    "            continue\n",
    "        pt1 = featurePt\n",
    "        pts1 = np.int32([pt1])\n",
    "        pts2 = np.int32(imagesModels[releventImageIdx][featureType])\n",
    "\n",
    "        originalWithFeaturePt = imagesModels[baseImageIdx][\"image\"].copy()\n",
    "        cv.circle(originalWithFeaturePt,tuple(pt1),5,(0,0,255),-1)\n",
    "\n",
    "        # Get the epilines of features in left image on the right image\n",
    "        # parameter1: points required to get its epilines in the other image\n",
    "        # parameter2: which image that points are belong, 1-left 2-right\n",
    "        # parameter3: fundmental matrix between the 2 images\n",
    "        # returns list of epilines that lie on the other image and corresponding to the points\n",
    "        lines = cv.computeCorrespondEpilines(pts1.reshape(-1,1,2), 1,fundmentalMat)\n",
    "        lines = lines.reshape(-1,3)\n",
    "        #sara_im = plot_epipolar_line(imagesModels[i][\"image\"],fundmentalMat,[pt1[0],pt1[1],1])\n",
    "\n",
    "        # draw the epiline on the other image\n",
    "        # parameter1: the second image\n",
    "        # parameter2: the epilines that lie on the second image\n",
    "        # parameter3: the features lie on the second image\n",
    "        fullFeaturesImage,reducedFeaturesImage,legalFeatures = drawlines(imagesModels[releventImageIdx],lines,pts2)\n",
    "\n",
    "        #Triangulation\n",
    "        for j in range(len(legalFeatures)):\n",
    "            if not(empty_cell(releventImageIdx, int(legalFeatures[j][1]), int(legalFeatures[j][0]))): #TODO check t = 1\n",
    "                continue\n",
    "                \n",
    "            triangulatedPointsHomogeneous = cv.triangulatePoints(imagesModels[baseImageIdx][\"projMat\"],imagesModels[releventImageIdx][\"projMat\"],pt1,legalFeatures[j])\n",
    "            triangulatedPoint = triangulatedPointsHomogeneous[:4, :] / triangulatedPointsHomogeneous[3, :]\n",
    "\n",
    "            #triangulatedPoint = triangulate_point(np.array([pt1[0], pt1[1],1]),legalFeatures[j],imagesModels[baseImageIdx][\"projMat\"],imagesModels[i][\"projMat\"])\n",
    "\n",
    "            distFromcenter = abs(abs(np.linalg.norm(np.array(imagesModels[baseImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))) - abs(np.linalg.norm(np.array(imagesModels[releventImageIdx][\"optCenter\"][:-1]) - np.array([triangulatedPoint[0][0], triangulatedPoint[1][0], triangulatedPoint[2][0]]))))\n",
    "\n",
    "            triangulation = {\n",
    "                \"originalImg\": releventImageIdx,\n",
    "                \"position\": triangulatedPoint,\n",
    "                \"distFromCenter\": distFromcenter,\n",
    "                \"ptx\": legalFeatures[j][0],\n",
    "                \"pty\": legalFeatures[j][1]\n",
    "            }\n",
    "\n",
    "            triangulations.append(triangulation)\n",
    "\n",
    "        #show_images([imagesModels[baseImageIdx][\"image\"],imagesModels[releventImageIdx][\"image\"],fullFeaturesImage,reducedFeaturesImage, originalWithFeaturePt],[\"image\"+str(baseImageIdx),\"image\"+str(releventImageIdx),\"fullfeatures in image\"+str(releventImageIdx),\"reducedfeatures in image\"+str(releventImageIdx), \"originalWithFeaturePt\"+str(releventImageIdx)])\n",
    "\n",
    "    triangulations = sorted(triangulations, key=lambda k: k[\"distFromCenter\"]) \n",
    "    #for i in range(len(triangulations)):\n",
    "        #print(\"triangulations: \", triangulations[i][\"originalImg\"], \"ptx\", triangulations[i][\"ptx\"], \"pty\", triangulations[i][\"pty\"], triangulations[i][\"distFromCenter\"])\n",
    "    \n",
    "    return triangulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_patches(baseImageIdx, triangulations):\n",
    "    #print(\"construct_patches ...\")\n",
    "    baseOptCenter = imagesModels[baseImageIdx][\"optCenter\"]\n",
    "    for candidate in triangulations:\n",
    "\n",
    "        patch = {}\n",
    "        patch[\"referenceImgIdx\"] = baseImageIdx\n",
    "        patch[\"center\"] = candidate[\"position\"]\n",
    "        patch[\"normal\"] = np.float32([\n",
    "                baseOptCenter[0] - candidate[\"position\"][0],\n",
    "                baseOptCenter[1] - candidate[\"position\"][1],\n",
    "                baseOptCenter[2] - candidate[\"position\"][2],\n",
    "                baseOptCenter[3] - candidate[\"position\"][3],\n",
    "            ])\n",
    "        patch[\"normal\"] = patch[\"normal\"] / np.linalg.norm(patch[\"normal\"])\n",
    "\n",
    "        patch['visibleSet'] = get_visible_images(patch,imagesModels[baseImageIdx][\"releventImgsIdxs\"])\n",
    "        print(patch['visibleSet'][:])\n",
    "        break\n",
    "        patch[\"trueSet\"] = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"]) \n",
    "\n",
    "        #print(\"len(patch[trueSet]): \", len(patch[\"trueSet\"]))\n",
    "        if len(patch[\"trueSet\"]) <= 1 : \n",
    "            continue\n",
    "\n",
    "        optimize_patch(patch)\n",
    "        patch[\"visibleSet\"] = get_t_images(patch,0.6,imagesModels[baseImageIdx][\"releventImgsIdxs\"]) \n",
    "        patch[\"trueSet\"] = get_t_images(patch,0.3,imagesModels[baseImageIdx][\"releventImgsIdxs\"])\n",
    "        #print(\"len(patch[trueSet]): \", len(patch[\"trueSet\"]), \" gamma: \", gamma)\n",
    "        if len(patch[\"trueSet\"]) >= gamma:\n",
    "            register_patch(patch)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Read Input---->DONE\nImageID: 0 \tharris: 287 \tDoG: 295\nImageID: 1 \tharris: 290 \tDoG: 294\nImageID: 2 \tharris: 236 \tDoG: 250\nImageID: 3 \tharris: 201 \tDoG: 215\nImageID: 4 \tharris: 249 \tDoG: 263\nImageID: 5 \tharris: 241 \tDoG: 250\nImageID: 6 \tharris: 242 \tDoG: 260\nImageID: 7 \tharris: 273 \tDoG: 277\nImageID: 8 \tharris: 293 \tDoG: 297\nImageID: 9 \tharris: 287 \tDoG: 293\nImageID: 10 \tharris: 287 \tDoG: 294\nImageID: 11 \tharris: 236 \tDoG: 244\nImageID: 12 \tharris: 193 \tDoG: 206\nImageID: 13 \tharris: 192 \tDoG: 205\nImageID: 14 \tharris: 211 \tDoG: 217\nImageID: 15 \tharris: 268 \tDoG: 279\nFeature Detection---->DONE\nGet Relevent Images---->DONE\n"
    }
   ],
   "source": [
    "images,grids = init_imgs(datasetPath)\n",
    "projections,optAxes = read_parameters_file(datasetPath)\n",
    "print(\"Read Input---->DONE\")\n",
    "imagesModels = list()\n",
    "\n",
    "for idx,image in enumerate(images):\n",
    "    dog,harris = get_dog_harris(image)\n",
    "    sparseDog,sparseHarris,dogPositions,harrisPositions = sparse_dog_harris(dog,harris)\n",
    "    opticalCenter = getOpticalCenter(projections[idx])\n",
    "    imgModel={\n",
    "        \"image\": images[idx],\n",
    "        \"projMat\": projections[idx],\n",
    "        \"optCenter\": opticalCenter,\n",
    "        \"optAxis\": optAxes[idx],\n",
    "        \"grid\": grids[idx],\n",
    "        \"dog\": dog,\n",
    "        \"harris\": harris,\n",
    "        \"sparseDog\": sparseDog,\n",
    "        \"sparseHarris\": sparseHarris,\n",
    "        \"dogPositions\": dogPositions,\n",
    "        \"harrisPositions\": harrisPositions\n",
    "    }\n",
    "    print(\"ImageID:\", str(idx),\"\\tharris:\",str(len(harrisPositions)),\"\\tDoG:\", str(len(dogPositions)))\n",
    "    imagesModels.append(imgModel)\n",
    "\n",
    "print(\"Feature Detection---->DONE\")\n",
    "\n",
    "for i in range(len(imagesModels)):\n",
    "    imagesModels[i][\"releventImgsIdxs\"] = get_relevent_images(imagesModels,i)\n",
    "    \n",
    "print(\"Get Relevent Images---->DONE\")\n",
    "# show_images([imagesModels[0][\"dog\"],imagesModels[0][\"sparseDog\"],imagesModels[0][\"harris\"],imagesModels[0][\"sparseHarris\"]],['dog','sparse dog','harris','sparse harris'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Start Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start Matching....\nTotal number of patches:  0\nImageID: 0 harrisPositions Number of Features: 287 Done-->Number of constructed patches: 120\nImageID: 0 dogPositions Number of Features: 295 Done-->Number of constructed patches: 96\n\nImageID: 1 harrisPositions Number of Features: 290 Done-->Number of constructed patches: 160\nImageID: 1 dogPositions Number of Features: 294 Done-->Number of constructed patches: 119\n\nImageID: 2 harrisPositions Number of Features: 236 Done-->Number of constructed patches: 135\nImageID: 2 dogPositions Number of Features: 250 Done-->Number of constructed patches: 108\n\nImageID: 3 harrisPositions Number of Features: 201 Done-->Number of constructed patches: 95\nImageID: 3 dogPositions Number of Features: 215 Done-->Number of constructed patches: 73\n\nImageID: 4 harrisPositions Number of Features: 249 Done-->Number of constructed patches: 85\nImageID: 4 dogPositions Number of Features: 263 Done-->Number of constructed patches: 57\n\nImageID: 5 harrisPositions Number of Features: 241 Done-->Number of constructed patches: 82\nImageID: 5 dogPositions Number of Features: 250 Done-->Number of constructed patches: 49\n\nImageID: 6 harrisPositions Number of Features: 242 Done-->Number of constructed patches: 109\nImageID: 6 dogPositions Number of Features: 260 Done-->Number of constructed patches: 85\n\nImageID: 7 harrisPositions Number of Features: 273 Done-->Number of constructed patches: 148\nImageID: 7 dogPositions Number of Features: 277 Done-->Number of constructed patches: 127\n\nImageID: 8 harrisPositions Number of Features: 293 Done-->Number of constructed patches: 157\nImageID: 8 dogPositions Number of Features: 297 Done-->Number of constructed patches: 137\n\nImageID: 9 harrisPositions Number of Features: 287 Done-->Number of constructed patches: 154\nImageID: 9 dogPositions Number of Features: 293 Done-->Number of constructed patches: 130\n\nImageID: 10 harrisPositions Number of Features: 287 Done-->Number of constructed patches: 138\nImageID: 10 dogPositions Number of Features: 294 Done-->Number of constructed patches: 119\n\nImageID: 11 harrisPositions Number of Features: 236 Done-->Number of constructed patches: 97\nImageID: 11 dogPositions Number of Features: 244 Done-->Number of constructed patches: 62\n\nImageID: 12 harrisPositions Number of Features: 193 Done-->Number of constructed patches: 69\nImageID: 12 dogPositions Number of Features: 206 Done-->Number of constructed patches: 53\n\nImageID: 13 harrisPositions Number of Features: 192 Done-->Number of constructed patches: 88\nImageID: 13 dogPositions Number of Features: 205 Done-->Number of constructed patches: 60\n\nImageID: 14 harrisPositions Number of Features: 211 Done-->Number of constructed patches: 116\nImageID: 14 dogPositions Number of Features: 217 Done-->Number of constructed patches: 86\n\nImageID: 15 harrisPositions Number of Features: 268 Done-->Number of constructed patches: 114\nImageID: 15 dogPositions Number of Features: 279 Done-->Number of constructed patches: 80\n\nTotal number of patches: 3308\n"
    }
   ],
   "source": [
    "print(\"Start Matching....\")\n",
    "patches = list()\n",
    "numberOfPatches = 0\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "for i in range(len(imagesModels)):\n",
    "    baseImageIdx = i\n",
    "    completeCell = np.zeros((len(imagesModels[baseImageIdx]['image'])//ß1,len(imagesModels[baseImageIdx]['image'][0])//ß1))\n",
    "    featureTypes = [\"harrisPositions\",'dogPositions']\n",
    "    for featureType in featureTypes:\n",
    "        #if featureType == 'harrisPositions':\n",
    "            #continue\n",
    "        for featurePt in imagesModels[baseImageIdx][featureType]:\n",
    "            if completeCell[featurePt[1]//ß1][featurePt[0]//ß1]:\n",
    "                continue\n",
    "                \n",
    "            if not(empty_cell(baseImageIdx, featurePt[1], featurePt[0])):\n",
    "                # print(\"non empty cell\")\n",
    "                continue\n",
    "            #print(\"empty cell\")\n",
    "            features  = get_features_statsify_epipoler_consistency(baseImageIdx, featurePt,featureType)\n",
    "            construct_patches(baseImageIdx, features)\n",
    "            completeCell[featurePt[1]//ß1][featurePt[0]//ß1] = 1\n",
    "        print(\"ImageID:\", str(baseImageIdx),featureType,\"Number of Features:\", str(len(imagesModels[baseImageIdx][featureType])),\"Done-->Number of constructed patches:\", str(len(patches) - numberOfPatches))\n",
    "        numberOfPatches = len(patches)\n",
    "    print()\n",
    "print(\"Total number of patches:\", len(patches))\n",
    "originalImageModels = deepcopy(imagesModels)\n",
    "originalPatches = deepcopy(patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_header(file):\n",
    "    file.write(\"ply\\n\")\n",
    "    file.write(\"format ascii 1.0\\n\")\n",
    "    file.write( \"element vertex \"+ str(len(patches)) + \"\\n\")\n",
    "    file.write( \"property float x\\n\")\n",
    "    file.write(\"property float y\\n\")\n",
    "    file.write(\"property float z\\n\")\n",
    "    file.write(\"property float nx\\n\")\n",
    "    file.write(\"property float ny\\n\")\n",
    "    file.write(\"property float nz\\n\")\n",
    "    file.write(\"property uchar diffuse_red\\n\")\n",
    "    file.write(\"property uchar diffuse_green\\n\")\n",
    "    file.write(\"property uchar diffuse_blue\\n\")\n",
    "    file.write( \"end_header\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ply(): \n",
    "    file = open(\"pointcloud.txt.ply\", \"w\")\n",
    "    write_header(file)\n",
    "    for patch in patches:\n",
    "        file.write(str(patch[\"center\"][0][0]) + \" \" +  str(patch[\"center\"][1][0]) + \" \" + str(patch[\"center\"][2][0]) + \" \")\n",
    "        file.write(str(patch[\"normal\"][0][0]) + \" \" +  str(patch[\"normal\"][1][0]) + \" \" + str(patch[\"normal\"][2][0]) + \" \")\n",
    "        file.write(\"255\"+ \" \" + \"0\" + \" \"+\"0\")\n",
    "        file.write(\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    \n",
    "write_ply()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "minimum X:  -0.09080464488810025  maximum X:  0.04821384224063885\nminimum Y:  -0.05603411919822965  maximum Y:  0.06868740551299295\nminimum Z:  -0.10114196119154806  maximum Z:  0.08714915343371932\n"
    }
   ],
   "source": [
    "def get_boundaries():\n",
    "\n",
    "    minimumX = np.math.inf\n",
    "    minimumY = np.math.inf\n",
    "    minimumZ = np.math.inf\n",
    "    maximumX = - np.math.inf\n",
    "    maximumY = - np.math.inf\n",
    "    maximumZ = - np.math.inf\n",
    "    for patch in patches:\n",
    "        # Get the minimum center\n",
    "        if patch[\"center\"][0][0] < minimumX:\n",
    "            minimumX = patch[\"center\"][0][0]\n",
    "        if patch[\"center\"][1][0] < minimumY:\n",
    "            minimumY = patch[\"center\"][1][0]\n",
    "        if patch[\"center\"][2][0] < minimumZ:\n",
    "            minimumZ = patch[\"center\"][2][0]\n",
    "\n",
    "        # get the maximum center\n",
    "\n",
    "        if patch[\"center\"][0][0] > maximumX:\n",
    "            maximumX = patch[\"center\"][0][0]\n",
    "        if patch[\"center\"][1][0] > maximumY:\n",
    "            maximumY = patch[\"center\"][1][0]\n",
    "        if patch[\"center\"][2][0] > maximumZ:\n",
    "            maximumZ = patch[\"center\"][2][0]\n",
    "    print(\"minimum X: \",minimumX,\" maximum X: \",maximumX)\n",
    "    print(\"minimum Y: \",minimumY,\" maximum Y: \",maximumY)\n",
    "    print(\"minimum Z: \",minimumZ,\" maximum Z: \",maximumZ)\n",
    "\n",
    "\n",
    "get_boundaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2> Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbor_cells(originalPatch):\n",
    "    neighborCells = []\n",
    "    for idx,visibleImage in enumerate(originalPatch['visibleSet']):\n",
    "        x = visibleImage['cell']['ptx']\n",
    "        y = visibleImage['cell']['pty']\n",
    "        \n",
    "        # Get neighbor cells\n",
    "        for neighborY in range(y-1,y+2,1):\n",
    "            for neighborX in range(x-1,x+2,1):\n",
    "                # diagonal cells\n",
    "                if (abs(neighborY-y) + abs(neighborX-x)) != 1:\n",
    "                    continue\n",
    "\n",
    "                if not outside_image_boundry(neighborY,neighborX,len(imagesModels[0]['image'])//ß1,len(imagesModels[0]['image'][0])//ß1):\n",
    "                    neighborCell = imagesModels[visibleImage['idx']]['grid'][neighborY][neighborX]\n",
    "                    # non empty cell Qt\n",
    "                    if len(neighborCell['Qt']) != 0:\n",
    "                        continue\n",
    "                        \n",
    "                   \n",
    "                        # print(\"not neighbors\")\n",
    "                    neighborCells.append({\n",
    "                        'idx':visibleImage['idx'],\n",
    "                        \"x\":neighborX,\n",
    "                        \"y\":neighborY,\n",
    "                        \"neighborCell\":neighborCell\n",
    "                    })\n",
    "    return neighborCells\n",
    "\n",
    "def construct_expanded_patch(originalPatch,neighborCell):    \n",
    "    newPatch = {}\n",
    "    newPatch[\"referenceImgIdx\"] = originalPatch[\"referenceImgIdx\"]\n",
    "    newPatch[\"normal\"] = originalPatch[\"normal\"]\n",
    "    #newPatch[\"trueSet\"] = originalPatch[\"trueSet\"]\n",
    "\n",
    "    # Get the ray\n",
    "    cellCenter = np.array([neighborCell['x'],neighborCell['y'],1]).reshape(3,1)\n",
    "    projMat = imagesModels[originalPatch['referenceImgIdx']][\"projMat\"]\n",
    "    ppinv = np.linalg.pinv(projMat)\n",
    "\n",
    "    m = projMat[:,:3]\n",
    "    p4 = projMat[:,3].reshape(3,1)\n",
    "    minv = np.linalg.inv(m)\n",
    "\n",
    "    b = cellCenter - p4\n",
    "    cellCenter3D = np.matmul(minv,b) \n",
    "    cellCenter3D = np.append(cellCenter3D,1).reshape(4,1)\n",
    "\n",
    "    optCenter = imagesModels[originalPatch['referenceImgIdx']][\"optCenter\"].reshape(4,1) \n",
    "    ray = cellCenter3D - optCenter\n",
    "    ray = ray / np.linalg.norm(ray)\n",
    "\n",
    "    # cellCenter3D = np.matmul(ppinv,cellCenter)\n",
    "    # scaleCell = 1/cellCenter3D[3]\n",
    "    # cellCenter3D = scaleCell * cellCenter3D\n",
    "    # ray = cellCenter3D + imagesModels[originalPatch['referenceImgIdx']][\"optCenter\"].reshape(4,1)\n",
    "    # normalize the ray\n",
    "    \n",
    "    if abs(np.dot(np.squeeze(ray),np.squeeze(newPatch['normal']))) < 10**-6:\n",
    "        print(\"ray parallel to originalPatch\")\n",
    "        return None\n",
    "    \n",
    "        # Get the intersection\n",
    "    t = (- np.dot(np.squeeze(originalPatch['normal']),np.squeeze(cellCenter3D- originalPatch['center'])))/(np.dot(np.squeeze(originalPatch['normal']),np.squeeze(ray)))\n",
    "    intersection = t*ray + cellCenter3D\n",
    "\n",
    "    scaleT = 1/intersection[3]\n",
    "    intersection = intersection * scaleT\n",
    "\n",
    "    # Check if the intersection in the bounding volume \n",
    "    # if intersection[0] > maximumX or intersection[0] < minimumX or intersection[1] > maximumY or intersection[1] < minimumY or intersection[2] > maximumZ or intersection[2] > minimumZ :\n",
    "    #    continue\n",
    "\n",
    "    newPatch['center'] = intersection\n",
    "    newPatch['trueSet'] = get_t_images(newPatch,0.6,imagesModels[newPatch[\"referenceImgIdx\"]][\"releventImgsIdxs\"])\n",
    "    newPatch[\"visibleSet\"] = originalPatch['visibleSet']\n",
    "    #-------\n",
    "    #optimize_patch(newPatch)\n",
    "    #newVImgs = get_t_images(newPatch,0.6,imagesModels[newPatch[\"referenceImgIdx\"]][\"releventImgsIdxs\"])\n",
    "\n",
    "    #for newVImg in newVImgs:\n",
    "     #   found = False\n",
    "      #  for vImg in newPatch[\"visibleSet\"]:\n",
    "       #     if newVImg['idx'] == vImg['idx']:\n",
    "        #        found = True\n",
    "         #       break\n",
    "\n",
    "        #if not found:\n",
    "         #   newPatch[\"visibleSet\"].append(newVImg)\n",
    "    \n",
    "    #visibleIdxs = [vImg['idx'] for vImg in newPatch[\"visibleSet\"]]\n",
    "    #newPatch[\"trueSet\"] = get_t_images(newPatch,0.7,visibleIdxs)\n",
    "    #------\n",
    "    return newPatch"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<h2>Start Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "5877 \tremaining patches: 856\nThe total number of patches now: 25880 \tremaining patches: 855\nThe total number of patches now: 25880 \tremaining patches: 854\nThe total number of patches now: 25880 \tremaining patches: 853\nThe total number of patches now: 25880 \tremaining patches: 852\nThe total number of patches now: 25883 \tremaining patches: 851\nThe total number of patches now: 25897 \tremaining patches: 850\nThe total number of patches now: 25909 \tremaining patches: 849\nThe total number of patches now: 25924 \tremaining patches: 848\nThe total number of patches now: 25934 \tremaining patches: 847\nThe total number of patches now: 25950 \tremaining patches: 846\nThe total number of patches now: 25960 \tremaining patches: 845\nThe total number of patches now: 25968 \tremaining patches: 844\nThe total number of patches now: 25968 \tremaining patches: 843\nThe total number of patches now: 25972 \tremaining patches: 842\nThe total number of patches now: 25982 \tremaining patches: 841\nThe total number of patches now: 25994 \tremaining patches: 840\nThe total number of patches now: 26005 \tremaining patches: 839\nThe total number of patches now: 26017 \tremaining patches: 838\nThe total number of patches now: 26029 \tremaining patches: 837\nThe total number of patches now: 26041 \tremaining patches: 836\nThe total number of patches now: 26050 \tremaining patches: 835\nThe total number of patches now: 26058 \tremaining patches: 834\nThe total number of patches now: 26070 \tremaining patches: 833\nThe total number of patches now: 26086 \tremaining patches: 832\nThe total number of patches now: 26098 \tremaining patches: 831\nThe total number of patches now: 26114 \tremaining patches: 830\nThe total number of patches now: 26126 \tremaining patches: 829\nThe total number of patches now: 26141 \tremaining patches: 828\nThe total number of patches now: 26141 \tremaining patches: 827\nThe total number of patches now: 26142 \tremaining patches: 826\nThe total number of patches now: 26149 \tremaining patches: 825\nThe total number of patches now: 26155 \tremaining patches: 824\nThe total number of patches now: 26156 \tremaining patches: 823\nThe total number of patches now: 26157 \tremaining patches: 822\nThe total number of patches now: 26160 \tremaining patches: 821\nThe total number of patches now: 26163 \tremaining patches: 820\nThe total number of patches now: 26176 \tremaining patches: 819\nThe total number of patches now: 26184 \tremaining patches: 818\nThe total number of patches now: 26193 \tremaining patches: 817\nThe total number of patches now: 26195 \tremaining patches: 816\nThe total number of patches now: 26195 \tremaining patches: 815\nThe total number of patches now: 26195 \tremaining patches: 814\nThe total number of patches now: 26200 \tremaining patches: 813\nThe total number of patches now: 26204 \tremaining patches: 812\nThe total number of patches now: 26220 \tremaining patches: 811\nThe total number of patches now: 26228 \tremaining patches: 810\nThe total number of patches now: 26244 \tremaining patches: 809\nThe total number of patches now: 26259 \tremaining patches: 808\nThe total number of patches now: 26267 \tremaining patches: 807\nThe total number of patches now: 26267 \tremaining patches: 806\nThe total number of patches now: 26267 \tremaining patches: 805\nThe total number of patches now: 26267 \tremaining patches: 804\nThe total number of patches now: 26271 \tremaining patches: 803\nThe total number of patches now: 26275 \tremaining patches: 802\nThe total number of patches now: 26281 \tremaining patches: 801\nThe total number of patches now: 26283 \tremaining patches: 800\nThe total number of patches now: 26288 \tremaining patches: 799\nThe total number of patches now: 26288 \tremaining patches: 798\nThe total number of patches now: 26288 \tremaining patches: 797\nThe total number of patches now: 26290 \tremaining patches: 796\nThe total number of patches now: 26290 \tremaining patches: 795\nThe total number of patches now: 26291 \tremaining patches: 794\nThe total number of patches now: 26295 \tremaining patches: 793\nThe total number of patches now: 26302 \tremaining patches: 792\nThe total number of patches now: 26315 \tremaining patches: 791\nThe total number of patches now: 26331 \tremaining patches: 790\nThe total number of patches now: 26347 \tremaining patches: 789\nThe total number of patches now: 26347 \tremaining patches: 788\nThe total number of patches now: 26347 \tremaining patches: 787\nThe total number of patches now: 26351 \tremaining patches: 786\nThe total number of patches now: 26358 \tremaining patches: 785\nThe total number of patches now: 26367 \tremaining patches: 784\nThe total number of patches now: 26379 \tremaining patches: 783\nThe total number of patches now: 26395 \tremaining patches: 782\nThe total number of patches now: 26411 \tremaining patches: 781\nThe total number of patches now: 26427 \tremaining patches: 780\nThe total number of patches now: 26443 \tremaining patches: 779\nThe total number of patches now: 26455 \tremaining patches: 778\nThe total number of patches now: 26459 \tremaining patches: 777\nThe total number of patches now: 26459 \tremaining patches: 776\nThe total number of patches now: 26468 \tremaining patches: 775\nThe total number of patches now: 26476 \tremaining patches: 774\nThe total number of patches now: 26484 \tremaining patches: 773\nThe total number of patches now: 26499 \tremaining patches: 772\nThe total number of patches now: 26515 \tremaining patches: 771\nThe total number of patches now: 26531 \tremaining patches: 770\nThe total number of patches now: 26541 \tremaining patches: 769\nThe total number of patches now: 26550 \tremaining patches: 768\nThe total number of patches now: 26556 \tremaining patches: 767\nThe total number of patches now: 26561 \tremaining patches: 766\nThe total number of patches now: 26561 \tremaining patches: 765\nThe total number of patches now: 26568 \tremaining patches: 764\nThe total number of patches now: 26578 \tremaining patches: 763\nThe total number of patches now: 26581 \tremaining patches: 762\nThe total number of patches now: 26587 \tremaining patches: 761\nThe total number of patches now: 26601 \tremaining patches: 760\nThe total number of patches now: 26613 \tremaining patches: 759\nThe total number of patches now: 26623 \tremaining patches: 758\nThe total number of patches now: 26639 \tremaining patches: 757\nThe total number of patches now: 26644 \tremaining patches: 756\nThe total number of patches now: 26651 \tremaining patches: 755\nThe total number of patches now: 26651 \tremaining patches: 754\nThe total number of patches now: 26657 \tremaining patches: 753\nThe total number of patches now: 26669 \tremaining patches: 752\nThe total number of patches now: 26681 \tremaining patches: 751\nThe total number of patches now: 26696 \tremaining patches: 750\nThe total number of patches now: 26704 \tremaining patches: 749\nThe total number of patches now: 26719 \tremaining patches: 748\nThe total number of patches now: 26728 \tremaining patches: 747\nThe total number of patches now: 26744 \tremaining patches: 746\nThe total number of patches now: 26751 \tremaining patches: 745\nThe total number of patches now: 26761 \tremaining patches: 744\nThe total number of patches now: 26773 \tremaining patches: 743\nThe total number of patches now: 26776 \tremaining patches: 742\nThe total number of patches now: 26783 \tremaining patches: 741\nThe total number of patches now: 26795 \tremaining patches: 740\nThe total number of patches now: 26802 \tremaining patches: 739\nThe total number of patches now: 26810 \tremaining patches: 738\nThe total number of patches now: 26823 \tremaining patches: 737\nThe total number of patches now: 26836 \tremaining patches: 736\nThe total number of patches now: 26836 \tremaining patches: 735\nThe total number of patches now: 26842 \tremaining patches: 734\nThe total number of patches now: 26850 \tremaining patches: 733\nThe total number of patches now: 26862 \tremaining patches: 732\nThe total number of patches now: 26867 \tremaining patches: 731\nThe total number of patches now: 26871 \tremaining patches: 730\nThe total number of patches now: 26871 \tremaining patches: 729\nThe total number of patches now: 26879 \tremaining patches: 728\nThe total number of patches now: 26882 \tremaining patches: 727\nThe total number of patches now: 26883 \tremaining patches: 726\nThe total number of patches now: 26887 \tremaining patches: 725\nThe total number of patches now: 26890 \tremaining patches: 724\nThe total number of patches now: 26890 \tremaining patches: 723\nThe total number of patches now: 26898 \tremaining patches: 722\nThe total number of patches now: 26914 \tremaining patches: 721\nThe total number of patches now: 26918 \tremaining patches: 720\nThe total number of patches now: 26918 \tremaining patches: 719\nThe total number of patches now: 26921 \tremaining patches: 718\nThe total number of patches now: 26926 \tremaining patches: 717\nThe total number of patches now: 26935 \tremaining patches: 716\nThe total number of patches now: 26935 \tremaining patches: 715\nThe total number of patches now: 26935 \tremaining patches: 714\nThe total number of patches now: 26935 \tremaining patches: 713\nThe total number of patches now: 26940 \tremaining patches: 712\nThe total number of patches now: 26955 \tremaining patches: 711\nThe total number of patches now: 26966 \tremaining patches: 710\nThe total number of patches now: 26982 \tremaining patches: 709\nThe total number of patches now: 26989 \tremaining patches: 708\nThe total number of patches now: 26997 \tremaining patches: 707\nThe total number of patches now: 27003 \tremaining patches: 706\nThe total number of patches now: 27011 \tremaining patches: 705\nThe total number of patches now: 27023 \tremaining patches: 704\nThe total number of patches now: 27039 \tremaining patches: 703\nThe total number of patches now: 27051 \tremaining patches: 702\nThe total number of patches now: 27059 \tremaining patches: 701\nThe total number of patches now: 27065 \tremaining patches: 700\nThe total number of patches now: 27073 \tremaining patches: 699\nThe total number of patches now: 27081 \tremaining patches: 698\nThe total number of patches now: 27089 \tremaining patches: 697\nThe total number of patches now: 27105 \tremaining patches: 696\nThe total number of patches now: 27117 \tremaining patches: 695\nThe total number of patches now: 27126 \tremaining patches: 694\nThe total number of patches now: 27134 \tremaining patches: 693\nThe total number of patches now: 27134 \tremaining patches: 692\nThe total number of patches now: 27146 \tremaining patches: 691\nThe total number of patches now: 27152 \tremaining patches: 690\nThe total number of patches now: 27157 \tremaining patches: 689\nThe total number of patches now: 27173 \tremaining patches: 688\nThe total number of patches now: 27181 \tremaining patches: 687\nThe total number of patches now: 27181 \tremaining patches: 686\nThe total number of patches now: 27189 \tremaining patches: 685\nThe total number of patches now: 27197 \tremaining patches: 684\nThe total number of patches now: 27205 \tremaining patches: 683\nThe total number of patches now: 27221 \tremaining patches: 682\nThe total number of patches now: 27231 \tremaining patches: 681\nThe total number of patches now: 27243 \tremaining patches: 680\nThe total number of patches now: 27251 \tremaining patches: 679\nThe total number of patches now: 27263 \tremaining patches: 678\nThe total number of patches now: 27264 \tremaining patches: 677\nThe total number of patches now: 27274 \tremaining patches: 676\nThe total number of patches now: 27287 \tremaining patches: 675\nThe total number of patches now: 27297 \tremaining patches: 674\nThe total number of patches now: 27301 \tremaining patches: 673\nThe total number of patches now: 27302 \tremaining patches: 672\nThe total number of patches now: 27308 \tremaining patches: 671\nThe total number of patches now: 27320 \tremaining patches: 670\nThe total number of patches now: 27328 \tremaining patches: 669\nThe total number of patches now: 27332 \tremaining patches: 668\nThe total number of patches now: 27336 \tremaining patches: 667\nThe total number of patches now: 27339 \tremaining patches: 666\nThe total number of patches now: 27339 \tremaining patches: 665\nThe total number of patches now: 27346 \tremaining patches: 664\nThe total number of patches now: 27346 \tremaining patches: 663\nThe total number of patches now: 27346 \tremaining patches: 662\nThe total number of patches now: 27348 \tremaining patches: 661\nThe total number of patches now: 27353 \tremaining patches: 660\nThe total number of patches now: 27355 \tremaining patches: 659\nThe total number of patches now: 27355 \tremaining patches: 658\nThe total number of patches now: 27361 \tremaining patches: 657\nThe total number of patches now: 27373 \tremaining patches: 656\nThe total number of patches now: 27374 \tremaining patches: 655\nThe total number of patches now: 27374 \tremaining patches: 654\nThe total number of patches now: 27385 \tremaining patches: 653\nThe total number of patches now: 27401 \tremaining patches: 652\nThe total number of patches now: 27417 \tremaining patches: 651\nThe total number of patches now: 27421 \tremaining patches: 650\nThe total number of patches now: 27423 \tremaining patches: 649\nThe total number of patches now: 27423 \tremaining patches: 648\nThe total number of patches now: 27423 \tremaining patches: 647\nThe total number of patches now: 27425 \tremaining patches: 646\nThe total number of patches now: 27431 \tremaining patches: 645\nThe total number of patches now: 27441 \tremaining patches: 644\nThe total number of patches now: 27450 \tremaining patches: 643\nThe total number of patches now: 27456 \tremaining patches: 642\nThe total number of patches now: 27456 \tremaining patches: 641\nThe total number of patches now: 27456 \tremaining patches: 640\nThe total number of patches now: 27462 \tremaining patches: 639\nThe total number of patches now: 27475 \tremaining patches: 638\nThe total number of patches now: 27479 \tremaining patches: 637\nThe total number of patches now: 27483 \tremaining patches: 636\nThe total number of patches now: 27483 \tremaining patches: 635\nThe total number of patches now: 27483 \tremaining patches: 634\nThe total number of patches now: 27486 \tremaining patches: 633\nThe total number of patches now: 27490 \tremaining patches: 632\nThe total number of patches now: 27506 \tremaining patches: 631\nThe total number of patches now: 27522 \tremaining patches: 630\nThe total number of patches now: 27525 \tremaining patches: 629\nThe total number of patches now: 27533 \tremaining patches: 628\nThe total number of patches now: 27537 \tremaining patches: 627\nThe total number of patches now: 27538 \tremaining patches: 626\nThe total number of patches now: 27552 \tremaining patches: 625\nThe total number of patches now: 27556 \tremaining patches: 624\nThe total number of patches now: 27570 \tremaining patches: 623\nThe total number of patches now: 27583 \tremaining patches: 622\nThe total number of patches now: 27587 \tremaining patches: 621\nThe total number of patches now: 27593 \tremaining patches: 620\nThe total number of patches now: 27600 \tremaining patches: 619\nThe total number of patches now: 27610 \tremaining patches: 618\nThe total number of patches now: 27626 \tremaining patches: 617\nThe total number of patches now: 27626 \tremaining patches: 616\nThe total number of patches now: 27632 \tremaining patches: 615\nThe total number of patches now: 27632 \tremaining patches: 614\nThe total number of patches now: 27636 \tremaining patches: 613\nThe total number of patches now: 27645 \tremaining patches: 612\nThe total number of patches now: 27645 \tremaining patches: 611\nThe total number of patches now: 27649 \tremaining patches: 610\nThe total number of patches now: 27651 \tremaining patches: 609\nThe total number of patches now: 27659 \tremaining patches: 608\nThe total number of patches now: 27669 \tremaining patches: 607\nThe total number of patches now: 27675 \tremaining patches: 606\nThe total number of patches now: 27679 \tremaining patches: 605\nThe total number of patches now: 27682 \tremaining patches: 604\nThe total number of patches now: 27689 \tremaining patches: 603\nThe total number of patches now: 27689 \tremaining patches: 602\nThe total number of patches now: 27696 \tremaining patches: 601\nThe total number of patches now: 27704 \tremaining patches: 600\nThe total number of patches now: 27710 \tremaining patches: 599\nThe total number of patches now: 27715 \tremaining patches: 598\nThe total number of patches now: 27721 \tremaining patches: 597\nThe total number of patches now: 27721 \tremaining patches: 596\nThe total number of patches now: 27721 \tremaining patches: 595\nThe total number of patches now: 27721 \tremaining patches: 594\nThe total number of patches now: 27725 \tremaining patches: 593\nThe total number of patches now: 27725 \tremaining patches: 592\nThe total number of patches now: 27730 \tremaining patches: 591\nThe total number of patches now: 27741 \tremaining patches: 590\nThe total number of patches now: 27750 \tremaining patches: 589\nThe total number of patches now: 27750 \tremaining patches: 588\nThe total number of patches now: 27750 \tremaining patches: 587\nThe total number of patches now: 27750 \tremaining patches: 586\nThe total number of patches now: 27750 \tremaining patches: 585\nThe total number of patches now: 27753 \tremaining patches: 584\nThe total number of patches now: 27762 \tremaining patches: 583\nThe total number of patches now: 27774 \tremaining patches: 582\nThe total number of patches now: 27785 \tremaining patches: 581\nThe total number of patches now: 27797 \tremaining patches: 580\nThe total number of patches now: 27805 \tremaining patches: 579\nThe total number of patches now: 27809 \tremaining patches: 578\nThe total number of patches now: 27809 \tremaining patches: 577\nThe total number of patches now: 27809 \tremaining patches: 576\nThe total number of patches now: 27810 \tremaining patches: 575\nThe total number of patches now: 27817 \tremaining patches: 574\nThe total number of patches now: 27825 \tremaining patches: 573\nThe total number of patches now: 27825 \tremaining patches: 572\nThe total number of patches now: 27825 \tremaining patches: 571\nThe total number of patches now: 27828 \tremaining patches: 570\nThe total number of patches now: 27836 \tremaining patches: 569\nThe total number of patches now: 27848 \tremaining patches: 568\nThe total number of patches now: 27864 \tremaining patches: 567\nThe total number of patches now: 27880 \tremaining patches: 566\nThe total number of patches now: 27880 \tremaining patches: 565\nThe total number of patches now: 27882 \tremaining patches: 564\nThe total number of patches now: 27883 \tremaining patches: 563\nThe total number of patches now: 27884 \tremaining patches: 562\nThe total number of patches now: 27891 \tremaining patches: 561\nThe total number of patches now: 27891 \tremaining patches: 560\nThe total number of patches now: 27891 \tremaining patches: 559\nThe total number of patches now: 27892 \tremaining patches: 558\nThe total number of patches now: 27898 \tremaining patches: 557\nThe total number of patches now: 27903 \tremaining patches: 556\nThe total number of patches now: 27911 \tremaining patches: 555\nThe total number of patches now: 27921 \tremaining patches: 554\nThe total number of patches now: 27932 \tremaining patches: 553\nThe total number of patches now: 27933 \tremaining patches: 552\nThe total number of patches now: 27933 \tremaining patches: 551\nThe total number of patches now: 27941 \tremaining patches: 550\nThe total number of patches now: 27945 \tremaining patches: 549\nThe total number of patches now: 27949 \tremaining patches: 548\nThe total number of patches now: 27949 \tremaining patches: 547\nThe total number of patches now: 27954 \tremaining patches: 546\nThe total number of patches now: 27962 \tremaining patches: 545\nThe total number of patches now: 27962 \tremaining patches: 544\nThe total number of patches now: 27962 \tremaining patches: 543\nThe total number of patches now: 27963 \tremaining patches: 542\nThe total number of patches now: 27968 \tremaining patches: 541\nThe total number of patches now: 27968 \tremaining patches: 540\nThe total number of patches now: 27972 \tremaining patches: 539\n"
    },
    {
     "ename": "IndexError",
     "evalue": "index 245 is out of bounds for axis 0 with size 240",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-3246a760b252>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewPatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"trueSet\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mregister_patch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewPatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0mexpandedPatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewPatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mtotalPatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewPatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-39a238e490fa>\u001b[0m in \u001b[0;36mregister_patch\u001b[1;34m(patch)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgCoord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mß1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgCoord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mß1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mcell1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimgModel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'grid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgIdx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msImg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idx'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimgIdx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trueSet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 245 is out of bounds for axis 0 with size 240"
     ]
    }
   ],
   "source": [
    "print(\"Start Expansion....\")\n",
    "patches = deepcopy(originalPatches)\n",
    "totalPatches = deepcopy(originalPatches)\n",
    "patchesStack = deepcopy(originalPatches)\n",
    "expandedPatches = []\n",
    "imagesModels = deepcopy(originalImageModels)\n",
    "print(\"Total number of patches: \", len(patches))\n",
    "while len(patchesStack) != 0:\n",
    "    print(\"The total number of patches now:\",len(totalPatches),\"\\tremaining patches:\",len(patchesStack))\n",
    "    patch = patchesStack.pop(0)\n",
    "    neighborCells = get_neighbor_cells(patch)\n",
    "    \n",
    "    for neighborCell in neighborCells:\n",
    "        newPatch = construct_expanded_patch(patch,neighborCell)\n",
    "        if newPatch is None:\n",
    "            continue\n",
    "\n",
    "        if len(newPatch[\"trueSet\"]) >= gamma:\n",
    "            register_patch(newPatch)\n",
    "            expandedPatches.append(newPatch)\n",
    "            totalPatches.append(newPatch)\n",
    "\n",
    "        # print(intersection)\n",
    "        # d = - np.dot(np.squeeze(patch['normal']),np.squeeze(imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1))) \n",
    "        # xx, yy = np.meshgrid(range(10), range(10))\n",
    "        # z = (-patch['normal'][0] * xx - patch['normal'][1] * yy - d) * 1. /patch['normal'][2]\n",
    "        # plt3d = plt.figure().gca(projection='3d')\n",
    "        # plt3d.plot_surface(xx, yy, z)\n",
    "        # x = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[0]]\n",
    "        # y = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[1]]\n",
    "        # z = [imagesModels[patch['referenceImgIdx']][\"optCenter\"].reshape(4,1)[2]]\n",
    "        # xi = [intersection[0]]\n",
    "        # yi = [intersection[1]]\n",
    "        # zi = [intersection[2]]\n",
    "        # plt3d.scatter(x,y,z,c='r')\n",
    "        # plt3d.scatter(xi,yi,zi,c='y')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "totTim = time()\n",
    "while(len(expandedPatches)!=0):\n",
    "    print(\"Pass\"+str(idx)+\":\")\n",
    "    patchesStack = deepcopy(expandedPatches)\n",
    "    expandedPatches = []\n",
    "    print(\"Total number of patches: \", len(patches),\"\\tremaining patches:\",len(patchesStack))\n",
    "    tim = time()\n",
    "    while len(patchesStack) != 0:\n",
    "        print(\"The total number of patches now:\",len(totalPatches),\"\\tremaining patches:\",len(patchesStack))\n",
    "        patch = patchesStack.pop(0)\n",
    "        neighborCells = get_neighbor_cells(patch)\n",
    "        for neighborCell in neighborCells:    \n",
    "            newPatch = construct_expanded_patch(patch,neighborCell)\n",
    "            if newPatch is None:\n",
    "                continue\n",
    "            \n",
    "            if len(newPatch[\"trueSet\"]) >= gamma:\n",
    "                register_patch(newPatch)\n",
    "                expandedPatches.append(newPatch)\n",
    "                totalPatches.append(newPatch)\n",
    "    print(\"Pass time:\",time()-tim)\n",
    "    idx += 1\n",
    "print(\"Total time:\",time()-totTim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_expanded_header(file):\n",
    "    file.write(\"ply\\n\")\n",
    "    file.write(\"format ascii 1.0\\n\")\n",
    "    file.write( \"element vertex \"+ str(len(totalPatches)) + \"\\n\")\n",
    "    file.write( \"property float x\\n\")\n",
    "    file.write(\"property float y\\n\")\n",
    "    file.write(\"property float z\\n\")\n",
    "    file.write(\"property float nx\\n\")\n",
    "    file.write(\"property float ny\\n\")\n",
    "    file.write(\"property float nz\\n\")\n",
    "    file.write(\"property uchar diffuse_red\\n\")\n",
    "    file.write(\"property uchar diffuse_green\\n\")\n",
    "    file.write(\"property uchar diffuse_blue\\n\")\n",
    "    file.write( \"end_header\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_expanded_ply(): \n",
    "    file = open(\"expandedpointcloud.txt.ply\", \"w\")\n",
    "    write_expanded_header(file)\n",
    "    \n",
    "    for idx,patch in enumerate(totalPatches):\n",
    "        file.write(str(patch[\"center\"][0][0]) + \" \" +  str(patch[\"center\"][1][0]) + \" \" + str(patch[\"center\"][2][0]) + \" \")\n",
    "        file.write(str(patch[\"normal\"][0][0]) + \" \" +  str(patch[\"normal\"][1][0]) + \" \" + str(patch[\"normal\"][2][0]) + \" \")\n",
    "        if idx < len(originalPatches):\n",
    "            file.write(\"255\"+ \" \" + \"0\" + \" \"+\"0\")\n",
    "        else:\n",
    "             file.write(\"0\"+ \" \" + \"0\" + \" \"+\"255\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "    file.close()\n",
    "\n",
    "print(len(totalPatches))   \n",
    "print(len(expandedPatches)) \n",
    "print(len(originalPatches)) \n",
    "write_expanded_ply()"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python36764bitbaseconda671ffe7150094cd9ba8c9cb5c362aaeb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}